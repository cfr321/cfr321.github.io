<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[个人简历]]></title>
    <url>%2F2019%2F04%2F30%2F%E4%B8%AA%E4%BA%BA%E7%AE%80%E5%8E%86%2F</url>
    <content type="text"><![CDATA[这是一份个人简历。。 联系方式 | 期望职位：Java开发实习生 手机（微信号）：173-9651-0930 Email：cwellshake@gmail.com 个人信息 | 陈发荣 / 男 / 1998 教育背景：福州大学（211） 技术博客：http://cfr321.github.io Github：https://github.com/cfr321 证书技能：CTE4 / 自学C语言、数据结构和算法、计算机网络知识等计算机专业知识 技能清单 | 熟悉Java基础，了解常见设计模式 熟悉Servlet、JSP、JDBC等JavaWeb基础知识 熟悉IntelliJ IDEA、eclipse、vscode、Git、Maven等工具 熟悉MySQL关系型数据库，了解Redis 熟悉SringMVC、Spring、Mybatis框架技术；了解SpringBoot、SpringData 了解HTML+CSS+JS，以及BootStrap、Vue.js等前端知识 了解Linux常用命令，能够搭建开发环境 个人项目 | 员工管理系统 项目介绍：这是一个独立完成的员工管理系统，通过这个项目使我更加熟悉了SSM框架，以及学习BootStrap对页面的搭建，项目主要采用页面发送ajax到后端，实现对员工的信息的修改。整个项目业务并不复杂，但第一次做项目还是出现了很多问题，比如bootstrap的cs效果引入问题、MySQL8.0版本连接问题等等，我是完全自学的、遇到了问题我只能不断地去网上搜索，翻阅很多别人的博客，最终让问题得到解决。 CkServer服务器 一个类似tomcat的web服务器，这是在我学习Java网络编程时候做的一个小项目。它能接受HTTP请求以及响应，实现了war包的自动解压、xml的解析获取servlet、以及常见的状态码的响应。一开始它只支持IO流操作，一个请求一个线程；我又去学习了NIO的知识，并运用在这个小项目上。 cako商城 这是一个基于SpringBoot和SpringData的分布式项目，前端用的是vue.js，用nginx实现方向代理。目前并没有完全开发完全，现在在开发后台商品管理系统，从中我也在不断记取不断进步。 其他信息 | 校园经历：曾担任idea精英汇新闻官部长，负责微信公众号管理，有公众号管理和推文撰写经验 性格特点：专注度高，热爱学习，富有创造力 个人爱好：运动、游戏、读书和敲代码]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>分享</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池技术]]></title>
    <url>%2F2019%2F04%2F29%2F%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[线程学到了线程池技术了，可能多线程学习也要告一段落了，回顾，线程我们实现多线程的方式已经有了四种，Thread继承，Runnable接口实现，Callable接口实现，和最后的线程池。 一、Callable以前并没有聊过这个东东，先说一下这个Callable 1234567891011121314151617public class CallableDome implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; System.out.println("call== come in "); return 2; &#125; public static void main(String[] args) throws Exception &#123; FutureTask&lt;Integer&gt; futureTask=new FutureTask&lt;&gt;(new CallableDome()); new Thread(futureTask).start(); new Thread(futureTask).start(); System.out.println(futureTask.get()); &#125;&#125; /** output: * call== come in * 2 */ 对于上面这个代码有以下几点总结： Thread并没有为Callable提供构造方法，不能像Runnable一样直接传入，这时候就需要一个适配器 FutureTask，这个东西实现了Runnable接口，所以能被Thread接受，其次FutureTask 提供了传入 Callable接口的构造方法。- - —–FutureTask在这里就是适配器，这就是典型的适配器模式。 其实这里还有一个策略模式，对于任何类，只要实现了Runnable接口，它就能被Thread接受，这就是策略模式 比较Callable和Runnable，前者的运行方法是call,不再是run，而且有了返回值。 最终的打印结果只有一个 call== come in ，这里也是要注意的，已经得出结果的线程操作不会去在运行一次，当然你要再弄个FutureTask，是能再运行的。 二、线程池 一看类图关系：着重注意TreadPoolExecutor 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 1、线程池：ThreadPoolExecutor * Java中有五种实现： * newFixedThreadPool //一池规定线程数 * newCachedThreadPool //一池n线程数， * newSingleThreadExecutor //一池一线程 * newScheduledThreadPool //延迟加载的 * newWorkStealingPool //根据系统cup确定核心线程数的 * * 2、底层都是时去用ThreadPoolExecutor实现的： * ThreadPoolExecutord有七个属性： * ThreadPoolExecutor threadPool1=new ThreadPoolExecutor( * 5, //corepoolsize 核心线程数 * 8, //maxmumpoolsize 最大线程数 * 1L, //keepAliveTime 普通线程为被使用多久撤销 * TimeUnit.SECONDS, //TimeUnit时间单位 * new LinkedBlockingQueue&lt;Runnable&gt;(5), //阻塞队列的类型 * Executors.defaultThreadFactory(), //线程工厂，默认即可 * new ThreadPoolExecutor.DiscardOldestPolicy()); //拒绝策略，当全都满了怎么处理 * * 3、拒绝策略：有四种 * AbortPolicy //抛异常 * CallerRunsPolicy //给调用线程池的线程去处理 * DiscardOldestPolicy //丢弃等待最久的线程 * DiscardtPolicy //直接丢弃要进来的 * */public class MyThreadPoolDemo &#123; public static void main(String[] args)&#123; ExecutorService threadPool= Executors.newWorkStealingPool(); ThreadPoolExecutor threadPool1=new ThreadPoolExecutor(5,8,1L,TimeUnit.SECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(5), Executors.defaultThreadFactory(), new ThreadPoolExecutor.DiscardOldestPolicy()); try &#123; for (int i = 0; i &lt;14 ; i++) &#123; int finalI = i; threadPool.execute(()-&gt;&#123; System.out.println(Thread.currentThread().getName()+"\t "+ finalI); &#125;); &#125; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; threadPool.shutdown(); &#125; &#125;&#125; 二看具体属性关系 三看流程 三、总结线程池主要要了解的就是 Java中提供的几种实现，线程池构造的七种属性，它们的关系以及操作的流程。 注意：实际生产中我们其实基本不用Java自带的那几种配好的线程池，因为拒绝策略不好，或者阻塞列队直接Integer.MAX也是不合适，还有线程数的设计也可能不符合要求。往往需要我们自己去配置。 关于配置线程池的线程数： cup密集型：电脑cup数加一。 io密集型：一般可以是电脑cup的八到十倍。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中的阻塞队列]]></title>
    <url>%2F2019%2F04%2F28%2FJava%E4%B8%AD%E7%9A%84%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[阻塞列队也是Java高并发里面常用的工具类，今天学习了一下，总结 一下。 注意：该随笔内容完全引自http://wsmajunfeng.iteye.com/blog/1629354，写的很好，非常感谢，复制过来算是个积累，怕以后找不到。 一. 前言 在新增的Concurrent包中，BlockingQueue很好的解决了多线程中，如何高效安全“传输”数据的问题。通过这些高效并且线程安全的队列类，为我们快速搭建高质量的多线程程序带来极大的便利。本文详细介绍了BlockingQueue家庭中的所有成员，包括他们各自的功能以及常见使用场景。 二. 认识BlockingQueue 阻塞队列，顾名思义，首先它是一个队列，而一个队列在数据结构中所起的作用大致如下图所示： 从上图我们可以很清楚看到，通过一个共享的队列，可以使得数据由队列的一端输入，从另外一端输出； 常用的队列主要有以下两种：（当然通过不同的实现方式，还可以延伸出很多不同类型的队列，DelayQueue就是其中的一种） 先进先出（FIFO）：先插入的队列的元素也最先出队列，类似于排队的功能。从某种程度上来说这种队列也体现了一种公平性。 后进先出（LIFO）：后插入队列的元素最先出队列，这种队列优先处理最近发生的事件。 ​ 多线程环境中，通过队列可以很容易实现数据共享，比如经典的“生产者”和“消费者”模型中，通过队列可以很便利地实现两者之间的数据共享。假设我们有若干生产者线程，另外又有若干个消费者线程。如果生产者线程需要把准备好的数据共享给消费者线程，利用队列的方式来传递数据，就可以很方便地解决他们之间的数据共享问题。但如果生产者和消费者在某个时间段内，万一发生数据处理速度不匹配的情况呢？理想情况下，如果生产者产出数据的速度大于消费者消费的速度，并且当生产出来的数据累积到一定程度的时候，那么生产者必须暂停等待一下（阻塞生产者线程），以便等待消费者线程把累积的数据处理完毕，反之亦然。然而，在concurrent包发布以前，在多线程环境下，我们每个程序员都必须去自己控制这些细节，尤其还要兼顾效率和线程安全，而这会给我们的程序带来不小的复杂度。好在此时，强大的concurrent包横空出世了，而他也给我们带来了强大的BlockingQueue。（在多线程领域：所谓阻塞，在某些情况下会挂起线程（即阻塞），一旦条件满足，被挂起的线程又会自动被唤醒），下面两幅图演示了BlockingQueue的两个常见阻塞场景： 如上图所示：当队列中没有数据的情况下，消费者端的所有线程都会被自动阻塞（挂起），直到有数据放入队列。 如上图所示：当队列中填满数据的情况下，生产者端的所有线程都会被自动阻塞（挂起），直到队列中有空的位置，线程被自动唤醒。 这也是我们在多线程环境下，为什么需要BlockingQueue的原因。作为BlockingQueue的使用者，我们再也不需要关心什么时候需要阻塞线程，什么时候需要唤醒线程，因为这一切BlockingQueue都给你一手包办了。既然BlockingQueue如此神通广大，让我们一起来见识下它的常用方法： 三. BlockingQueue的核心方法： 1.放入数据 （1）offer(anObject):表示如果可能的话,将anObject加到BlockingQueue里,即如果BlockingQueue可以容纳,则返回true,否则返回false.（本方法不阻塞当前执行方法 的线程）； （2）offer(E o, long timeout, TimeUnit unit)：可以设定等待的时间，如果在指定的时间内，还不能往队列中加入BlockingQueue，则返回失败。 （3）put(anObject):把anObject加到BlockingQueue里,如果BlockQueue没有空间,则调用此方法的线程被阻断直到BlockingQueue里面有空间再继续. 2. 获取数据 （1）poll(time):取走BlockingQueue里排在首位的对象,若不能立即取出,则可以等time参数规定的时间,取不到时返回null; （2）poll(long timeout, TimeUnit unit)：从BlockingQueue取出一个队首的对象，如果在指定时间内，队列一旦有数据可取，则立即返回队列中的数据。否则知道时间 超时还没有数据可取，返回失败。 （3）take():取走BlockingQueue里排在首位的对象,若BlockingQueue为空,阻断进入等待状态直到BlockingQueue有新的数据被加入; （4）drainTo():一次性从BlockingQueue获取所有可用的数据对象（还可以指定获取数据的个数），通过该方法，可以提升获取数据效率；不需要多次分批加锁或释放锁。 四. 常见BlockingQueue 在了解了BlockingQueue的基本功能后，让我们来看看BlockingQueue家庭大致有哪些成员？ 1. ArrayBlockingQueue 基于数组的阻塞队列实现，在ArrayBlockingQueue内部，维护了一个定长数组，以便缓存队列中的数据对象，这是一个常用的阻塞队列，除了一个定长数组外，ArrayBlockingQueue内部还保存着两个整形变量，分别标识着队列的头部和尾部在数组中的位置。 ArrayBlockingQueue在生产者放入数据和消费者获取数据，都是共用同一个锁对象，由此也意味着两者无法真正并行运行，这点尤其不同于LinkedBlockingQueue；按照实现原理来分析，ArrayBlockingQueue完全可以采用分离锁，从而实现生产者和消费者操作的完全并行运行。Doug Lea之所以没这样去做，也许是因为ArrayBlockingQueue的数据写入和获取操作已经足够轻巧，以至于引入独立的锁机制，除了给代码带来额外的复杂性外，其在性能上完全占不到任何便宜。 ArrayBlockingQueue和LinkedBlockingQueue间还有一个明显的不同之处在于，前者在插入或删除元素时不会产生或销毁任何额外的对象实例，而后者则会生成一个额外的Node对象。这在长时间内需要高效并发地处理大批量数据的系统中，其对于GC的影响还是存在一定的区别。而在创建ArrayBlockingQueue时，我们还可以控制对象的内部锁是否采用公平锁，默认采用非公平锁。 2.LinkedBlockingQueue 基于链表的阻塞队列，同ArrayListBlockingQueue类似，其内部也维持着一个数据缓冲队列（该队列由一个链表构成），当生产者往队列中放入一个数据时，队列会从生产者手中获取数据，并缓存在队列内部，而生产者立即返回；只有当队列缓冲区达到最大值缓存容量时（LinkedBlockingQueue可以通过构造函数指定该值），才会阻塞生产者队列，直到消费者从队列中消费掉一份数据，生产者线程会被唤醒，反之对于消费者这端的处理也基于同样的原理。而LinkedBlockingQueue之所以能够高效的处理并发数据，还因为其对于生产者端和消费者端分别采用了独立的锁来控制数据同步，这也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。 作为开发者，我们需要注意的是，如果构造一个LinkedBlockingQueue对象，而没有指定其容量大小，LinkedBlockingQueue会默认一个类似无限大小的容量（Integer.MAX_VALUE），这样的话，如果生产者的速度一旦大于消费者的速度，也许还没有等到队列满阻塞产生，系统内存就有可能已被消耗殆尽了。 ArrayBlockingQueue和LinkedBlockingQueue是两个最普通也是最常用的阻塞队列，一般情况下，在处理多线程间的生产者消费者问题，使用这两个类足以。 下面的代码演示了如何使用BlockingQueue： 3. DelayQueue DelayQueue中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素。DelayQueue是一个没有大小限制的队列，因此往队列中插入数据的操作（生产者）永远不会被阻塞，而只有获取数据的操作（消费者）才会被阻塞。 使用场景： DelayQueue使用场景较少，但都相当巧妙，常见的例子比如使用一个DelayQueue来管理一个超时未响应的连接队列。 4. PriorityBlockingQueue 基于优先级的阻塞队列（优先级的判断通过构造函数传入的Compator对象来决定），但需要注意的是PriorityBlockingQueue并不会阻塞数据生产者，而只会在没有可消费的数据时，阻塞数据的消费者。因此使用的时候要特别注意，生产者生产数据的速度绝对不能快于消费者消费数据的速度，否则时间一长，会最终耗尽所有的可用堆内存空间。在实现PriorityBlockingQueue时，内部控制线程同步的锁采用的是公平锁。 5. SynchronousQueue 一种无缓冲的等待队列，类似于无中介的直接交易，有点像原始社会中的生产者和消费者，生产者拿着产品去集市销售给产品的最终消费者，而消费者必须亲自去集市找到所要商品的直接生产者，如果一方没有找到合适的目标，那么对不起，大家都在集市等待。相对于有缓冲的BlockingQueue来说，少了一个中间经销商的环节（缓冲区），如果有经销商，生产者直接把产品批发给经销商，而无需在意经销商最终会将这些产品卖给那些消费者，由于经销商可以库存一部分商品，因此相对于直接交易模式，总体来说采用中间经销商的模式会吞吐量高一些（可以批量买卖）；但另一方面，又因为经销商的引入，使得产品从生产者到消费者中间增加了额外的交易环节，单个产品的及时响应性能可能会降低。 声明一个SynchronousQueue有两种不同的方式，它们之间有着不太一样的行为。公平模式和非公平模式的区别: 如果采用公平模式：SynchronousQueue会采用公平锁，并配合一个FIFO队列来阻塞多余的生产者和消费者，从而体系整体的公平策略； 但如果是非公平模式（SynchronousQueue默认）：SynchronousQueue采用非公平锁，同时配合一个LIFO队列来管理多余的生产者和消费者，而后一种模式，如果生产者和消费者的处理速度有差距，则很容易出现饥渴的情况，即可能有某些生产者或者是消费者的数据永远都得不到处理。 五. 小结 BlockingQueue不光实现了一个完整队列所具有的基本功能，同时在多线程环境下，他还自动管理了多线间的自动等待于唤醒功能，从而使得程序员可以忽略这些细节，关注更高级的功能 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566//生产者消费者模式 3.0 class MyResouce&#123; private volatile boolean flag=true; private AtomicInteger atomicInteger=new AtomicInteger(); BlockingQueue&lt;String&gt; blockingDeque=null; public MyResouce(BlockingQueue&lt;String&gt; blockingDeque) &#123; this.blockingDeque = blockingDeque; System.out.println(blockingDeque.getClass().getName()); &#125; public void myProd() throws Exception&#123; String Date=null; boolean reValue; while(flag)&#123; Date=atomicInteger.incrementAndGet()+""; reValue=blockingDeque.offer(Date,2L, TimeUnit.SECONDS); if(reValue)&#123; System.out.println("生产成功"+Date); &#125;else&#123; System.out.println("生产失败"); &#125; TimeUnit.SECONDS.sleep(1); &#125; if(!flag)&#123; System.out.println("停止生产"); &#125; &#125; public void myComsu() throws Exception&#123; String result=null; while (flag)&#123; result=blockingDeque.poll(2L,TimeUnit.SECONDS); if(result==null || result.equalsIgnoreCase(""))&#123; System.out.println("没有取到"); &#125;else&#123; System.out.println("去到蛋糕"+result); &#125; &#125; &#125; public void stop()&#123; flag=false; &#125;&#125;public class ProdConsumer_BlockQueue &#123; public static void main(String[] args)&#123; MyResouce myResouce=new MyResouce(new ArrayBlockingQueue&lt;String&gt;(3)); new Thread(() -&gt; &#123; System.out.println("开始生产"); try &#123; myResouce.myProd(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, "pro").start(); new Thread(() -&gt; &#123; System.out.println("开始消费"); try &#123; myResouce.myComsu(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, "comsu").start(); try &#123; TimeUnit.SECONDS.sleep(5);&#125;catch (InterruptedException e) &#123; e.printStackTrace();&#125; myResouce.stop(); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[锁]]></title>
    <url>%2F2019%2F04%2F27%2F%E9%94%81%2F</url>
    <content type="text"><![CDATA[学习三部曲：理论+实践+总结 一、公平锁和非公平锁公平锁符合先到先得，有先来后到之分；非公平锁就没有，都是同时竞争锁，而且趋于短作业优先。 ReentrantLock默认就是非公平锁，非公平锁有着更好的吞吐率。 1Lock lock=new ReentrantLock(true); //设置为公平锁 synchronized，也是非公平锁 二、可重入锁（递归锁）ReentrantLock 和 Synchronized都是个可重入锁： 重入锁：同一个线程外层获取锁后，这个线程可以进入任何这把锁的方法。 12345678910111213//case1:证明了synchronized是可重入锁private synchronized void method1()&#123; System.out.println("方法一被调用了"); method2();&#125;private synchronized void method2() &#123; System.out.println("方法二被调用了");&#125;public static void main(String[] args)&#123; Doma01 doma01=new Doma01(); doma01.method1();&#125; 1234567891011121314151617181920212223242526272829//case2：证明了ReentrantLock是可重入锁public class Dome2 &#123; static Lock lock=new ReentrantLock(); private static void method1()&#123; lock.lock(); try &#123; System.out.println(Thread.currentThread().getName()+"\t invoked method1"); method2(); &#125;finally &#123; lock.unlock(); &#125; &#125; private static void method2() &#123; lock.lock(); try &#123; System.out.println(Thread.currentThread().getName()+"\t invoked method2"); &#125;finally &#123; lock.unlock(); &#125; &#125; public static void main(String[] args)&#123; new Thread(() -&gt; &#123; method1(); &#125;, "t1").start(); new Thread(() -&gt; &#123; method1(); &#125;, "t2").start(); &#125;&#125; 上面的代码都能正常运行，线程可以访问到其他的同样锁的方法，可重入锁的目的是防止了死锁。自锁。 注意，ReenteankLock，加锁和解锁的次数一定要匹配，调用了几次lock（），就需要几unlock()，才能释放锁，其他线程才能获得到锁。 少了unlock()，会出现锁未释放，程序阻塞。而多了unlock（）程序是会报错的。 java.lang.IllegalMonitorStateException 三、自旋锁自旋：多次来看看时候能获得锁，看了不能获得就去干自己的，然后一段时间后又来看看时候能获得锁。 手写自旋锁： 123456789101112131415161718public class MySpinLock &#123; //设置Thread的原子对象，对其修改具有原子性 AtomicReference&lt;Thread&gt; atomicReference=new AtomicReference&lt;&gt;(); public void myLock()&#123; Thread thread=Thread.currentThread(); System.out.println(thread.getName()+"\t come in"); //自旋的去看atomicReference是否为空了，为空就将自己设置进去。 while(!atomicReference.compareAndSet(null,thread))&#123; &#125; &#125; //释放锁的方法 public void myUnlock()&#123; Thread thread=Thread.currentThread(); atomicReference.compareAndSet(thread,null); System.out.println(thread.getName()+"\t come out"); &#125;&#125; 自旋锁问题：当一个线程长时间占用资源，其他线程将会不断的去尝试获取锁，那么就会消耗cup性能。 四、独占锁（写锁）/共享锁（读锁）/ 读写锁多线程操作资源，有时又需要读的时候可以共同访问，但是写的时候其他线程不能访问子资源。 写操作：原子性+独占，整个过程必须是个完整的过程，不能又其他线程插入其中。 ReentrankReadWriteLock就是典型的读写锁 12345678910111213141516171819202122232425262728293031//利用ReentrankReadWriteLock实现 写时上锁，读读共享class Mychace&#123; private volatile Map&lt;String,Object&gt; map=new HashMap&lt;&gt;(); private ReentrantReadWriteLock lock=new ReentrantReadWriteLock(false); public void put(String k,Object o)&#123; lock.writeLock().lock(); try &#123; System.out.println(Thread.currentThread().getName()+"\t 开始写入"); map.put(k,o); System.out.println(Thread.currentThread().getName()+"\t 写入完成"); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.writeLock().unlock(); &#125; &#125; public void get(String k)&#123; lock.readLock().lock(); try &#123; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.readLock().unlock(); &#125; System.out.println(Thread.currentThread().getName()+"\t 开始读取"); Object o=map.get(k); System.out.println(Thread.currentThread().getName()+"\t 读取完成"+o); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAS-实现原子性]]></title>
    <url>%2F2019%2F04%2F26%2FCAS-%E5%AE%9E%E7%8E%B0%E5%8E%9F%E5%AD%90%E6%80%A7%2F</url>
    <content type="text"><![CDATA[前面学习过volatile，它实现了内存的可见性，但是不保证原子性。于是我们引用了AtomicInteger类实现了非原子操作的线程安全，回过头来想，AtomicInteger类是如果实现 ++ 的原子性的呢。 一、compareAndSet123456789101112131415161718//比较符合预期就更新public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update); &#125;//加一public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1; &#125;//再点进去 unsafe.getAndAddIntpublic final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; &#125; 我们最后发现两个方法最后都有调用 unsafe.compareAndSwapInt (this, valueOffset, expect, update); 那这是是个什么方法呢，unsafe类的这个方法是一个native的本地方法，它是底层的c类语言的对cup直接操作的原语。何为原语，它是一段不能被打断插入的对底层操作。 百度百科：原语 操作系统或计算机网络用语范畴。是由若干条指令组成的，用于完成一定功能的一个过程。primitive or atomic action 是由若干个机器指令构成的完成某种特定功能的一段程序，具有不可分割性·即原语的执行必须是连续的，在执行过程中不允许被中断。 OK我们要知道的就是它不能被分割了的，不会被别的操作再去干扰的机器命令。 那么在看看它传入的参数： this ：表示当前需要修改的对象 valueOffset：对象的内存地址，底层可以通过这个地址获得 this 对象的值。 expect：我们对this对象所期望的值 update：符合期望我们要将它更新的值 2、那么到这里我们的compareAndSet compareAndSet(expect, update)方法就借助底层的compareAndSwapInt (this, valueOffset, expect, update)，实现了是否可以跟新。 3、getAndAddInt（）又是如何借助compareAndSwapInt 实现安全自增呢。我们的++操作是一个必须要成功的操作，不能想compareAndSet一样更新不成功就不更新了。 再来读读getAndAddInt(Object var1, long var2, int var4)源码， var1=&gt;this，var2=&gt;地址，var4=&gt;需要增加的值，var5=&gt;就是自己线程工作内存里面的值 1234567public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); //读取主内存值到工作内存 &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));//跟新不成功，自旋操作,重新读取var5，然后再进行compareAndSwapInt，注意这个方法是原语操作不会被打断，也就是这个操作过程中主内存里面的值是不会被修改的，这个var1也就是当前主内存里面的值。 return var5; &#125; 我们模拟两个线程并发的执行这个操作： 1、A线程读取主内存值得到自己的 Avar5=3，然后被挂起了 2、B线程读取主内存值得到自己的 Bvar5=3，然后进行了加一写入主内存。 3、A线程唤起，进行compareAndSwapInt，但是读取的var1是4，和期望的var5=3不相等，那么不跟新进入下一次循环。 4、再次读取var5=4，执行compareAndSwapInt，对比没问题，更新操作，写入主内存。 二、CAS的问题1、ABA问题：那上面的来讲，要是B线程加完之后又减了，主内存中的值就还是3，那么A线程的跟新操作也会一次就成功。这就是ABA问题。有一种狸猫换太子的感觉 ​ 解决：加上一个版本号，每次操作都让版本号加一，比较更新时除了比较值意外还要比较版本号。AtomicStampedRefrence，就实现了这样的功能， 2、自旋的性能消耗问题 3、无法解决多个变量的原子操作，前面的方法也体现了，这个时只能对一个变量进行比较跟新，多个变量操纵就需要加锁了。 ​]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[volatile轻量级锁-同步机制]]></title>
    <url>%2F2019%2F04%2F25%2Fvolatile%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%9A%84%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[不写点东西他还啥都没有 1、Volatile:轻量级的同步机制 保证可见性 不保证原子性(不保证JMM需要的原子性，所以轻量) 禁止指令重拍 2、JMM(Java内存模型)：是一种抽象概念，并不正式存在， 是一种规范。可见性、原子性、有序性 变量存在主内存、线程变量需要拷贝到自己的工作内存，操作完成后再写入主内存。 线程A读取主内存值，线程B也读取主内存。 3、从内存模型里去分析volatile的各种属性 可见性 此时A线程修改x,并写入主内，此时要求其他线程知道这个x被改变。这部分其实在Java多线程学习中就有学习过，只不过没有从JMM层次这么深刻的去认识。 123456789101112131415161718192021222324252627class MyDate&#123; volatile int number=0; public void addTo60()&#123; this.number=60; &#125;&#125;//1、验证volatile可见性 public class Test1 &#123; public static void main(String[] args)&#123; MyDate date=new MyDate(); //第一个线程AAA， new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName()+"\t come in"); try &#123; TimeUnit.SECONDS.sleep(3);&#125;catch (InterruptedException e) &#123; e.printStackTrace();&#125; date.addTo60(); System.out.println(); &#125;, "AAA").start(); while(date.number==0)&#123; &#125; //1、如果number没有加volatile.这里无法发生，main线程无法读取到AAA线程修改的值，无法读取主内存中改变的值 //2、如果加了volatile，就可以去读取到主内存改变的值 System.out.println("main线程结束"); &#125;&#125; 不保证原子性，JMM要求保证原子性，但是volatile不保证原子性。为什么volatile不能保证原子性呢。比如两个线程同时要对主内存中的i 进行 ++操作。++并不是原子操作，三步，读取i的值，将i加1，赋值给i。最后写入主内存。现在两个线程都完成了i++的操作了，然后写入操作是同步的，那么其中一个被挂起，写入之后主内存里面的值改变，这时候根据volatile的内存语义，其他线程应该通知得到这个值，但是被挂起的线程已经完成了i++的操作，所以这个可见来的有点晚，线程并不会再去对新的这个值去++操作，而是在很快的时间内就把自己加好的值写入主内存，这时候就会造成++操作的丢失。 12345678910111213141516171819202122232425//不保证原子性操作public class Test2 &#123; public static void main(String[] args)&#123; MyDate date=new MyDate(); for(int i=0;i&lt;100;i++)&#123; new Thread(() -&gt; &#123; for(int j=0;j&lt;1000;j++)&#123; date.addSum(); date.sumByAtomic(); &#125; &#125;, "i").start(); &#125; while(Thread.activeCount()&gt;2)&#123; Thread.yield(); &#125; System.out.println("mian中： number="+date.number); //number2是原子类型的 AtomicInteger System.out.println("main中： number2="+date.number2); &#125;&#125;/**mian中： number=98729main中： number2=100000 *///解决这个问题其实只要用上原子类 volatile重排规则，这是比较复杂的一个内容，涉及到JMM中happend-before，在代码编译运行过程中会对我们的代码进些一些重新排序，我们的基本要求是希望这些重新排序不要影响程序的运行结果。 volatile变量对于重拍有了这些内存语义： 对于任何volatile写，其前面的操作都不能重拍到它的后面 对于任何volatile读，其后面的操作都不能重拍到它的前面 先volatile写 再volatile读，也不能重新排序。 volatile要先读了，操作后面，操作好了，再写。如果硬是要先写再读也不能重排序]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap--浅析]]></title>
    <url>%2F2019%2F04%2F23%2FConcurrentHashMap-%E6%B5%85%E6%9E%90%2F</url>
    <content type="text"><![CDATA[ConcurrentHashMap简单小总结 最近一直在看《Java并发编程艺术》一书，书本内容还是相当的丰富，先从并发的底层实现、内存层次剖析了并发的实现，再到各种锁的底层实现原理，然后降到了Java中并发容器和框架。 前面的内容一直没时间整理，主要前面的知识底层读起来还是有难度的，一遍看过来感触不是很深。 今天学习了并发容器里面的ConcurrentHashMap和ConcurrentLinkedQueue，这里主要是写一些ConcurrentHashMap的理解。 Map家族是Java容器里非常重要的一部分，比如HashMap，Hashtable，ConcurrentHashMap。这三个中国HashMap线程不安全，后两者线程安全，但是Hashtable采用的是一种相当重量的锁，在对它进行操作的时候它会把整个表锁起来，是一种悲观锁。 而今天要讲的ConcurrentHashMap则时采用了一种更为巧妙地方式实现了线程安全。 不锁全表，锁局部。 不锁所有操作，只锁有线程安全的操作。 对用量的计算（size)，采用一种乐观锁的机制。 我阅读书本后书本总ConcurrentHashMap的结构大致是这样子的：ConcurrentHashMap的内部结构图： 从上面的结构我们可以了解到，ConcurrentHashMap定位一个元素的过程需要进行两次Hash操作。 锁的思路是put才锁上局部的HashEntry，这些HashEntry都是volatile的，volatile是concurrent包一个非常重要的锁的机制，当然它底层关键的点还是CAS算法。这本书前面讲原理讲锁主要就是讲这些东西。 看完书后我打开电脑翻阅了一下concurrentHashMap的源码，发现似乎和书上的有所差异，我的是jdk1.8，后来看了网上发现书本上应该讲的是1.7及以前的版本。 1.8的ConcurrentHashMap的结构其实我觉得和HashMap结构非常相似： 123456789/** * The array of bins. Lazily initialized upon first insertion. * Size is always a power of two. Accessed directly by iterators. */ transient volatile Node&lt;K,V&gt;[] table;/** * The next table to use; non-null only while resizing. */ private transient volatile Node&lt;K,V&gt;[] nextTable; 但是不一样的是变量前都加了volatile。 卧槽源码越读越卧槽，大概看了下get 和 put 还有扩容， get方法比较简单，和HashMap的思路差不多，先找到table对应的位置，再到链表中找对应的key，无需加锁。 123456789101112131415161718192021222324public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; //计算hash值 int h = spread(key.hashCode()); //根据hash值确定节点位置 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; //如果搜索到的节点key与传入的key相同且不为null,直接返回这个节点 if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; //如果eh&lt;0 说明这个节点在树上 直接寻找 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; //否则遍历链表 找到对应的值并返回 while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null; &#125; put复杂一些:我们看到它锁的是节点， 先计算hash，找到对应位置，当然还有一系列的判断、table是否为空、判断时候需要扩容、判断时候需要调整链表为数、插入的时候还要判断key时候存在过了、其实都和HashMap相似。关键在于它将这个节点锁主其他线程不能访问，当然它的子节点也不能被访问到了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public V put(K key, V value) &#123; return putVal(key, value, false); &#125; /** Implementation for put and putIfAbsent */ final V putVal(K key, V value, boolean onlyIfAbsent) &#123; //不允许 key或value为null if (key == null || value == null) throw new NullPointerException(); //计算hash值 int hash = spread(key.hashCode()); int binCount = 0; //死循环 何时插入成功 何时跳出 for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; //如果table为空的话，初始化table if (tab == null || (n = tab.length) == 0) tab = initTable(); //根据hash值计算出在table里面的位置 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; //如果这个位置没有值 ，直接放进去，不需要加锁 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; //当遇到表连接点时，需要进行整合表的操作 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; V oldVal = null; //结点上锁 这里的结点可以理解为hash值相同组成的链表的头结点 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; //fh〉0 说明这个节点是一个链表的节点 不是树的节点 if (fh &gt;= 0) &#123; binCount = 1; //在这里遍历链表所有的结点 for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; //如果hash值和key值相同 则修改对应结点的value值 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; //如果遍历到了最后一个结点，那么就证明新的节点需要插入 就把它插入在链表尾部 if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; //如果这个节点是树节点，就按照树的方式插入值 else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; //如果链表长度已经达到临界值8 就需要把链表转换为树结构 if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; //将当前ConcurrentHashMap的元素数量+1 addCount(1L, binCount); return null; &#125; 还有就是关于size和扩容的操作，扩容是要复制表的，这个过程要考虑到线程的安全性问题，当然可以简单的单线程一步一步复制，但它是支持了多线程复制的。源码瞄了一两眼实在难看。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring重点归纳]]></title>
    <url>%2F2019%2F04%2F22%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[佛了 计算机网络知识一、TCP/IP物理层：主要解决对接的标准，网络信号的传输，信道的多效利用 数据链路层：1、打包成贞、透明传输、可靠传输、差错检验。。。。。给资源加上MAC地址 网络层一、IP协议IP协议是TCP/IP协议的核心，所有的TCP，UDP，IMCP，IGMP的数据都以IP数据格式传输。要注意的是，IP不是可靠的协议，这是说，IP协议没有提供一种数据未传达以后的处理机制，这被认为是上层协议：TCP或UDP要做的事情。每个计算机都有为一的IP地址 TTL字段。这个字段规定该数据包在穿过多少个路由之后才会被抛弃。某个IP数据包每穿过一个路由器，该数据包的TTL数值就会减少1，当该数据包的TTL成为零，它就会被自动抛弃。 这个字段的最大值也就是255，也就是说一个协议包也就在路由器里面穿行255次就会被抛弃了，根据系统的不同，这个数字也不一样，一般是32或者是64。 二、ARP协议（地址解析协议）这个协议是为IP协议服务的： 做三件事：先查开目的的IP地址在自己的ARP高速缓存（就是一个IP-MAC地址对应表缓存）。 ​ 没有的话就会在自己的局域网中发广播获取目标IP的MAC地址 ​ 没有的话，就会发给网关路由器，等到MAC地址。 描述RARP协议答:RARP是逆地址解析协议，作用是完成硬件地址到IP地址的映射，主要用于无盘工作站，因为给无盘工作站配置的IP地址不能保存。工作流程：在网络中配置一台RARP服务器，里面保存着IP地址和MAC地址的映射关系，当无盘工作站启动后，就封装一个RARP数据包，里面有其MAC地址，然后广播到网络上去，当服务器收到请求包后，就查找对应的MAC地址的IP地址装入响应报文中发回给请求者。因为需要广播请求报文，因此RARP只能用于具有广播能力的网络。 三、ICMP协议（网络控制报文协议）IP协议并不是一个可靠的协议，它不保证数据被送达，那么，自然的，保证数据送达的工作应该由其他的模块来完成。其中一个重要的模块就是ICMP(网络控制报文)协议。ICMP不是高层协议，而是IP层的协议。 当传送IP数据包发生错误。比如主机不可达，路由不可达等等，ICMP协议将会把错误信息封包，然后传送回给主机。给主机一个处理错误的机会，这 也就是为什么说建立在IP层以上的协议是可能做到安全的原因。 ​ 网络层两个应用： pingping可以说是ICMP的最著名的应用，是TCP/IP协议的一部分。利用“ping”命令可以检查网络是否连通，可以很好地帮助我们分析和判定网络故障。 ping这个单词源自声纳定位，而这个程序的作用也确实如此，它利用ICMP协议包来侦测另一个主机是否可达。原理是用类型码为0的ICMP发请 求，受到请求的主机则用类型码为8的ICMP回应。 ping程序来计算间隔时间，并计算有多少个包被送达。用户就可以判断网络大致的情况。我们可以看到， ping给出来了传送的时间和TTL的数据。 TracerouteTraceroute是用来侦测主机到目的主机之间所经路由情况的重要工具，也是最便利的工具。 Traceroute的原理是非常非常的有意思，它收到到目的主机的IP后，首先给目的主机发送一个TTL=1的UDP数据包，而经过的第一个路由器收到这个数据包以后，就自动把TTL减1，而TTL变为0以后，路由器就把这个包给抛弃了，并同时产生 一个主机不可达的ICMP数据报给主机。主机收到这个数据报以后再发一个TTL=2的UDP数据报给目的主机，然后刺激第二个路由器给主机发ICMP数据 报。如此往复直到到达目的主机。这样，traceroute就拿到了所有的路由器IP。 传输层TCP/UDP一个面向连接、可靠传输、面向字节流、能流量控制和阻塞控制，全双工。 TCP对应的协议：（1） FTP：定义了文件传输协议，使用21端口。（2） Telnet：一种用于远程登陆的端口，使用23端口，用户可以以自己的身份远程连接到计算机上，可提供基于DOS模式下的通信服务。（3） SMTP：邮件传送协议，用于发送邮件。服务器开放的是25号端口。（4） POP3：它是和SMTP对应，POP3用于接收邮件。POP3协议所用的是110端口。（5）HTTP：是从Web服务器传输超文本到本地浏览器的传送协议。 一个不连接、不可靠、面向报文、不能流量控制和阻塞控制，一对一、一对多、多对多、多对一，速度快。 UDP对应的协议：（1） DNS：用于域名解析服务，将域名地址转换为IP地址。DNS用的是53号端口。（2） SNMP：简单网络管理协议，使用161号端口，是用来管理网络设备的。由于网络设备很多，无连接的服务就体现出其优势。（3） TFTP(Trival File Transfer Protocal)，简单文件传输协议，该协议在熟知端口69上使用UDP服务。 TCP三次握手第一次握手： 建立连接。客户端发送连接请求报文段，将SYN位置为1，Sequence Number为x；然后，客户端进入SYN_SEND状态，等待服务器的确认； 第二次握手： 服务器收到SYN报文段。服务器收到客户端的SYN报文段，需要对这个SYN报文段进行确认，设置Acknowledgment Number为x+1(Sequence Number+1)；同时，自己自己还要发送SYN请求信息，将SYN位置为1，Sequence Number为y；服务器端将上述所有信息放到一个报文段（即SYN+ACK报文段）中，一并发送给客户端，此时服务器进入SYN_RECV状态； 第三次握手： 客户端收到服务器的SYN+ACK报文段。然后将Acknowledgment Number设置为y+1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。 为什么要三次握手？ 主要是第三次握手的存在，避免了服务端等待确认的资源浪费， 为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。 具体例子：“已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。” 四次分手第一次分手： 主机1（可以使客户端，也可以是服务器端），设置Sequence Number，向主机2发送一个FIN报文段；此时，主机1进入FIN_WAIT_1状态；这表示主机1没有数据要发送给主机2了； 第二次分手： 主机2收到了主机1发送的FIN报文段，向主机1回一个ACK报文段，Acknowledgment Number为Sequence Number加1；主机1进入FIN_WAIT_2状态；主机2告诉主机1，我“同意”你的关闭请求； 第三次分手： 主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入LAST_ACK状态； 第四次分手： 主机1收到主机2发送的FIN报文段，向主机2发送ACK报文段，然后主机1进入TIME_WAIT状态；主机2收到主机1的ACK报文段以后，就关闭连接；此时，主机1等待2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，主机1也可以关闭连接了。 为什么要四次分手？ TCP协议是一种面向连接的、可靠的、基于字节流的运输层通信协议。TCP是全双工模式，这就意味着，当主机1发出FIN报文段时，只是表示主机1已经没有数据要发送了，主机1告诉主机2，它的数据已经全部发送完毕了；但是，这个时候主机1还是可以接受来自主机2的数据；当主机2返回ACK报文段时，表示它已经知道主机1没有数据发送了，但是主机2还是可以发送数据到主机1的；当主机2也发送了FIN报文段时，这个时候就表示主机2也没有数据要发送了，就会告诉主机1，我也没有数据要发送了，之后彼此就会愉快的中断这次TCP连接。 为什么要等待2MSL？ MSL：报文段最大生存时间，它是任何报文段被丢弃前在网络内的最长时间。 原因有二： 保证TCP协议的全双工连接能够可靠关闭 保证这次连接的重复数据段从网络中消失 第一点：如果主机1直接CLOSED了，那么由于IP协议的不可靠性或者是其它网络原因，导致主机2没有收到主机1最后回复的ACK。那么主机2就会在超时之后继续发送FIN，此时由于主机1已经CLOSED了，就找不到与重发的FIN对应的连接。所以，主机1不是直接进入CLOSED，而是要保持TIME_WAIT，当再次收到FIN的时候，能够保证对方收到ACK，最后正确的关闭连接。 第二点：如果主机1直接CLOSED，然后又再向主机2发起一个新连接，我们不能保证这个新连接与刚关闭的连接的端口号是不同的。也就是说有可能新连接和老连接的端口号是相同的。一般来说不会发生什么问题，但是还是有特殊情况出现：假设新连接和已经关闭的老连接端口号是一样的，如果前一次连接的某些数据仍然滞留在网络中，这些延迟数据在建立新连接之后才到达主机2，由于新连接和老连接的端口号是一样的，TCP协议就认为那个延迟的数据是属于新连接的，这样就和真正的新连接的数据包发生混淆了。所以TCP连接还要在TIME_WAIT状态等待2倍MSL，这样可以保证本次连接的所有数据都从网络中消失。 TCP流量控制主要是借助 rwnd,接受端通过不断地响应rwnd的大小给接受端来实现流量的控制 发送窗口时不会大于接受窗口的。 TCP拥塞控制拥塞控制是有一个 cwnd, 拥塞窗口，这是发送端发送数据的窗口， 发送模拟：1、慢开始：发送的第一个数据只有一个包，cwnd的大小为1，如果能够顺利响应 ​ 2、继续满开始的节奏，成指数增长窗口的大小。 ​ 3、然后增长会到达一个慢增长限制 12345为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个慢开始门限ssthresh状态变量。慢开始门限ssthresh的用法如下： 当 cwnd &lt; ssthresh 时，使用上述的慢开始算法。 当 cwnd &gt; ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。 当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞控制避免算法。 ​ 4、接着只会进行，cwnd一个一个的增长 ​ 5、知道增大到某一个值，发生了阻塞，丢包了， ​ 就会向调整 ssthresh等于 档期cwnd大小的一半，然后cwnd的大小回到1，重新慢增长。 快重传 问题：（因为报文是每隔多少 响应一次的，比如M5才会响应，M3丢了，那么要等到M5，传好了之后才响应M3丢了） 快重传算法首先要求接收方每收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时才进行捎带确认。 接收方收到了M1和M2后都分别发出了确认。现在假定接收方没有收到M3但接着收到了M4。 显然，接收方不能确认M4，因为M4是收到的失序报文段。根据 可靠传输原理，接收方可以什么都不做，也可以在适当时机发送一次对M2的确认。 但按照快重传算法的规定，接收方应及时发送对M2的重复确认，这样做可以让 发送方及早知道报文段M3没有到达接收方。发送方接着发送了M5和M6。接收方收到这两个报文后，也还要再次发出对M2的重复确认。这样，发送方共收到了 接收方的四个对M2的确认，其中后三个都是重复确认。 快重传算法还规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段M3，而不必 继续等待M3设置的重传计时器到期。 由于发送方尽早重传未被确认的报文段，因此采用快重传后可以使整个网络吞吐量提高约20%。 快恢复 问题：报文的丢失，可能不是网络拥塞的问题，那么当三个重复确认连续收到，说明网络没有阻塞，没有必要再从1满开始。所以有了快恢复。 与快重传配合使用的还有快恢复算法，其过程有以下两个要点： 当发送方连续收到三个重复确认，就执行“乘法减小”算法，把慢开始门限ssthresh减半。 与慢开始不同之处是现在不执行慢开始算法（即拥塞窗口cwnd现在不设置为1），而是把cwnd值设置为 慢开始门限ssthresh减半后的数值，然后开始执行拥塞避免算法（“加法增大”），使拥塞窗口缓慢地线性增大。]]></content>
      <categories>
        <category>计算机基础</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式简单的思考]]></title>
    <url>%2F2019%2F04%2F20%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%AE%80%E5%8D%95%E7%9A%84%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[这几天学习的几种设计模式，其实学习的和肤浅，我平时做的东西也很少达到要用设计模式的地步，只是对他们有个初步的认识。 面向对象设计原则1.开闭原则 - Open Close Principle（OCP） 一个软件实体如类、模块和函数应该对扩展开放，对修改关闭 功能的扩展应该是定义新的类，而不是对原有的类进行修改 2.单一职责原则 - Single Responsibility Principle（SRP） 不要存在多于一个导致类变更的原因 3.里士替换原则 - Liskov Substitution Principle（LSP） 定义一：所有引用基类的地方必须能透明地使用其子类的对象。 定义二：如果对每一个类型为 T1的对象 o1，都有类型为 T2 的对象o2，使得以 T1定义的所有程序 P 在所有的对象 o1 都代换成 o2 时，程序 P 的行为没有发生变化，那么类型 T2 是类型 T1 的子类型。 4.依赖倒置原则 - Dependence Inversion Principle（DIP） 高层模块不应该依赖低层模块，二者都应该依赖其抽象；抽象不应该依赖细节，细节应该依赖抽象。 5.接口隔离原则 - Interface Segration Principle（ISP） 定义一：客户端不应该依赖它不需要的接口 定义二：类间的依赖关系应该建立在最小的接口上 6.迪米特法则/最少知道原则 - Law of Demeter or Least Knowledge Principle（LoD or LKP） 一个对象应该对其他对象保持最少的了解 这个原理的名称来源于希腊神话中的农业女神，孤独的得墨忒耳。 一、创建者模型单例模式：一个类只有一个对象： 数据库连接池，windows的任务管理器，配置文件加载器，spring的bean也是单例,springmvc，网站技术器都是单例 单例模式优点：只有一个实例减少系统的开销， 实现：饿汉模式，懒汉模式，静态内部类和局部静态块，枚举单例，双重检验锁， CountDownLatch,等待其他线程执行完自己才结束，可以和join一样。就像一个技术器，一个线程执行完毕就让它减一，可以去调用CountDownLatch.await让主线程等待。 工厂模式： 简单工厂模式 简单工厂对功能的拓展是需要对类修改的，那么就违背了acp（开闭原则）。 工厂方法模式 工厂方法模式满足了acp,但是造成了很多类增加了代码的复杂度，在生产的实际中反而简单工厂使用的更多 抽象工厂模式 建造者模式需要构建很多的零件一个复杂的类，我们需要构造（Builder）很多零件，还需要组装成（Director)一个复杂的对象。 通常建造者模式是和工厂模式搭配使用的。 定义一个类，这个类需要有其他几个类组成 定义一构建者接口，定义创建组件的方法。定义一个组装者接口，返回那个复杂的类 实现构建者接口重写构建零件方法，通常这里可以和工厂模式结合，用简单工厂模式来实现各个零件的构建 实现组装者接口，组装者需要传入一个构建者，调用构建者构建零件的方法获得零件，由零件set来组成复杂类 代理模式静态代理 代理类包含被代理的类，其他行为代理类完成，关键步骤调用真实类完成 代理对象需要我们自己取定义，相对繁琐不灵活。 动态代理 动态的去生成我们的代理类， 生成这个代理类需要一个，handler 1234567891011121314151617public class StarHandler implements InvocationHandler &#123; Star star; public StarHandler(Star star) &#123; this.star = star; &#125; //重写invoke方法，以后动态生成的代理的对象都会来执行这个方法。method.incoke是又返回对象的。 @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; method.invoke(star, args); return null; &#125;&#125;//而动态生成代理的方法其实是反射的过程，需要类加载器，被代理类的Class信息，并且有一个处理器 Star proxy= (Star) Proxy.newProxyInstance(ClassLoader.getSystemClassLoader(), new Class[]&#123;Star.class&#125;,handler); 桥接模式类与类之间的继承关系比较多，比如有一个电脑接口，下面有台式、笔记本、平板，下面又有联想、戴尔、神州。 这样不应该设置成联想台式、联想笔记本，这样不符合类的单一指责原则。 这个时候应该用桥接模式：定义品牌接口和样式接口， 桥接模式是典型的多对多的类的交互问题。 装饰模式装饰模式是一个对功能扩展常用的模式。 比如我现在有一个car类，下面可能有飞的car，智能car，水上漂的car，然后他们直接又可以组合，既可以飞又智能，这样如果没个不同类型的功能都定义一个子类，会让子类迅速膨胀。 那么需要装饰模式，装饰模式有一个关键点就是装饰者，装饰者持有最基本的cart这个对象，然后然一些单一功能的继承这个装饰者，去分别实现它们单一增加的功能。如果要组合的时候只要将一个功能的car传给另一个功能的car进行组合，就能实现功能的组合扩展。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455//定义顶级接口public interface Icar &#123; void move();&#125;//实现类，实现最基本的功能class Car implements Icar&#123; @Override public void move() &#123; System.out.println("路上跑"); &#125;&#125;//装饰者，持有基本类的实现class SuCar implements Icar&#123; Icar car; public SuCar(Icar car) &#123; super(); this.car = car; &#125; @Override public void move() &#123; car.move(); &#125;&#125;//具体实现功能扩展的装饰好的class WortCar extends SuCar&#123; public WortCar(Icar car) &#123; super(car); &#125; //功能扩展 public void extend() &#123; System.out.println("水上漂"); &#125; @Override public void move() &#123; super.move(); extend(); &#125;&#125;class FlyCar extends SuCar&#123; public FlyCar(Icar car) &#123; super(car); &#125; //功能扩展 public void extend() &#123; System.out.println("天上飞"); &#125; @Override public void move() &#123; super.move(); extend(); &#125;&#125; 我们的io就是装饰模式的一种，装饰模式和桥接模式看上去很相似，都是去避免定义过多的类。 但实际它们解决的问题是不一样的，桥接是桥接类与类直接的组合关系，在多继承的情况下解决类组合复杂的问题。 而装饰模式是不能功能的扩展导致过多的定义类，是对新功能的扩展性问题。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring重点归纳]]></title>
    <url>%2F2019%2F04%2F18%2Fspring%E9%87%8D%E7%82%B9%E5%BD%92%E7%BA%B3%2F</url>
    <content type="text"><![CDATA[为什么会乱啊 iocioc：控制反转 比如有一个类，在类里面有方法（不是静态的方法），调用类里面的方法，创建类的对象，使用对象调用方法，创建类对象的过程，需要new出来对象 把对象的创建不是通过new方式实现，而是交给spring配置创建类对象 ioc底层原理使用技术 （1）xml配置文件：在xml中配置类信息，类名和类路径。 （2）dom4j解析xml：解析xml获取类信息 （3）工厂设计模式 和反射：这两个应该是结合的，工厂模式的设计理念，工厂制造bean的机制是反射。 Bean标签常用属性 id属性：定义的名称，id属性值名称任意命名 id属性值，不能包含特殊符号 根据id值得到配置对象 class属性：创建对象所在类的全路径 name属性：功能和id属性一样的，id属性值不能包含特殊符号，但是在name属性值里面可以包含特殊符号老版本为兼容struts1的name属性，现在基本只是用id属性 scope属性 singleton：默认值，单例（重点） prototype：多例（用在配置action）（重点） 1&lt;bean id="user" class="me.test.ioc.User" scope="singleton"&gt;&lt;/bean&gt; DL依赖注入： 依赖：一个类需要用到另一个类，而往往我们需要去new另外一个类，这样就增加了耦合。就需要注入 注入：通过setter方法进行另一个对象实例设置。 例如：l 例如： ​ class BookServiceImpl{ ​ //之前开发：接口 = 实现类 （service和dao耦合） ​ //private BookDao bookDao = new BookDaoImpl(); //spring之后 （解耦：service实现类使用dao接口，不知道具体的实现类） ​ private BookDao bookDao; ​ setter（BookDao bookDao) 方法，传入一个bookDao实现注入。 } ​ 模拟spring执行过程 ​ 创建service实例：BookService bookService = new BookServiceImpl() –&gt;IoC ​ 创建dao实例：BookDao bookDao = new BookDaoImple() –&gt;IoC ​ 将dao设置给service：bookService.setBookDao(bookDao); –&gt;DI 12345678910111213141516171819&lt;!-- 模拟spring执行过程 创建service实例：BookService bookService = new BookServiceImpl() IoC &lt;bean&gt; 创建dao实例：BookDao bookDao = new BookDaoImpl() IoC 将dao设置给service：bookService.setBookDao(bookDao); DI &lt;property&gt; &lt;property&gt; 用于进行属性注入 name： bean的属性名，通过setter方法获得 setBookDao ##&gt; BookDao ##&gt; bookDao ref ：另一个bean的id值的引用 --&gt;&lt;!-- 创建service --&gt;&lt;bean id="bookServiceId" class="com.itheima.b_di.BookServiceImpl"&gt; &lt;property name="bookDao" ref="bookDaoId"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 创建dao实例 --&gt;&lt;bean id="bookDaoId" class="com.itheima.b_di.BookDaoImpl"&gt;&lt;/bean&gt; 属性的注入我们都知道，一个类的私有属性其他人想去对其定义，通常有两种方法 一种是在构造这个类的对象的时候就传入相关的属性信息 还有一种是通过setter方法来传入属性 比如一个类: 1234567891011121314class Persen&#123; private String name; private int age; public Persen (String name,int age)&#123; this.age=age; this.name=name &#125; public void setName(String name)&#123; this.name=name; &#125; public void setAge(int age)&#123; this.age=age; &#125;&#125; 这个类提供了公共的构造方法和 set方法，这都是可以对对象属性的进行定义的，那么如果这个类的实例化交给了sping容器来完成，它是怎么实现这两种属性的注入的呢。 构造方法 12345678910111213141516171819&lt;!-- 构造方法注入 * &lt;constructor-arg&gt; 用于配置构造方法一个参数argument name ：参数的名称 value：设置普通数据 ref：引用数据，一般是另一个bean id值 index ：参数的索引号，从0开始 。如果只有索引，匹配到了多个构造方法时，默认使用第一个。 type ：确定参数类型 例如：使用名称name &lt;constructor-arg name="username" value="jack"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name="age" value="18"&gt;&lt;/constructor-arg&gt; 例如2：【类型type 和 索引 index】 &lt;constructor-arg index="0" type="java.lang.String" value="1"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg index="1" type="java.lang.Integer" value="2"&gt;&lt;/constructor-arg&gt;--&gt;&lt;bean id="userId" class="com.itheima.f_xml.a_constructor.User" &gt; &lt;constructor-arg index="0" type="java.lang.String" value="1"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg index="1" type="java.lang.Integer" value="2"&gt;&lt;/constructor-arg&gt;&lt;/bean&gt; set方法：类的注入也是用set方法 123456789101112131415161718192021222324252627282930313233&lt;!-- setter方法注入 * 普通数据 &lt;property name="" value="值"&gt; 等效 &lt;property name=""&gt; &lt;value&gt;值 * 引用数据 &lt;property name="" ref="另一个bean"&gt; 等效 &lt;property name=""&gt; &lt;ref bean="另一个bean"/&gt; --&gt; &lt;bean id="personId" class="com.itheima.f_xml.b_setter.Person"&gt; &lt;property name="pname" value="阳志"&gt;&lt;/property&gt; &lt;property name="age"&gt; &lt;value&gt;1234&lt;/value&gt; &lt;/property&gt; &lt;property name="homeAddr" ref="homeAddrId"&gt;&lt;/property&gt; &lt;property name="companyAddr"&gt; &lt;ref bean="companyAddrId"/&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id="homeAddrId" class="com.itheima.f_xml.b_setter.Address"&gt; &lt;property name="addr" value="阜南"&gt;&lt;/property&gt; &lt;property name="tel" value="911"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id="companyAddrId" class="com.itheima.f_xml.b_setter.Address"&gt; &lt;property name="addr" value="北京八宝山"&gt;&lt;/property&gt; &lt;property name="tel" value="120"&gt;&lt;/property&gt; &lt;/bean&gt; 当然还可以注入一些复杂的数据，比如集合，链表等等，它们的注入就是在标签下面再加上对应的结构标签。 name：注入属性的名字 ref：注入的类id value：注入普通的值 IOC和Dl区别 IOC：控制反转，把对象创建交给spring进行配置 DI：依赖注入，向类里面的属性中设置值 关系：依赖注入不能单独存在，需要在IOC基础之上完成操作 其实这个区别的化还是没什么好说的，更重要的是明白这两个东西，我觉得不是一个类型的。 AOP原理AOP术语 Joinpoint(连接点): 类里面可以被增强的方法，这些方法称为连接点 Pointcut(切入点):所谓切入点是指我们要对哪些Joinpoint进行拦截的定义 Advice(通知/增强):所谓通知是指拦截到Joinpoint之后所要做的事情就是通知.通知分为前置通知,后置通知,异常通知,最终通知,环绕通知(切面要完成的功能) Aspect(切面): 是切入点和通知（引介）的结合 Introduction(引介):引介是一种特殊的通知在不修改类代码的前提下, Introduction可以在运行期为类动态地添加一些方法或Field Target(目标对象):代理的目标对象(要增强的类) Weaving(织入):是把增强应用到目标的过程把advice 应用到 target的过程 Proxy（代理）:一个类被AOP织入增强后，就产生一个结果代理类 AOP中文名就是切面编程，前面编程有三个关键点 一个是我们要被切的基本业务类，也就是目标对象 一个是通知增强的类，就是要对我们的目标类进行前后异常操作的。 还有一个就是把它们结合其他的形成的切面了，一个类被AOP增强之后就会形成一个它的代理类，这个代理类不仅仅有目标类的方法，还有增强类的方法，并且能让增强类方法在合适的位置出现。 spring是用cglib字节码操作，结合代理模式和工厂模式和反射实现。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//目标类public class MyService implements Service&#123; public void service()&#123; System.out.println("服务业务被调用"); &#125;&#125;//切入类public class MyAspect &#123; public void before()&#123; System.out.println("前方法"); &#125; public void after()&#123; System.out.println("后方法"); &#125;&#125;//结合类public class MyBeanFactory &#123; public static MyService createService()&#123; final MyAspect aspect=new MyAspect(); final MyService service=new MyService(); Enhancer enhancer = new Enhancer(); //确定父类 enhancer.setSuperclass(MyService.class); /* 设置回调函数 , MethodInterceptor接口 等效 jdk InvocationHandler接口 * intercept() 等效 jdk实现代理模式的 invoke() * 参数1、参数2、参数3：以invoke一样 * 参数4：methodProxy 方法的代理 */ enhancer.setCallback((MethodInterceptor) (o, method, objects, methodProxy) -&gt; &#123; aspect.before(); //两种调用业务的方法1、2. //1、执行目标类的方法 Object objet=method.invoke(service,objects); //2、执行代理类的父类 ，执行目标类 （目标类和代理类 父子关系） methodProxy.invokeSuper(o,objects); aspect.after(); return objet; &#125;); //创建代理 MyService proxService = (MyService) enhancer.create(); return proxService; &#125;&#125; 这种代理模式也可以用JDK自带的反射包的proxy和invokhandler实现 12345678910111213141516public class MyBeanFactorybyjdk &#123; public static Service createService() &#123; MyAspect aspect = new MyAspect(); Service service = new MyService(); Service serviceProxy = (Service) Proxy.newProxyInstance( service.getClass().getClassLoader(), service.getClass().getInterfaces(), (InvocationHandler) (proxy, method, args) -&gt; &#123; aspect.before(); Object object=method.invoke(service,args); aspect.after(); return object; &#125;); return serviceProxy; &#125;&#125; spring通过配置实现AOP这个工厂肯定不是我们手写的，因为spring天生就是来创建bean的，实现AOP我们只要编写好我们的目标类和切入类，讲它们放入spring容器，然后将他们相切，怎么切呢 12345678910111213141516171819202122232425262728293031323334353637&lt;!-- 3 aop编程 3.1 导入命名空间 3.2 使用 &lt;aop:config&gt;进行配置 proxy-target-class="true" 声明时使用cglib代理 &lt;aop:pointcut&gt; 切入点 ，从目标对象获得具体方法 &lt;aop:advisor&gt; 特殊的切面，只有一个通知 和 一个切入点 advice-ref 通知引用 pointcut-ref 切入点引用 3.3 切入点表达式（重要） execution(* com.itheima.c_spring_aop.*.*(..)) 选择方法 返回值任意 包 类名任意 方法名任意 参数任意 --&gt; &lt;!-- 1 创建目标类 --&gt; &lt;bean id="userServiceId" class="路径"&gt;&lt;/bean&gt; &lt;!-- 2 创建切面类（通知） --&gt; &lt;bean id="myAspectId" class="路径"&gt;&lt;/bean&gt;&lt;aop:config&gt;方法1： &lt;aop:pointcut expression="切入点表达式" id=""&gt; &lt;aop:advisor advice-ref="通知引用" pointcut-ref="切入点的引用"&gt;方法2： &lt;aop:advisor advice-ref="通知引用" pointcut="切入点表达式"&gt;&lt;/aop:config&gt; &lt;!--AspectJ xml--&gt;&lt;aop:config&gt; &lt;aop:aspect ref="切面类"&gt; &lt;aop:pointcut expression="切入点表达式" id=""&gt; &lt;aop:before&gt; 前置 &lt;aop:afterReturning returning="第二个参数名称"&gt; 后置 &lt;aop:around&gt; 环绕 &lt;aop:afterThrowing throwing="第二。。。"&gt; 抛出异常 &lt;aop:after&gt; 最终 AspectJ 是AOP实现的一个框架，整合到了spring中，前面aop:advisor 特殊的切面，只有一个通知 和 一个切入点，那么如果我有多个需要切入的点或者说我要在这个切入点的不能位置进行操作，那么就需要AspectJ，如上面配置，它实现了五个位置对切入点的操作。 明天继续复习事务———— 明天到来了 spring事务1.1 回顾事务l 事务：一组业务操作ABCD，要么全部成功，要么全部不成功。 l 特性：ACID ​ 原子性：整体 ​ 一致性：完成 ​ 隔离性：并发 ​ 持久性：结果 l 隔离问题： ​ 脏读：一个事务读到另一个事务没有提交的数据 ​ 不可重复读：一个事务读到另一个事务已提交的数据（update） ​ 虚读(幻读)：一个事务读到另一个事务已提交的数据（insert） l 隔离级别： ​ read uncommitted：读未提交。存在3个问题 ​ read committed：读已提交。解决脏读，存在2个问题 ​ repeatable read：可重复读。解决：脏读、不可重复读，存在1个问题。 ​ serializable ：串行化。都解决，单事务。 l PlatformTransactionManager 平台事务管理器，spring要管理事务，必须使用事务管理器 ​ 进行事务配置时，必须配置事务管理器。 l TransactionDefinition：事务详情（事务定义、事务属性），spring用于确定事务具体详情， ​ 例如：隔离级别、是否只读、超时时间 等 ​ 进行事务配置时，必须配置详情。spring将配置项封装到该对象实例。 l TransactionStatus：事务状态，spring用于记录当前事务运行状态。例如：是否有保存点，事务是否完成。 ​ spring底层根据状态进行相应操作。 AOP是事务的基础]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis学习心得]]></title>
    <url>%2F2019%2F04%2F17%2FLinux%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[简单罗列一些Linux和jvm性能分析的工具和命令、 Linux性能分析命令 top(整机）：（uptime)：查开整机性能，cup和load average（平局超过0.6）就比较高了 vmstat -n 2 3（cpu) : 看procs: 轮转进程数 cpu ：us+sy mpstat pidstat。 free（内存）: free m free g（后面是单位，兆还是g） df（硬盘）: iostat（磁盘io) ： ifstat（网络io）： pidstat：查看具体进程号对应信息： pidstat -r -p 13084 1 pidstat命令指定采样周期和采样次数，命令形式为”pidstat [option] interval [count]”，以下pidstat输出以2秒为采样周期，输出10次cpu使用统计信息： cpu使用情况统计(-u) 内存使用情况统计(-r) IO情况统计(-d) JVM性能分析工具 jps （虚拟机进程）like ps jstat （统计信息监视）like pidstat，可以查看进程的某种信息，比如-gc -gcold jinfo（配置信息） jmap (堆内存，dump heap，查看进程堆信息) jstack（堆栈跟踪工具） jhat （堆转储快照分析） CUP占用过高： ​ 分析流程: top==&gt;找到哪个程序，记录pid ​ 用 jps -l 或者 ps -ef | grep -v grep 得到进程 id ​ ps -mp 进程id -o THREAD，tid,time 得到线程 id （-m 显示所有线程，-p进程号，-o 用户自定义格式） ​ 线程id变成16 进制 或者用 ”printf “%x\n” ​ jstack 进程号 | grep (16进制线程号) -A60]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis学习心得]]></title>
    <url>%2F2019%2F04%2F17%2Fredis%E5%AD%A6%E4%B9%A0%E5%BF%83%E5%BE%97%2F</url>
    <content type="text"><![CDATA[学习redis已经有几天了，主要都是断断续续的，这几天看Java高级知识也花了很多时间，今天来给redis的一些知识点做一下总结回顾。 redis是什么介绍Redis之前，先了解下NoSQL （Not noly SQL）不仅仅是SQL 属于非关系型数据库；Redis就属于非关系型数据库 传统的Mysql ,oracle ,sql server 等 都是关系型数据库 redis是基于内存的，单线程操作的，多路IO(NIO)复用的，key value型缓存数据库。 为什么要学redis为什么需要NoSQL，主要应对以下问题，传统关系型数据库力不从心 High performance -高并发读写 Huge Storage-海量数据的高效率存储和访问 High Scalablility &amp;&amp; High Availability 高可扩展性和高可用性 redis主要的数据类型1.STRING redis的STRING十分神奇，它不单指字符串，还可以代表数值型数据，可以进行字符串以及数值的各种处理 2.LIST redis的列表，列表的每一个节点都包含了一个字符串 LIST可以从表头和表尾push和put数据，也可以根据偏移量对链表进行修剪（trim）；读取单个/多个元素，查询或者删除元素 3.SET 包含字符串的无序收集器，并且包含的每一个字符串都是唯一的 操作就是基本的增删改查，计算交集，并集以及差集，并且可以随机获取元素 4.ZSET 有序集合 字符串成员（member）与浮点数分值（sorce）之间的有序映射，元素排列顺序由分值决定 操作就是基本的增，查，删单个元素，获取分值范围内的或者成员来获取元素 5.HASH 包换键值对的无序列表 增，删，查单个键值对，获取所有键值对 redis一些高级特性【聊聊redis持久化 – 两种方式】 redis提供了两种持久化的方式，分别是RDB（Redis DataBase）和AOF（Append Only File）。 RDB，简而言之，就是在不同的时间点，将redis存储的数据生成快照并存储到磁盘等介质上； AOF，则是换了一个角度来实现持久化，那就是将redis执行过的所有写指令记录下来，在下次redis重新启动时，只要把这些写指令从前到后再重复执行一遍，就可以实现数据恢复了。 其实RDB和AOF两种方式也可以同时使用，在这种情况下，如果redis重启的话，则会优先采用AOF方式来进行数据恢复，这是因为AOF方式的数据恢复完整度更高。 如果你没有数据持久化的需求，也完全可以关闭RDB和AOF方式，这样的话，redis将变成一个纯内存数据库，就像memcache一样。 【聊聊redis持久化 – RDB】 RDB方式，是将redis某一时刻的数据持久化到磁盘中，是一种快照式的持久化方法。 redis在进行数据持久化的过程中，会先将数据写入到一个临时文件中，待持久化过程都结束了，才会用这个临时文件替换上次持久化好的文件。正是这种特性，让我们可以随时来进行备份，因为快照文件总是完整可用的。 对于RDB方式，redis会单独创建（fork）一个子进程来进行持久化，而主进程是不会进行任何IO操作的，这样就确保了redis极高的性能。 如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。 虽然RDB有不少优点，但它的缺点也是不容忽视的。如果你对数据的完整性非常敏感，那么RDB方式就不太适合你，因为即使你每5分钟都持久化一次，当redis故障时，仍然会有近5分钟的数据丢失。所以，redis还提供了另一种持久化方式，那就是AOF。 【聊聊redis持久化 – AOF】 AOF，英文是Append Only File，即只允许追加不允许改写的文件。 如前面介绍的，AOF方式是将执行过的写指令记录下来，在数据恢复时按照从前到后的顺序再将指令都执行一遍，就这么简单。 我们通过配置redis.conf中的appendonly yes就可以打开AOF功能。如果有写操作（如SET等），redis就会被追加到AOF文件的末尾。 默认的AOF持久化策略是每秒钟fsync一次（fsync是指把缓存中的写指令记录到磁盘中），因为在这种情况下，redis仍然可以保持很好的处理性能，即使redis故障，也只会丢失最近1秒钟的数据。 如果在追加日志时，恰好遇到磁盘空间满、inode满或断电等情况导致日志写入不完整，也没有关系，redis提供了redis-check-aof工具，可以用来进行日志修复。 因为采用了追加方式，如果不做任何处理的话，AOF文件会变得越来越大，为此，redis提供了AOF文件重写（rewrite）机制，即当AOF文件的大小超过所设定的阈值时，redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。举个例子或许更形象，假如我们调用了100次INCR指令，在AOF文件中就要存储100条指令，但这明显是很低效的，完全可以把这100条指令合并成一条SET指令，这就是重写机制的原理。 在进行AOF重写时，仍然是采用先写临时文件，全部完成后再替换的流程，所以断电、磁盘满等问题都不会影响AOF文件的可用性，这点大家可以放心。 AOF方式的另一个好处，我们通过一个“场景再现”来说明。某同学在操作redis时，不小心执行了FLUSHALL，导致redis内存中的数据全部被清空了，这是很悲剧的事情。不过这也不是世界末日，只要redis配置了AOF持久化方式，且AOF文件还没有被重写（rewrite），我们就可以用最快的速度暂停redis并编辑AOF文件，将最后一行的FLUSHALL命令删除，然后重启redis，就可以恢复redis的所有数据到FLUSHALL之前的状态了。是不是很神奇，这就是AOF持久化方式的好处之一。但是如果AOF文件已经被重写了，那就无法通过这种方法来恢复数据了。 虽然优点多多，但AOF方式也同样存在缺陷，比如在同样数据规模的情况下，AOF文件要比RDB文件的体积大。而且，AOF方式的恢复速度也要慢于RDB方式。 如果你直接执行BGREWRITEAOF命令，那么redis会生成一个全新的AOF文件，其中便包括了可以恢复现有数据的最少的命令集。 如果运气比较差，AOF文件出现了被写坏的情况，也不必过分担忧，redis并不会贸然加载这个有问题的AOF文件，而是报错退出。这时可以通过以下步骤来修复出错的文件： 1.备份被写坏的AOF文件 2.运行redis-check-aof –fix进行修复 3.用diff -u来看下两个文件的差异，确认问题点 4.重启redis，加载修复后的AOF文件 【聊聊redis持久化 – AOF重写】 AOF重写的内部运行原理，我们有必要了解一下。 在重写即将开始之际，redis会创建（fork）一个“重写子进程”，这个子进程会首先读取现有的AOF文件，并将其包含的指令进行分析压缩并写入到一个临时文件中。 与此同时，主工作进程会将新接收到的写指令一边累积到内存缓冲区中，一边继续写入到原有的AOF文件中，这样做是保证原有的AOF文件的可用性，避免在重写过程中出现意外。 当“重写子进程”完成重写工作后，它会给父进程发一个信号，父进程收到信号后就会将内存中缓存的写指令追加到新AOF文件中。 当追加结束后，redis就会用新AOF文件来代替旧AOF文件，之后再有新的写指令，就都会追加到新的AOF文件中了。 【聊聊redis持久化 – 如何选择RDB和AOF】 对于我们应该选择RDB还是AOF，官方的建议是两个同时使用。这样可以提供更可靠的持久化方案。 【聊聊主从 – 用法】 像MySQL一样，redis是支持主从同步的，而且也支持一主多从以及多级从结构。 主从结构，一是为了纯粹的冗余备份，二是为了提升读性能，比如很消耗性能的SORT就可以由从服务器来承担。 redis的主从同步是异步进行的，这意味着主从同步不会影响主逻辑，也不会降低redis的处理性能。 主从架构中，可以考虑关闭主服务器的数据持久化功能，只让从服务器进行持久化，这样可以提高主服务器的处理性能。 在主从架构中，从服务器通常被设置为只读模式，这样可以避免从服务器的数据被误修改。但是从服务器仍然可以接受CONFIG等指令，所以还是不应该将从服务器直接暴露到不安全的网络环境中。如果必须如此，那可以考虑给重要指令进行重命名，来避免命令被外人误执行。 【聊聊主从 – 同步原理】 从服务器会向主服务器发出SYNC指令，当主服务器接到此命令后，就会调用BGSAVE指令来创建一个子进程专门进行数据持久化工作，也就是将主服务器的数据写入RDB文件中。在数据持久化期间，主服务器将执行的写指令都缓存在内存中。 在BGSAVE指令执行完成后，主服务器会将持久化好的RDB文件发送给从服务器，从服务器接到此文件后会将其存储到磁盘上，然后再将其读取到内存中。这个动作完成后，主服务器会将这段时间缓存的写指令再以redis协议的格式发送给从服务器。 另外，要说的一点是，即使有多个从服务器同时发来SYNC指令，主服务器也只会执行一次BGSAVE，然后把持久化好的RDB文件发给多个下游。在redis2.8版本之前，如果从服务器与主服务器因某些原因断开连接的话，都会进行一次主从之间的全量的数据同步；而在2.8版本之后，redis支持了效率更高的增量同步策略，这大大降低了连接断开的恢复成本。 主服务器会在内存中维护一个缓冲区，缓冲区中存储着将要发给从服务器的内容。从服务器在与主服务器出现网络瞬断之后，从服务器会尝试再次与主服务器连接，一旦连接成功，从服务器就会把“希望同步的主服务器ID”和“希望请求的数据的偏移位置（replication offset）”发送出去。主服务器接收到这样的同步请求后，首先会验证主服务器ID是否和自己的ID匹配，其次会检查“请求的偏移位置”是否存在于自己的缓冲区中，如果两者都满足的话，主服务器就会向从服务器发送增量内容。 增量同步功能，需要服务器端支持全新的PSYNC指令。这个指令，只有在redis-2.8之后才具有。 【聊聊redis的事务处理】 众所周知，事务是指“一个完整的动作，要么全部执行，要么什么也没有做”。 在聊redis事务处理之前，要先和大家介绍四个redis指令，即MULTI、EXEC、DISCARD、WATCH。这四个指令构成了redis事务处理的基础。 1.MULTI用来组装一个事务； 2.EXEC用来执行一个事务； 3.DISCARD用来取消一个事务； 4.WATCH用来监视一些key，一旦这些key在事务执行之前被改变，则取消事务的执行。 redis没有实际的事务的感念，这里的事务也不想关系型数据库里的事务那样。当在组装的时候某个语句组装没出错，比如取一个空key，那么在执行的时候也只有这一句是不行的。但在exec执行前就报出来语法错误则整个事务失败。 redis面试题Redis与Memcached的区别与比较1 、Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。memcache支持简单的数据类型，String。 2 、Redis支持数据的备份，即master-slave模式的数据备份。 3 、Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而Memecache把数据全部存在内存之中 4、 redis的速度比memcached快很多 5、Memcached是多线程，非阻塞IO复用的网络模型；Redis使用单线程的IO复用模型。 MySQL里有2000w数据，Redis中只存20w的数据，如何保证Redis中的数据都是热点数据（redis有哪些数据淘汰策略？？？）相关知识：redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略（回收策略）。redis 提供 6种数据淘汰策略： volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-enviction（驱逐）：禁止驱逐数据 lru算法是一种用hashmap和链表实现的算法，没使用一次就将数据放在链表的最后，要回收的时候就回收前面的。 Redis常见性能问题和解决方案:1、Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件2、如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次3、为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内4、尽量避免在压力很大的主库上增加从库]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java多线程（二）]]></title>
    <url>%2F2019%2F04%2F16%2FJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[继续Java多线程的学习，这一部分主要是书本上的Lock章节和Java多线程实现单例模式，以及最后一章补充知识的简单总结，后续我还会读Java并发编程艺术。好好学习Java的高级知识。 Java多线程（二）一、Lock在Java中实现线程的同步出了之前的synchronized同步锁的使用，在JDK1.5新增了ReentrantLock可以实现同样的效果，而且使用起来更加的灵活，新增了嗅探锁定和多路分支通知等功能。这个IPA属于Java的concurrent包。 学习之后我的感受是，这把锁像是在房间外我们给它加上的一把锁，什么时候锁上，什么时候不锁了都由我们说了算，而synchromized更像是线程自己把自己锁在了房间里，在里面做操作，只有当线程完了任务自己要出来了，才会把锁释放出去。 ReentrantLock 使用ReentrantLock实现线程的同步 1、定义Lock:private static Lock lock=new ReentrantLock(); 2、上锁：lock.lock(); 3、执行完了要释放锁：lock.unlock(); 这样就实现了线程的同步。ReentrantLock对象就像一个管理者，为线程上锁，为线程开锁。 12345678910111213141516171819202122232425public class ReentrantLock1 &#123; private static Lock lock=new ReentrantLock(); private static void menthdA()&#123; lock.lock(); for(int i=0;i&lt;10;i++)&#123; System.out.println("方法A被调用了"); &#125; lock.unlock(); &#125; private static void menthdB()&#123; lock.lock(); for(int i=0;i&lt;10;i++)&#123; System.out.println("方法B被调用了"); &#125; lock.unlock(); &#125; public static void main(String[] args)&#123; new Thread(()-&gt;&#123; menthdA(); &#125;).start(); new Thread(()-&gt;&#123; menthdB(); &#125;).start(); &#125;&#125; 使用Condition实现线程之间的等待/通知 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 用Condition实现等待通知: * 使用：1、private Condition condition=lock.newCondition(); 获得condition对象 * 2、lock.lock(); 一定要获得了锁，才能执行后面的方法进入等待 * 3、condition.await(),同时就会释放了锁。 * 4、condition.signal(); 其他线程调用signal唤醒等待线程 * 5、signal线程释放锁，lock.unlock(); 释放锁，让其他线程获得锁，因为signal不释放锁。 */public class Reentranlock2 &#123; private Lock lock=new ReentrantLock(); private Condition condition=lock.newCondition(); private void menthdA()&#123; try &#123; lock.lock(); System.out.println("方法A被调用了,现在时间="+System.currentTimeMillis()); condition.await(); System.out.println("A:我终于被唤醒了"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125; private void menthdB()&#123; try &#123; lock.lock(); System.out.println("方法B被调用了,现在时间="+System.currentTimeMillis()); condition.signal(); Thread.sleep(500); System.out.println("B:放你出去你也得先等我执行完"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; Reentranlock2 reentranlock2=new Reentranlock2(); new Thread(()-&gt;&#123; reentranlock2.menthdA(); &#125;).start(); Thread.sleep(2000); new Thread(()-&gt;&#123; reentranlock2.menthdB(); &#125;).start(); &#125;&#125; 生产者消费者模式的实现 实现这个模式的关键其实就是利用线程的等待通知机制，另外加上一个在变化的条件。 这里也一样当有多个生产者消费者是，需要全部唤起，condition也有一个signalAll，功能和notifyAll相似。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * 用Condition实现生产者消费者模式 * 实现两个线程交替打印。。。 */public class Reentranlock4 &#123; private boolean hasValue=false; private Lock lock=new ReentrantLock(); private Condition condition=lock.newCondition(); private void set() throws InterruptedException &#123; lock.lock(); while(hasValue)&#123; condition.await(); &#125; System.out.println("*********"); hasValue=true; condition.signal(); lock.unlock(); &#125; private void get() throws InterruptedException &#123; lock.lock(); while(!hasValue)&#123; condition.await(); &#125; System.out.println("------------"); hasValue=false; condition.signal(); lock.unlock(); &#125; public static void main(String[] args)&#123; Reentranlock4 reentranlock4=new Reentranlock4(); new Thread(()-&gt;&#123; for(int i=0;i&lt;50;i++)&#123; try &#123; reentranlock4.set(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); new Thread(()-&gt;&#123; for(int i=0;i&lt;50;i++)&#123; try &#123; reentranlock4.get(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125;&#125; 公平锁与非公平锁 这就是锁的ReentrantLock的两种形态，公平锁就是先到先得，也就是在main方法中先调用start会先获得锁，当然这不是绝对的，知识基本有序，而非公平锁就是和不排队，先后来都一样，一起抢锁。 123//再锁定义的时候可以确定它是什么锁，true公平锁，false非公平锁。Lock lock=new ReentrantLock(true);Lock lock=new ReentrantLock(false); ReentrantLock的一些其他方法 因为这把锁像我们管理者加的，所以我们在外面就能清晰的知道谁上锁了，谁没锁，谁在等，有没有人在等，线程是不是在等…..这样就有很多方法，我觉得这个不需要去记，因为API这么多哪里都记得住，只要知道有，有需要用的时候翻翻api就好。 ReentrantReadWriteLock​ ReentrantReadWriteLock有两把锁，一把读的锁，一把写的锁，当上的是读的锁，他们其他线程也是可以读的不可以写，但上的是写的锁，那么其他线程不能读不能写。 如何理解? ReentrantReadWriteLock按照字面意思是读写锁，如果你把它理解为对IO的控制，那就大错特错了（其实大多数人的直觉是这样）。其实你只要把它理解成一个数据库的事务锁就对了。 众所周知数据库事务锁的特点就是，读写分离。而ReentrantReadWriteLock是类似最高级的事务级别Serializable可串行化（严格讲比这个还更严谨）。什么意思呢，意思就是，对一条数据的更新操作只影响其它对该条数据的更新操作，而读操作是不影响的。 而并发锁Lock也好，synchronizy也好，是直接把读写都锁住的。就是说，该代码块一但锁住之后，既不能读也不能写。 但这样是有问题的，有些线程只是想读取一下数据，我又不改数据，你锁它干嘛呢？（类似事物吧） 所以ReentrantReadWriteLock把锁拆分成了读锁和写锁。 写锁之间的互斥的，但读锁不互斥（大家一起读数据么，压根就没冲突）。 但是有一点要注意。就是你想获取写锁，是除当前线程外，不能存在其它的读锁的。 好比就是说，我要改里面的数据了，那些获取了读锁的线程，必须通通退出来，否则会出现读到老数据的问题（类似事物里面的脏读） ，获取到写锁之后，其它线程也不能再获取到读锁了。 Lock和synchronized对比？1）Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现； 2）synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁； 3）Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断； 4）通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。 5）Lock可以提高多个线程进行读操作的效率。 6）在JDK1.5中，synchronized是性能低效的。因为这是一个重量级操作，它对性能最大的影响是阻塞式的实现，挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作给系统的并发性带来了很大的压力。相比之下使用Java提供的Lock对象，性能更高一些。 但是，JDK1.6，发生了变化，对synchronize加入了很多优化措施，有自适应自旋，锁消除，锁粗化，轻量级锁，偏向锁等等。导致在JDK1.6上synchronize的性能并不比Lock差。因此。提倡优先考虑使用synchronized来进行同步。 二、多线程与单例模式单例模式单例模式有两种加载模式： 立即加载/“饿汉模式”：当需要这个类的时候就立即加载出这个类的对象返回回去。 延迟加载/“懒汉模式”：对象的事例不会随着类的加载而马上事例化，而是真正调用某个方法的时候才去事例化。 这样一来，延迟加载的时候多个线程同时加载这个类，就会为每一个线程实例化一个对象，这就不符合单例模式的要求了。 后面介绍几种解决这种问题的方法 多线程实现单例的几种方法 直接上全锁，把真个建立事例对像的方法锁起来，但是效率低 DCL双检查锁机制 123456789101112131415161718private volatile static Danli danli; public static Danli getInstance()&#123; try &#123; if(danli!=null)&#123; return danli; &#125;else&#123; //模拟创建对象的准备工作 Thread.sleep(2000); synchronized (Danli.class)&#123; if(danli!=null)&#123; //再次检验，以确保等待之后是否有对象创建了 danli=new Danli(); &#125; &#125; return danli; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; 使用静态内部类 1234567891011public class Danli2 &#123; //利用静态内部类实现多线程的单例 private static class Help&#123; private volatile static Danli2 danli=new Danli2(); &#125; private Danli2()&#123; &#125; public static Danli2 getInstance()&#123; return Help.danli; &#125;&#125; 使用静态代码块 这两个我觉得是一个意思，利用类的初始化对静态资源只加载一次，下此要用的时候直接去方法区里面找的原则，所以只会有一个类的实例化对象. 123456789public class Danli2 &#123; private volatile static Danli2 danli=null; static &#123; danli=new Danli2(); &#125; public static Danli2 getInstance()&#123; return danli; &#125;&#125; 序列化和反序列化的单例模式的实现 问题：在遇到对象序列化，使用默认的运行方式和静态内置类的方法还是对出现多例 序列化：把对象转换为字节序列的过程称为对象的序列化。反序列化：把字节序列恢复为对象的过程称为对象的反序列化。 实现是借助io流操作，ObjectOutputStream、ObjectInputStream 123456789101112131415161718192021private static void serializeFlyPig() throws IOException &#123; FlyPig flyPig = new FlyPig(); flyPig.setColor("black"); flyPig.setName("naruto"); flyPig.setCar("0000"); // ObjectOutputStream 对象输出流，将 flyPig 对象存储到E盘的 flyPig.txt 文件中，完成对 flyPig 对象的序列化操作 ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(new File("d:/flyPig.txt"))); oos.writeObject(flyPig); System.out.println("FlyPig 对象序列化成功！"); oos.close(); &#125; /** * 反序列化 */ private static FlyPig deserializeFlyPig() throws Exception &#123; ObjectInputStream ois = new ObjectInputStream(new FileInputStream(new File("d:/flyPig.txt"))); FlyPig person = (FlyPig) ois.readObject(); System.out.println("FlyPig 对象反序列化成功！"); return person; &#125; 三、其他知识的补充线程的状态 NEW: 子线程被创建，在父线程中子线程的状态就是new RUNNABLE：线程在执行的时候的状态 BLOCKED：线程在等待锁的状态 WAITING：线程在等待通知的状态 TIMED WAITING：sleep时候的状态 TERMINATED：线程运行完毕 调用 thread.getState()，可以查开线程的状态 线程组（ThreadGroup）直接new出来的对象，可以规定组名，其他线程可以指定自己的组，组里面也可以包含线程组。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM学习笔记（二）]]></title>
    <url>%2F2019%2F04%2F15%2FJVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[继续JVM知识，这次主要总分解类得加载，深入了解JVM这本书我就先看这部分，实在是难啃，很多名词都没接触过，知识概念性得东西又多，关于调优部分一些常用得调优工具我就不总结了，后面有机会再来读读这本书 类加载机制 类加载得全过程 什么时候类加载 类加载器 一、类加载全过程 先看看一张完整的类的生命周期图 整个过程分为七步，其中验证、准备、解析属于连接，前面五部总的来说就是类的加载，加载、验证、准备、初始化和卸载这些步骤的顺序是固定的，其他的可能不确定，解析可能在初始化之后，比如反射机制。 下面主题看看加载的步骤： 加载加载主要做三件事： 通过一个类的全限定名来获取定义此类的二进制字节流，后面介绍类加载器时，会自定义一个类加载器，就是需要一个io的字节流，来实现类的加载。 将字节流的静态储存结构转化为方法区的运行时的数据结构；也就是类加载先会去加载那些静态的资源放入方法区。 还有就是会在堆里面生成一个 java.lang.class的对象，作为访问这个类在方法区里面内容的接口。 验证验证的几个内容： 文件格式的验证：检查是不是以魔数开头，版本对不对。。。 元数据验证：对一些类需要的数据进行验证，必有这个类有没有父类，这个父类是不是不能被继承的，父类是不是抽象的 字节码验证：这是比较麻烦的一个部分，主要是验证程序是不是语义合法，是不是逻辑符合，这个其实idea也会去做….所以在编译器调优时可以把JVM 的这些验证功能关掉。-Xverify:none 符号引用验证：这个其实是在解析的时候发生。是对常量池中各种符号引用的一种验证 准备准备阶段就是为类的变量分配内存，并设置类变量的初始值的阶段，注意的是这个阶段只是对类变量（被static修饰的变量）进行准备，不包括实例变量。 public static int a=123; 这里再准备阶段a 的值将只是 0，不是123，因为只是给一个初始值，要解析的时候才会真正被复制。 public final static int a=123; 这里的a在准备阶段是123，因为加了final那么就会为变量赋值—-注意一下 解析 解析的主要目的是：将虚拟机常量池中的符号引用替换为直接引用的过程。 解释一下符号引用和直接引用：比如在方法A中使用方法B，A（）{B（）；}，这里的B（）就是符号引用，初学java时我们都是知道这是java的引用，以为B指向B方法的内存地址，但是这是不完整的，这里的B只是一个符号引用，它对于方法的调用没有太多的实际意义，可以这么认为，他就是给程序员看的一个标志，让程序员知道，这个方法可以这么调用，但是B方法实际调用时是通过一个指针指向B方法的内存地址，这个指针才是真正负责方法调用，他就是直接引用。 初始化初始化简单来讲就是去执行 &lt; clinit&gt;()构造方法的过程，为类的静态变量赋予正确的初始值，上述的准备阶段为静态变量赋予的是虚拟机默认的初始值，此处赋予的才是程序编写者为变量分配的真正的初始值。 对 类变量 和 静态语句块 进行赋值动作，这个过程先后就是开谁在前谁在后。 下面代码值得一看 123456789public class Test1 &#123; static &#123; i=0; //可以赋值，即使还没定义，但是不能访问，也就是你不能对i进行其他操作，除了赋值 &#125; static int i=1; public static void main(String[] args)&#123; System.out.println(i); //结果为1，如果调整静态块顺序结构就为0. &#125;&#125; 12345678910111213//对子类的静态值调用会先去加载父类的 static class Parent&#123; public static int A=1; static &#123; A=2; &#125; &#125; static class Sun extends Parent&#123; public static int B=A; &#125; public static void main(String[] args)&#123; System.out.println(Sun.B); //打印结果为2 &#125; 而且静态块的赋值操作还是阻塞的。 二、什么时候类加载类的主动加载主动加载就是出现下面情况，会里面对类进行初始化，当然初始化之前肯定还有加载、验证、准备、解析。。 java对类的主动使用有五种情况： 创建类的实例 (new），或者定义类用 final 修饰 访问某个类或接口的静态变量，或者对该静态变量赋值 ，调用类的静态方法 。类的static你要用就得先加载这个类。 反射（如Class.forName(“com.shengsiyuan.Test”)） 初始化一个类的子类（先初始化所有的父类，最后初始化本身，接口除外，类初始化的时候，它所实现的接口不会初始化，就算字接口初始化，父接口也不会初始化，只有当程序调用接口的静态变量的时候才会导致接口的初始化） Java虚拟机启动时被标明为启动类的类，如main方法的那个类。 写点代码吧,下面代码差不多概括了2和4和5，1好理解，3记一下 12345678910111213141516171819202122232425262728class Parent&#123; static &#123; System.out.println("我是妈妈，我要先被加载"); &#125;&#125;class Son extends Parent&#123; static &#123; System.out.println("我是儿子，我被加载了"); &#125; public static void function()&#123; System.out.println("我是儿子的静态方法，调用我要先加载我"); &#125;&#125;public class Test3 &#123; static &#123; System.out.println("我是有main方法的类，我第一个加载"); &#125; public static void main(String[] args)&#123; Son.function(); &#125;&#125; /** * 打印结果： * 我是有main方法的类，我第一个加载 * 我是妈妈，我要先被加载 * 我是儿子，我被加载了 * 我是儿子的静态方法，调用我要先加载我 */ 类的被动加载有以下三种情况 访问类的静态变量，只会去初始化这个变量真正被定义的类。 new一个类的数组是不会马上去加载这个类的，只有最后操作数组具体对象才会加载。 访问类的final变量不会去加载这个类 也写点代码吧。很有意义的代码，值得思考 123456789101112131415161718192021class Parent2&#123; static &#123; System.out.println("我是妈妈，我要先被加载"); &#125; public static int value=123;&#125;class Son2 extends Parent2&#123; public static final int sonvalue=123; static &#123; System.out.println("我是儿子，我被加载了"); &#125;&#125;public class Test4 &#123; public static void main(String[] args)&#123; System.out.println(Son2.value); //Son2不加载 Son2[] son2s=new Son2[10]; //Son2不加载 System.out.println(Son2.sonvalue); //Son2不加载 &#125;&#125;//打印结果是之后Parent2被加载了 三、类加载器JDK 默认提供了如下几种ClassLoader Bootstrp loaderBootstrp 加载器是用C++语言写的，它是在Java虚拟机启动后初始化的，它主要负责加载%JAVA_HOME%/jre/lib,-Xbootclasspath参数指定的路径以及%JAVA_HOME%/jre/classes中的类。 ExtClassLoader Bootstrp loader 加载ExtClassLoader,并且将ExtClassLoader的父加载器设置为Bootstrp loader.ExtClassLoader是用Java写的，具体来说就是 sun.misc.Launcher$ExtClassLoader，ExtClassLoader主要加载%JAVA_HOME%/jre/lib/ext，此路径下的所有classes目录以及java.ext.dirs系统变量指定的路径中类库。 AppClassLoader Bootstrp loader 加载完ExtClassLoader后，就会加载AppClassLoader,并且将AppClassLoader的父加载器指定为 ExtClassLoader。AppClassLoader也是用Java写成的，它的实现类是 sun.misc.Launcher$AppClassLoader，另外我们知道ClassLoader中有个getSystemClassLoader方法,此方法返回的正是AppclassLoader.AppClassLoader主要负责加载classpath所指定的位置的类或者是jar文档，它也是Java程序默认的类加载器。 综上所述，它们之间的关系可以通过下图形象的描述： 为什么要有三个类加载器，一方面是分工，各自负责各自的区块，另一方面为了实现委托模型。 双亲委派模型就是一个类加载器收到类加载的要求，它先不会去加载，会先让上一层的的类加载器去加载，一致到启动类加载器，然后启动类加载器就回去加载，它加载不了又丢回给扩展类加载器，下来每个都会去是试着加载知道加载出来，到最后加载不出来就报错。 目的就是为了安全，对Java层序稳定性有很重要的作用。 破坏双亲委派模型这个就是类加载器收到类加载的要求，它就回去加载，它加载不了再去个ParentClassLoader加载。比如tomcat就是这个干的，这样做灵活性更高。 自定义类加载器最后写一个自定义的文件类加载器，很简单，实现了双亲委派模型。先丢个parent。也就是会丢个App-ClassLoader。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class FileSystemClassLoader extends ClassLoader &#123; private String rootDir; public FileSystemClassLoader(String rootDir) &#123; this.rootDir=rootDir; &#125; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; Class c=findLoadedClass(name); if(c!=null)&#123; //已经加载过了 return c; &#125;else&#123; ClassLoader parent=this.getParent(); try &#123; c=parent.loadClass(name); &#125;catch (Exception e) &#123; &#125; if(c!=null)&#123; return c; &#125;else&#123; byte[] classdate= new byte[0]; try &#123; classdate = getClassDate(name); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; if(classdate==null)&#123; throw new ClassNotFoundException(); &#125;else&#123; c=defineClass(name,classdate,0,classdate.length); &#125; &#125; &#125; return c; &#125; private byte[] getClassDate(String className) throws IOException &#123; String path=rootDir+"/"+className.replace('.','/'); InputStream is = null; StringBuffer a=new StringBuffer(); try &#123; is=new FileInputStream(path); byte[] buffer=new byte[1024]; int tmp=0; while((tmp=is.read(buffer))!=-1)&#123; a.append(buffer); &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125;finally &#123; if(is!=null)&#123; is.close(); &#125; &#125; return a.toString().getBytes(); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>学习</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java多线程学习笔记（一）]]></title>
    <url>%2F2019%2F04%2F14%2FJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Java多线程编程核心技术也看了大半了，感觉时候做点总结了，这本书看着还是比较轻松愉快的，推荐推荐。书本用的了很多事例去讲解多线程的种种API，作为多线程学习还是很不错的。 Java多线程开山篇我就不一点一点总结了，毕竟别人总结的已经很好了，需要总体复习的时候看看别人总结的就挺不错了，学习时间够写博客时间自然得zip一下。 Thread 主要API一、体验多线程继承Thread类，实现Runnable接口，一般推荐后面的方法，因为继承只能有一个嘛。 1234567891011121314151617/** * 体验线程 * 线程的调用不是跟随程序书写的先后来决定的 */class Tread extends Thread&#123; @Override public void run() &#123; System.out.println("我被调用了"); &#125;&#125;public class Thread01 &#123; public static void main(String[] args)&#123; Tread s=new Tread(); s.start(); System.out.println("主线程被调用了"); &#125;&#125; 二、Thread主要的方法基本方法 currentThread() 获取当前线程 isAlive 判断线程时候已经结束 sleep 让线程进入阻塞状态，并且是规定时间的 getId 获得线程的ID，这相当于给每个线程编号，每个线程都有一个自己的ID 线程的停止 1234567891011121314151617181920212223242526272829303132333435363738/** * 线程的停止： * 1、run方法结束线程自然停止 * 2、调用stop方法，强行停止线程，但这是不安全的，不建议使用 * 3、调用interruput，这个方法并不是马上的停止线程，而是基于线程一个 interruput的值得改变 * 作为一个标记，通过这个boolen值得改变，进行if判断来终止循环，从而终止线程。 * interruputed是当前线程又类调用得，它得调用会使得true变成false,而且测试来看 * 调用interruput方法，先interruputed变成true，后isInterruputed变为true， * 因为我多次测试，用interruputed方法作为判断条件，打印得isInterruputed得结果依然还是false * Interruputed方法得调用，不会改变自身得值 * * 但是这个停止只是停止了 循环，并没有停止整个线程，通过抛出异常得方式可以使得整个线程真正得停下来 */ class Th7 extends Thread&#123; @Override public void run() &#123; for(int i=0;i&lt;10000;i++)&#123; if(Thread.interrupted())&#123; System.out.println(this.isInterrupted()); break; &#125; System.out.println(i); &#125; System.out.println("heihei,我还在运行喔"); &#125;&#125;public class Thread07 &#123; public static void main(String[] args) throws InterruptedException &#123; Th7 th7=new Th7(); th7.start(); Thread.sleep(50); //调整线程状态 th7.interrupt(); System.out.println(Thread.interrupted()); &#125;&#125; interruput 这个方法一般是配合着条件判断，或者抛异常来停止线程。 值得注意的是 ：当一个线程再阻塞，也就是再 sleep,wait,被join的时候，被interrupt是会抛出异常的。 线程的其他小点 suspend 和 resume 将线程挂起，resume使线程恢复，这个也不是安全的也不推荐。 yield ，这个就是放弃资源，重新排队，这个不退进入阻塞，而是直接重新开始排队。 线程的优先级： setPriority方法设置，1-10，默认5，注意优先级并不代表一定先执行。 守护线程：setDaemon可以设置某个线程为守护线程，守护亡则线程亡。 二、线程的同步都知道多线程处理同一份资源的时候，往往会出现线程非安全的问题。原因就是一个线程对一个资源进行了修改还没来得及保存，另一个线程也读取了这分资源进行了修改，只是后就会出现不同步的现象。 synchrnized同步方法123456789101112131415161718192021222324252627282930313233343536/** * 现在我们来加上锁试试 * 结果时不会又线程不安全问题的 * 等同于 同步了，一定要等a用完了这个方法，b才能去碰它 * */public class Thread13 &#123; private static int num; public synchronized static void addI(String uname) throws InterruptedException &#123; if(uname.equals("a"))&#123; num=100; System.out.println("a set over"); Thread.sleep(2000); &#125;else&#123; num=200; System.out.println("b set over"); &#125; System.out.println(uname+" num="+num); &#125; public static void main(String[] args)&#123; new Thread(()-&gt;&#123; try &#123; addI("a"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); new Thread(()-&gt;&#123; try &#123; addI("b"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125;&#125; synchrnized同步块1234567891011121314151617181920212223242526272829303132333435363738/** * 同步代码块也是对象锁，当一个线程持有了一个对象的同步块锁，那么这个对象的所有上锁的方法都是同步的 * 不能被其他线程所访问，只有当这个线程结束，才会释放锁 * * 上面是锁this,我们也可以不锁this，而是锁另外一个对象，那么这个锁和整个类里面的其他锁就是异步的了 */public class Thread19 &#123; private String name; private String pwd; private void fun(String name ,String pwd) throws InterruptedException &#123; String anything=new String(); synchronized (anything)&#123; this.name=name; this.pwd=pwd; Thread.sleep(3000); System.out.println(Thread.currentThread().getName()+" name="+this.name+ " pwd="+this.pwd); &#125; &#125; public static void main(String[] args)&#123; Thread19 thread19=new Thread19(); new Thread(()-&gt;&#123; try &#123; thread19.fun("a","aaa"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); new Thread(()-&gt;&#123; try &#123; thread19.fun("b","bbb"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125;&#125; volatile关键字轻基的锁，它所得是资源，也就是线程每次用到这个资源的时候都会区公共区看看这个资源是否改变，都会取读取公共部分的这个资源。这样就可以实现对一个线程的控制。 值得注意的是： 这个锁只对原子性=型操作有效。 关于死锁简单来说死锁就是互相持有对方需要的锁。。。 A线程持有A锁，在A线程里面需要调用上了B锁的资源。 B线程持有B锁，在B线程里需要调用上了A锁的资源，这个时候就很容易发生死锁， 嵌套锁是很容易导致死锁。 三、线程之间的通信wait 和 notify1234567891011121314151617181920212223242526272829303132333435363738/** * 这一部分是线程通信的学习： * 主要掌握的技术点： * 1、使用wait/notify实现线程之间的通信 * 2、生产者/消费者模式的实现 * 3、方法join的使用、 * 4、TreadLocal类额使用 *//** * wait使线程停止，停止必需要持有对象的锁，对象级别的锁， * 而notify/notifyall，刚好相反，它可以是线程恢复，但是它也需要对象锁，而且这把锁应该和它需要唤起的线程的对象 * 锁一致，方可唤起。 */public class Thread1 &#123; public static void main(String[] args) throws InterruptedException &#123; String lock=new String(); new Thread(()-&gt;&#123; synchronized (lock)&#123; System.out.println("第一个开始了"); try &#123; lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("第一个结束了"); &#125; &#125;).start(); Thread.sleep(2000); new Thread(()-&gt;&#123; synchronized (lock)&#123; System.out.println("第二个开始了"); lock.notify(); System.out.println("第二个结束了"); &#125; &#125;).start(); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 用wait/notify实现线程之间的通信 * 但结果是，另个一线程notify之后，wait线程并没有马上开始，而是等notify线程执行之后才执行 * 这是因为两个线程持有同一个锁，notify调用之后，可以让wait线程从阻塞状态到就绪状态。 * 但notify线程还没有释放同步锁，wait线程就只能同步等待 * 综上wait：让一个线程进入等待队列，并且释放同步锁，知道被另一个持有相同锁的线程调用notify才进入就绪状态 * notify:然同步锁相同的线程从阻塞状态进入就绪状态，但不会释放自己的同步锁。 */class MyList&#123; private static List list=new ArrayList(); public void add()&#123; list.add("anything"); &#125; public int size()&#123; return list.size(); &#125;&#125;public class Thread2 &#123; public static void main(String[] args)&#123; String lock=new String(); MyList list=new MyList(); new Thread(()-&gt;&#123; synchronized (lock)&#123; if(list.size()!=5)&#123; System.out.println("wait begin"); try &#123; lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("wait end"); &#125; &#125; &#125;).start(); new Thread(()-&gt;&#123; synchronized (lock)&#123; for(int i =0;i&lt;10;i++)&#123; list.add(); if(i==5)&#123; System.out.println("发出通知"); lock.notify(); &#125; System.out.println("添加了"+(i+1)+"个元素"); &#125; &#125; &#125;).start(); &#125;&#125; 稍微总结：wait时线程进入阻塞、并且释放锁，当线程被notify时，并不能马上开始，需要等notufy线程执行完毕释放了锁才能拿到锁，开始执行。这两个方法都是需要对象锁的！！！ 同步代码块，就是锁的范围缩小，我们应该让公共的变量被赋值的代码进行加锁，应该在线程结束之际在对其进行赋值,用私有变量保存小操作，可是这样连私有 线程通道流12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152** * 在javaz中有各种各样的io流操作，关于线程的io有以下几种 * PipedInpuStream PipedOutputStream * out.connect(in); 来连接两个流实现两个线程之间的交流 * PipedReader PepedWriter * 字符流操作大同小异，就是读出的时候不用再将字符变成字节，读取的时候创建一个字符数组或者stringbuild */public class Thread6 &#123; private void writeMthod(PipedOutputStream out) throws IOException &#123; System.out.println("write:"); for(int i=0;i&lt;300;i++)&#123; String outDate=""+(i+1); out.write(outDate.getBytes()); System.out.print(outDate); &#125; System.out.println(); out.close(); &#125; private void readMthod(PipedInputStream in) throws IOException &#123; System.out.println("read:"); byte[] bytes=new byte[20]; int lengh=in.read(bytes); while(lengh!=-1)&#123; String inDate=new String(bytes,0,lengh); System.out.print(inDate); lengh=in.read(bytes); &#125; System.out.println(); in.close(); &#125; public static void main(String[] args) throws IOException, InterruptedException &#123; Thread6 thread6=new Thread6(); PipedOutputStream out=new PipedOutputStream(); PipedInputStream in=new PipedInputStream(); out.connect(in); new Thread(()-&gt;&#123; try &#123; thread6.readMthod(in); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;).start(); Thread.sleep(200); new Thread(()-&gt;&#123; try &#123; thread6.writeMthod(out); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125;&#125; join 开始体验join实现线程之间的通信了。 在一个线程中 调用另一个线程的join方法，那么本线程将会进入阻塞状态，直到join的线程结束了 才会继续执行 在阻塞中的线程被调用 interrupt方法进行打断，都会抛出异常 join也有像wait(long)一样的方法，jion(long），而且底层就是用wait(long)实现的，所有也会释放锁 join(long)和wai(long)t不一样的是，join设置的时间到了也还要那个线程结束了才能唤起。但wait时间到了没有被notify也会被唤起 而且join是线程的方法，wait必要线程同步锁锁的对象！ sleep，是不释放锁的，一个线程在sleep的时候是始终持有着锁，其他线程无法访问 ThreadLocal 和 InheritableThreadLocal1、体验ThreadLocal：它相当于每个线程都个公共部分的变量设置一个私有的箱子，装着私有的内容。 简单来讲就是公共变量对每个线程都有自己私有的值。 它是一种泛型容器–，放在定义公共变量的前面. 它的底层是一个map,这个map会存放在所有的线程，然后每次去存取的时候，都会先找到当前线程。 如果从未存过内容，调用get会返回null。 2、没有存放get也可以不是null,方法是定义一个新的类继承ThreadLocal 当然要去复写initialValue方法，它就是定义了默认没有set的时候get出来的值。 当然这也继承出来的类，也是符合每个线程对公共变量可以有自己私有的值。 3、这里体验：InheritableThreadLocal的使用 名字真的是贼长…. 作用：就是让子线程可以从父线程中取值。。。 我觉得这里要明白一个东西就是 子父线程，这里不是线程之间的继承，而是父线中开创了子线程。 而且子线程也可以对这个值进行修改，但是这个修改不会对父线程值造成影响。 通知这种继承也实现了线程之间的通信 写在最后 char a =0 ; 这样a什么都没有的，null都不是 getIndexOf(String1,String2) 可以判断第一个字符串是否包含另一个字符串。包含放回起始位置，不包含返回-1。 123456789101112131415public static void main(String[] args)&#123; String a="12312314"; int abs=0; int[] index =new int[128]; /** * 动态规划：计算当前能到达当前位置的最长字符串，要有个头 * 这个头就是i，头的选择是从本来的i和当前字符前一次出现的下一个位置。得到头 */ for(int i=0,j=0;j&lt;a.length();j++)&#123; i=Math.max(i,index[a.charAt(j)]); abs=Math.max(abs,j-i+1); index[a.charAt(j)]=j+1; //这里是记录下 下一个位置，从j以后没有j位置上这个字符 &#125; System.out.println(abs); &#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[about me]]></title>
    <url>%2F2019%2F04%2F12%2Fabout-me%2F</url>
    <content type="text"><![CDATA[今天是2019.4.13–我念大三，从今天起记录我的生活。 被前端代码困扰和crud的一天，劳动节快乐 2019-4-30 很大的雨 马上开始五一长假了，我并没有回家呆在了学校，今天没怎么学知识，做了份简历，希望好运把 2019-4-26 开始热了 今天把图书馆借的多线程和高并发两本书还了，然后又借了本 ==Java编程思想== 2019-4-25 暴雨转大太阳 逼着我画了一下的CAD 最近依旧学习劲蒙，高并发—算法—以及新技术的继续学习 2019-4-23 气温逐渐升高 负载均衡 2019-4-21 还凑合 为什么重写对象的equals()方法一定要重写hashcode()方法。 原因很简单： 基本条件：两个对象 equals成立 是 hashcode相等的 充分不必要条件。 就此如果改了 equals 方法，使得地址不一样的两个对象 相等了；但是根据地址计算的hashcode却不相等；这违背了上面的条件，后面还会导致 hashSet去重不得经了，hashMap的key不重复也不得经了。 2019-4-20 多云转雨 今天周末，女朋友说练车手背门夹了，然后她大姨给了她一些17前过期的创口贴，然后现在她的手指夹还是紫的。我要笑死了。 学习学习使我快乐。 2019-4-18 天气还不错今天满课啊，每天又要上课又要学计算机还是蛮累的喔加油加油 2019-4-16 多云Java多线程一书算是看完了，后面还会看并发编程艺术一书，继续补充Java高级知识，真的挺累的，每天还有很多自己专业的课，虽然没听都是看自己的书，但还是感觉计算机学习不去敲代码感受很难有深切的体会。现在挺迷茫的，是应该再继续多学习新知识，还是回过头来把Java的核心知识回顾学习，三大框架和web基础好久没碰都不太记得了，原因也是之前学就仅仅只是学会怎么用，要去搞懂这些子框架原理又是需要一大把时间，我现在缺的就是时间啊。 2019-4-15 阴今天继续学习了JVM，这书看得非常的难受，先看到着吧，这本书以后再翻。这个月也不准备在学很多新知识了，准备做一个阶段性的复习，回顾整理。 2019-4-14 多云我已经写了两篇文章啦，还是很开心的。我在过着我喜欢的日子，不再有过去两年那种迷茫。 2019-4-12 雨初次尝试搭建一个博客，作为一个没什么审美的boy，照着文档七七八八的把功能补齐了，先凑合着用吧。我的其实是想记录下自己的所学，每天都能记录下来一些东西。]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>置顶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM学习笔记（一）]]></title>
    <url>%2F2019%2F04%2F12%2FJVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[最近学习Java虚拟机，看的是深入理解Java虚拟机，整本书内容还还是非常的多的，而且有一些知识似乎还太适合我…..水平不够。然后准备做点读书笔记和一些自己的思考。 JVM学习笔记（一） 我主要准备学习的有一下三部分： JVM虚拟内存和GC Java类的J加载机制 代码的优化） 本文主要总结一下第一部分，内存模型和垃圾回收机制。Java内存模型 先来看看一张JVM内存模型图 1. 程序计数器程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 各个线程独有，每个线程都有一个。内存区域是唯一一个在Java 虚拟机规范中没有规定任何OutOfMemoryError 情况的区域。 2. java虚拟机栈与程序计数器一样，Java 虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。虚拟机栈存放的是局部变量表、一些方法体内的东西。在Java 虚拟机规范中，对这个区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError 异常；如果虚拟机栈可以动态扩展（当前大部分的Java 虚拟机都可动态扩展，只不过Java 虚拟机规范中也允许固定长度的虚拟机栈），当扩展时无法申请到足够的内存时会抛出OutOfMemoryError 异常。 3. 本地方法栈这个和java虚拟机栈差不多，只不过它存放的是本地的方法，也就是native的方法。 4. Java堆堆占了很大一块内存它的作用：存放着所有的事例话对象，这里也是垃圾回收的主要目标了。后面讲垃圾回收在来自己看看。 5. 方法区方法区其实是在类加载的时一些类的信息，静态变量，常量，以及一些编译后的代码等数据。 6. 运行时的常量池常量池是方法区的一部分，常量池存放着编期生成的各种字面变量。这里有意思的是一个字符串常量池，和intern()方法： intern方法，是将堆里面的字符串对象试着放入字符转常量池，何为尝试？是这的，字符串放入常量池时，会先看看常量池中时候有这个字符串，如果有，则直接返回，我还是堆里面的我；如果没有，就回在常量池中创建这个字符串，然后返回常量池中这个字符串的引用，那么现在就不再时堆里面的那个我了，我就是指向常量池的那个我。 String a =” ads” ，这样去构造一个字符串对象，它首先会去看看常量池中是否有这个字符串，如果I有，就直接返回常量池的字符串引用。如果没有它就会在常量池中创建这个字符串然后然后返回。也就是是说，这样构造字符串一定是指向常量池的。 String a=new String(“sas”)。这样创建的话就是在堆里面的事例对象了。 ==，成立的前提是要对象一样（常量除外） 12345678910111213141516171819202122232425 public static void main(String[] args)&#123; String a =new String("1")+new String("1"); a.intern(); String b="11"; String c=new String("1")+new String("1"); c.intern(); System.out.println(a==b); //true 都是常量池中的 “11” System.out.println(a==c); //false c.intern时，常量池中已经有了“11”。所有c还是堆里的对象 System.out.println(b==c); //flase a==b,a!=c.自然 b!=c &#125;public static void main(String[] args)&#123; String b="11"; String a =new String("1")+new String("1"); a.intern(); System.out.println(a==b); //false 一样，先b就让常量池中有了“11”，a就intern不进去了 &#125;public static void main(String[] args)&#123; String a =new String("ja")+new String("va"); a.intern(); String b="java"; System.out.println(a==b); //这个也是false,因为常量池中本来就有"java".....我也不知道问什么本来就有 &#125; 7. 直接内存 直接内存其实也叫堆外内存。学习NIO的时候有了解一点，NIO在创建buffer时，就有两种allocate选择，其中有一种就是直接内存，数据是直接与底层的磁盘打交道。。。。。 Java垃圾回收机制一、判断是否可以回收的两个算法1、引用计数法算法介绍：简单来说一个对象被引用我就给他加一，失去引用就减一，以这个数来判断时候可以回收 缺点：无法解决对象之间的相互引用问题，所有jvm们基本都不是这么干的 2、可达性分析算法介绍：GC Roots，着就像一个根，所有的对象只要能和它扯上关系的就可以不被回收，也就是GC Root可以到达这些对象，如果GC Root不可达了，也就说明可以回收了 这个算法是现在用来判断是否可以回收的算法 在简单的说说引用：引用分四种：强引用、软引用、弱引用、虚引用。。。强度依次降低 分级作用：可以让垃圾回收有了分情况处理的能力，内存比较悠闲可以先不回收那些低级引用，如果内存紧张那么也知道应该先回收哪些。 二、垃圾回收算法1、标记-清除算法介绍：先标记，然后差不多了 就统一回收了 缺点： 效率不高 容易产生很多内存碎片，及其不集中，这样使得如果有大内存对象就不好处理了 2、复制算法介绍：把堆分成两份，一次只操作一遍，当这边的内存满了就将不要清楚的对象复制到另一边，然后统一清楚。 特点： 解决了标记-清楚的内存碎片问题 可以有一半的内存不被使用，效率可想而知，浪费啊！！ 3、标记-整理算法介绍：在标记-清除上做了一些改变，前面标记差不多，只是到了最后不是直接清除，而是将存活的对象移动到一端，其他的要清除的就清除掉 4、分代回收算法介绍：分代回收其实是一种思想，它肯定是要配合着前面的算法时候用，就是将堆里面的对象分为新生代和老年代 新生代：其实是马上要死了的。。。。别看它新， 老年代：这才是老不死的家伙，经常需要然后就很少被清除 总结一下：就是现在的虚拟机基本上是配合着使用的，老年代用标记-清除，新生代用复制算法三、主要的垃圾回收器1、串行：垃圾回收器 (Serial Garbage Collector)(1)串行垃圾回收器在进行垃圾回收时，它会持有所有应用程序的线程，冻结所有应用程序线程，使用单个垃圾回收线程来进行垃圾回收工作。 串行垃圾回收器是为单线程环境而设计的，如果你的程序不需要多线程，启动串行垃圾回收。 (2)串行收集器是最古老，最稳定以及效率高的收集器，可能会产生较长的停顿，只使用一个线程去回收。新生代、老年代使用串行回收；新生代复制算法、老年代标记-压缩；垃圾收集的过程中会Stop The World（服务暂停）使用方法：-XX:+UseSerialGC 串联收集 Ps：在jdk client模式，不指定VM参数，默认是串行垃圾回收器 2、串行：ParNew收集器ParNew收集器其实就是Serial收集器的多线程版本。新生代并行，老年代串行；新生代复制算法、老年代标记-压缩使用方法：-XX:+UseParNewGC ParNew收集器 -XX:ParallelGCThreads 限制线程数量 3、并行：Parallel收集器Parallel Scavenge收集器类似ParNew收集器，Parallel收集器更关注系统的吞吐量。可以通过参数来打开自适应调节策略，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或最大的吞吐量；也可以通过参数控制GC的时间不大于多少毫秒或者比例；新生代复制算法、老年代标记-压缩使用方法：-XX:+UseParallelGC 使用Parallel收集器+ 老年代串行 4、并行：Parallel Old 收集器Parallel Old是Parallel Scavenge收集器的老年代版本，使用多线程和“标记－整理”算法。这个收集器是在JDK 1.6中才开始提供使用方法： -XX:+UseParallelOldGC 使用Parallel收集器+ 老年代并行 5、并发标记扫描CMS收集器CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用都集中在互联网站或B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。 java官方介绍：https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/cms.html从名字（包含“Mark Sweep”）上就可以看出CMS收集器是基于“标记-清除”算法实现的，它的运作过程相对于前面几种收集器来说要更复杂一些，整个过程分为4个步骤，包括：初始标记（CMS initial mark）并发标记（CMS concurrent mark）重新标记（CMS remark）并发清除（CMS concurrent sweep）其中初始标记、重新标记这两个步骤仍然需要“Stop The World”。初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC Roots Tracing的过程，而重新标记阶段则是为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。由于整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，所以总体上来说，CMS收集器的内存回收过程是与用户线程一起并发地执行。老年代收集器（新生代使用ParNew） 优点:并发收集、低停顿 缺点：产生大量空间碎片、并发阶段会降低吞吐量 6、G1收集器G1是目前技术发展的最前沿成果之一，HotSpot开发团队赋予它的使命是未来可以替换掉JDK1.5中发布的CMS收集器。与CMS收集器相比G1收集器有以下特点：(1). 空间整合，G1收集器采用标记整理算法，不会产生内存空间碎片。分配大对象时不会因为无法找到连续空间而提前触发下一次GC。(2). 可预测停顿，这是G1的另一大优势，降低停顿时间是G1和CMS的共同关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为N毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒，这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了。上面提到的垃圾收集器，收集的范围都是整个新生代或者老年代，而G1不再是这样。使用G1收集器时，Java堆的内存布局与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔阂了，它们都是一部分（可以不连续）Region的集合。G1的新生代收集跟ParNew类似，当新生代占用达到一定比例的时候，开始出发收集。和CMS类似，G1收集器收集老年代对象会有短暂停顿。收集步骤：1)、标记阶段，首先初始标记(Initial-Mark),这个阶段是停顿的(Stop the World Event)，并且会触发一次普通Mintor GC。对应GC log:GC pause (young) (inital-mark)2)、Root Region Scanning，程序运行过程中会回收survivor区(存活到老年代)，这一过程必须在young GC之前完成。3)、Concurrent Marking，在整个堆中进行并发标记(和应用程序并发执行)，此过程可能被young GC中断。在并发标记阶段，若发现区域对象中的所有对象都是垃圾，那个这个区域会被立即回收(图中打X)。同时，并发标记过程中，会计算每个区域的对象活性(区域中存活对象的比例)。4)、Remark, 再标记，会有短暂停顿(STW)。再标记阶段是用来收集 并发标记阶段 产生新的垃圾(并发阶段和应用程序一同运行)；G1中采用了比CMS更快的初始快照算法:snapshot-at-the-beginning (SATB)。5)、Copy/Clean up，多线程清除失活对象，会有STW。G1将回收区域的存活对象拷贝到新区域，清除Remember Sets，并发清空回收区域并把它返回到空闲区域链表中。6)、复制/清除过程后。回收区域的活性对象已经被集中回收到深蓝色和深绿色区域。 唯一和串行垃圾回收器不同的是，并行垃圾回收器是使用多线程来进行垃圾回收工作的。 这些垃圾回收器应该只要有个印象吧，记不住=———-]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>学习</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F04%2F12%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post 1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
