<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Java并发包的锁]]></title>
    <url>%2F2019%2F06%2F21%2FJava%E5%B9%B6%E5%8F%91%E5%8C%85%E7%9A%84%E9%94%81%2F</url>
    <content type="text"><![CDATA[经过了一段漫长的而且折磨人的考试，最近终于可以缓解一下了，好久好久没有写博客了，今天重新开始做人，其实最近开始还是会抽出时间来学习计算机的，虽然不是很多。这篇主要介绍Java并发包里面的几把锁。 Java多线程的文章是我写的最多的了，但是一直都在路上，之前其实有学习一下AQS，但是看得迷迷糊糊的，这段时间有回顾了一遍，有些心得记录一下。 总的来看Java并发包的锁实现有ReentrantLock、ReentrantReadWriteLock、StampedLock。这些也是本文将要介绍的，前两个实现了Lock接口，第三个是JDK1.8新加入的，没有实现Lock接口。它们各有特点，理解它们的原理可以更好的利用好它们。 AQS和CAS是实现这些锁的基础，这里就不先介绍它们，我们从ReentrantLock的实现来看。 一、ReentrantLock一句话的来说这把锁是一把可重入的、可以非公平也可以公平的独占锁。它的使用就不多说了。 ReentrantLock内部有一个Syn内部类继承了AQS，Syn还是一个抽象类；然后一把公平锁一把非公平锁继承Syn。我们从Lock看看他是为何独占、为何可重入，为何又公平非公平。 Lock 1、lock（）实际是调用ReentrantLock里面公平锁或者非公平锁的lock，这两把锁继承子Syn，公平和非公平差别之一（还有别的差别）就是它们各自的lock()方法。 差别很容易看出来，就是非公平上来就通过CAS去修改锁的状态（0为没有锁，大于0锁被占用了），不了解CAS可以看看 CAS-实现原子性。 1234567891011//非公平final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);&#125;//非公平final void lock() &#123; acquire(1);&#125; 2、进入AQS的acquire(1) 尝试获取锁，不成功就加入队列，并且会LockSupport.pack自己。LockSupport也是并发包的类。后面3 4 5就是围绕着这个方法if里面的内容进行展开。 123456//这是在AQS里面的方法public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; //先尝试获取锁不成功，这个方法子类实现，返回一个boolean值 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) //tryAcquire(arg)不成功，才进入队列 selfInterrupt();&#125; 3、看看ReentranLock里面公平锁获取锁的操作 12345678910111213141516171819202122232425262728//这是ReentrantLock里面的FairLock的实现 protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); //1、还没有线程获取锁 if (c == 0) &#123; //hasQueuedPredecessors()判断是否又等待的线程 //AQS有等待的其他的线程，加上 ！就是没有等待的，才会下面的操作 //非公平没有这个判断 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; //公平和非公平差别而就是会不会去进行!hasQueuedPredecessors()的判断 setExclusiveOwnerThread(current); return true; &#125; &#125; //2、可重入的表现 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; //获取失败 return false; &#125;&#125; 4、如果这个上面这个请求锁的失败了，返回false就会进入AQS的队列。看看入队的操作 12345678910111213141516private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; //尝试进去，成功直接返回 if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; //如果前面没有返回，则循环的加入队列,知道成功才会返回 enq(node); return node;&#125; 5、acquireQueued（）方法：进入队列后检查自己的前面一个是不是到了可head，然后尝试获取锁还有有个打断状态的保存，见FIFOMutex。如果获取不成功，前的节点也不是head节点，还会尝试pack当前线程，不去使劲的自旋获取锁。 123456789101112131415161718try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; //尝试pack当前线程，避免自旋的资源浪费。 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; 上面五个办法就解决的了一个线程请求锁的过程。没获取成功的就进入了队列。等待着别的线程unlock释放锁。 unLcok（） 1、首先是靠AQS的release（）来释放锁 12345678910public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; //tryRelease()同样需要靠子类实现 Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); //让队列中的下一个节点unpack return true; &#125; return false;&#125; 2、tryRelease(arg)，释放锁，在ReentrantLock里面的Syn实现（Syn继承了AQS) 这个方法就是把一些状态参数调整 123456789101112protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; //可重入锁的体现，锁了多少层就要开多少次锁 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 3、unparkSuccessor(h)就是将下一个节点唤起。 结点的waitStatus有四种状态 1：被删除的 -1：等待unpack的 -2：waiting on condition -3: 共享锁有关的 12345678910111213Node s = node.next;if (s == null || s.waitStatus &gt; 0) &#123; //如果当前节点被标记为删除的 s = null; //从后往前找到最前面的一个状态小于0的？ for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t;&#125;if (s != null) LockSupport.unpark(s.thread); //unpark 这个节点这时候被唤起的节点就会又尝试取获取锁了，在前面获取锁的操作里面4步骤是没有退出的当被unpack之后，就又会去获取锁。 Condition 条件的实现是靠AQS的ConditionObjec实现的。简单的说一下，他是AQS实现等待通知的一个内部类，使用等待通知之前要先获取锁。然后它自己内部又维持了一个等待的Node队列，他的主要工作就是在AQS队里与自己的等待队列直接做好结点的转移。 到这里你应该可以看出ReentrantLock的独占、可重入与公平非公平了。 二、ReentrantReadWriteLockReentrantReadWriteLock实现读写分离。里面也是有一个Sync继承了AQS，Syn不再是一个抽象类了，而里面得ReadLock和WriteLock对Sync是持有而不是继承，这里复合优先于继承。 里面两把锁，带来得就有两个状态，而Doug Lea只用一个数记录了锁得状态，用32的int高位是读锁的数量。低位是写锁的状态，还是哪个state，只是不一样的味道 获取锁的判断是，如果当前有写锁，则直接入队。 如果当前有读锁，则请求写锁的入队，请求读锁会请求锁。 如果没锁，就会去尝试获取锁。 下面主要看看ReadLock的共享机制 (读锁获取）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445461、调用lock，来到AQS里面的共享获取方法public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125;2、tryAcquireShared(arg)由Sync实现protected final int tryAcquireShared(int unused)&#123; Thread current = Thread.currentThread(); int c = getState(); //1、如果有写锁（独占锁）占用，且不是当前线程，返回-1 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; //2、没有写锁，则可以尝试获取。 int r = sharedCount(c); //这个readerShouldBlock()判断返回ture的条件是有写锁在AQS列队下一个位置等待，避免饥饿 if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; //这里的CAS是确保当多个线程请求读锁只有一个读锁获取成功。（读读竞争） compareAndSetState(c, c + SHARED_UNIT)) &#123; //3、读锁已经成功获取，后面只要进行一些参数的设置。 if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; &#125; //读锁增加返回1，不必要入队 return 1; &#125; //4、读锁竞争失败，则会自旋的取获取读锁。操作和这个方法差不多只是加上了自旋 return fullTryAcquireShared(current); &#125; 3、如果读锁获取失败就入队doAcquireShared(arg)。 三、StampedLockStampedLock是不可重入的，这与前面两个都不一样，但它更灵活，锁得状态更丰富，提供了乐观锁： 写的独占锁，悲观共享读锁，乐观的读锁 乐观的读锁并不能保证数据的最新请求， 它还可以进行锁的升级，在乐观失败后升级为悲观，防止其他改 在悲观读锁想要修改数的时候也可以升级为写锁 一个重要的概念就是乐观锁，以及锁的升级，乐观锁肯定逃不了一个版本的操作。下面看看如果使用它的乐观读锁。 12345678910111213141516StampedLock lock=new StampedLock();double distanceFromOrigin()&#123; long l = lock.tryOptimisticRead(); //无锁获取，返回一个版本戳 double currentX=x,currentY=y; if(lock.validate(l))&#123; //判断版本戳是否过期，过期了就升级为悲观的读锁。（和上面的读写锁就类似了） long l1 = lock.readLock(); try &#123; currentX=x; currentY=y; &#125;finally &#123; lock.unlockRead(l1); &#125; &#125; return x*x+y*y; //但是这里并不能保证是最新的数据&#125; 这个锁的使用会稍微有一些差异，上锁的时候会返回返回一个版本戳，如果是写和悲观读获取了锁之后也是同样需要释放锁的！！！对于StampedLock上锁的因为考虑到可以升级和版本戳问题，比较复杂，我也没去仔细看了。。。 四、用AQS实现一个自己的不可重入锁12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061class Sync extends AbstractQueuedSynchronizer&#123; @Override protected boolean isHeldExclusively() &#123; return getState()==1; &#125; @Override protected boolean tryAcquire(int arg) &#123; assert arg==1; if(compareAndSetState(0,1))&#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; @Override protected boolean tryRelease(int arg) &#123; assert arg==1; if(getState()==0)&#123; throw new IllegalMonitorStateException(); &#125; setExclusiveOwnerThread(null); setState(0); return true; &#125; Condition newCondition()&#123; return new ConditionObject(); &#125;&#125;private final Sync sync=new Sync();@Overridepublic void lock() &#123; sync.acquire(1);&#125;@Overridepublic void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1);&#125;@Overridepublic boolean tryLock() &#123; return sync.tryAcquire(1);&#125;@Overridepublic boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1,unit.toNanos(time));&#125;@Overridepublic void unlock() &#123; sync.release(1);&#125;@Overridepublic Condition newCondition() &#123; return sync.newCondition();&#125; 看了上面的几把锁，可以知道要实现自己的锁关键是要实现tryAcquire（）和 tryRelease（）]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最近的一些思考]]></title>
    <url>%2F2019%2F06%2F02%2F%E6%9C%80%E8%BF%91%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[接近期末，考试真的好多，现在都没办法很静下心来学习，都大三下了还一堆乱七八糟的课真的是服了这个专业了。主要还是不喜欢吧。 明天又有一个闭卷的背背背的科目。很烦，学习的专注度很低，甚至我现在都不知道在干什么要干什么很空虚。 我自学计算机是从C开始的，后来看的数据结构也是C的，但是说实话C我只是稍微学了一下，然后我就开始学习Java的，从Java基础到Javaweb基础，再到后面的几个框架和一些数据库中间件。学了下来到现在其实也没花几个月。三个多月吧，虽然说学习效率不低，学了很多。可是我最近在想我这样真的是在变强吗？我那薄弱的计算机基础的知识支撑不起我的学习之路，学Java虚拟机学多线程，可是搞不清底层到的机制，不了解计算机运作的原理，不够扎实的算法与数据结构知识，不够系统的计算机知识等等。我知道我比起那些强者差了不止一点点，会用再多的框架又有什么用呢，写不出优雅的代码做不出美优的设计始终只能在鄙视链的最低端。 其实挺纠结的，到底要不要重写学习下C，要不要去学习一下C++。今天搞了半天搭建了一个C的IDE。可是尝到了写Java甜头的我再去写C真的有种很难受的感觉。而且似乎没有太多的意义。C++我不熟悉，但是给我一种晦涩的感觉。我不知道，一方面想着再去提高我的Java水平，一方面又想学习C和C++（为了更好的了解计算机）。还想去学习算法和计算机基础。一遍还有期末繁重的考试和实验。可是我的时间好少啊，我想在毕业的时候找到一个满意的工作。可是我马上就要毕业了啊。如何取舍呢，在这些剩下不多的大学时间了我该如何抓住，从何学。 在网上买了一些书，都是大家都在推荐的圣经吧，像深入了解计算机系统、Java编程思想、算法还有两把Java的书，我比较担心的是我着薄弱的C语言的水平，到时候看深入了解计算机系统会不会看到想放弃。可是真的不想最近又花上一些时间从头来搞一遍C，应该不会有很大问题吧，应该不止于看不懂，这三本书我也不是准备短时间就看完的，毕竟各个分量十足，我还买了两本Java的也是很重要的书吧，准便先看那两本，然后慢慢翻深入了解计算机系统和Java编程思想。其实有准备买一个C++的入门书籍，还能顺带复习C，但是想着估计也不会怎么看吧，就不浪费钱了先。 立个flag吧，好好看书！]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>学习</tag>
        <tag>反思</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F05%2F30%2FUntitled%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[ForkJoin的简单了解]]></title>
    <url>%2F2019%2F05%2F29%2FForkJoin%E7%9A%84%E7%AE%80%E5%8D%95%E4%BA%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[这篇文章主要是记一下今天学习的两个Java的API吧，底层的具体实现还是没有去看的，但是大概思路还是知道一些。 一、TimerTimer是一个定时器，它的作用是接受有个TimerTask，然后可以定时的执行这个TimerTask的任务。策略模式的体现。 看看具体的一些操作 1234567891011public static void main(String[] args)&#123; Timer timer=new Timer(); System.out.println("begin"); timer.schedule(new TimerTask() &#123; @Override public void run() &#123; System.out.println("time task"); &#125; &#125;,3000,1000); //延迟三秒后，每秒执行一次。 System.out.println("hhh");&#125; 此外schdule指定一个Date事件执行，也可以只指定延迟事件，emmmm其实我们用个循环加sleep似乎也可以做到。这个schedule是异步的，所以后面的“hhh”会先打印。 讲到这就顺便提一下springboot里面的定时任务。 基于注解(@Scheduled) @EnableScheduling（开启注解） 123456@Scheduled(cron = "0/5 * * * * ?") //或直接指定时间间隔，例如：5秒 //@Scheduled(fixedRate=5000) private void configureTasks() &#123; System.err.println("执行静态定时任务时间: " + LocalDateTime.now()); &#125; 二、ForkJoinPool背景：ForkJoinPool的优势在于，可以充分利用多cpu，多核cpu的优势，把一个任务拆分成多个“小任务”，把多个“小任务”放到多个处理器核心上并行执行；当多个“小任务”执行完成之后，再将这些执行结果合并起来即可。这种思想值得学习。 Java7 提供了ForkJoinPool来支持将一个任务拆分成多个“小任务”并行计算，再把多个“小任务”的结果合并成总的计算结果。 ForkJoinPool是ExecutorService的实现类，因此是一种特殊的线程池。 使用方法：创建了ForkJoinPool实例之后，就可以调用ForkJoinPool的submit(ForkJoinTask task) 或invoke(ForkJoinTask task)方法来执行指定任务了。 其中ForkJoinTask代表一个可以并行、合并的任务。ForkJoinTask是一个抽象类，它还有两个抽象子类：RecusiveAction和RecusiveTask。其中RecusiveTask代表有返回值的任务，而RecusiveAction代表没有返回值的任务。 下面的UML类图显示了ForkJoinPool、ForkJoinTask之间的关系： 所以熟悉线程池的话ForkJoinPool其实就是一个线程池，它把接受Runnble编程了接收ForkJoinTask。 基本知识介绍了下面看代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * @Description: 测试ForkJoinPool， * @CreateDate: Created in 2019/5/29 13:04 * @Author: 摇井 */public class ForkJoinDemo &#123; public static void main(String[] args) throws Exception&#123; int[] arr=new int[200000000]; //这个有点大，需要调一下运行对内存，不然直接溢出了 Random random=new Random(); ForkJoinPool pool=ForkJoinPool.commonPool(); for (int i = 0; i &lt;arr.length ; i++) &#123; arr[i]=random.nextInt(100); &#125; Sum sum1 = new Sum(arr, 0, arr.length-1); //单线程测试 long l = System.currentTimeMillis(); int sum=0; for (int i = 0; i &lt;arr.length ; i++) &#123; sum+=arr[i]; &#125; long l1 = System.currentTimeMillis(); System.out.println((l1-l)+" "+sum); //结果大约是80ms ForkJoinTask&lt;Integer&gt; submit = pool.submit(sum1); Integer integer = submit.get(); long l2 = System.currentTimeMillis(); System.out.println((l2-l1)+" "+integer); //结果大约是60ms，大概快了1/4，还是挺不错的。 pool.shutdown(); &#125;&#125;class Sum extends RecursiveTask&lt;Integer&gt; &#123; private int[] arr; private Integer start; private Integer end; public Sum(int[] arr,Integer start, Integer end) &#123; this.arr=arr; this.start = start; this.end = end; &#125; @Override protected Integer compute() &#123; if(end-start&lt;25000000)&#123; int sum=0; for (int i = start; i &lt;=end ; i++) &#123; sum+=arr[i]; &#125; return sum; &#125; else &#123; Integer mid=(start+end)/2; Sum sum = new Sum(arr, start, mid); Sum sum1 = new Sum(arr, mid + 1, end); invokeAll(sum,sum1); return sum.join()+sum1.join(); &#125; &#125;&#125; 使用还是很简单的，分到了合适的位置处理，不让就接着分，递归调用最后合起来。 不过测试的时候这个分的程度很重要，在这个数据量的情况下，如果颗粒度分的很小采用ForkJoin模式会比单线程慢很多很多，大概要300多ms，这可能是分的过程和合的过程花费了大量的时间。 从简单测试来看，这个分的颗粒度应该是总体量除以CPU数这个样子才比较合适。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一统Java集合]]></title>
    <url>%2F2019%2F05%2F27%2F%E4%B8%80%E7%BB%9FJava%E9%9B%86%E5%90%88%2F</url>
    <content type="text"><![CDATA[Java容器是数据结构、算法、高并发的完美体现，Java容器家族相当的庞大，这里我们不对底层实现深究，我们来整体观看Java容器家族。 在编程的世界里面，容器作为对象的持有者，是相当的重要的，程序是数据结构和算法加起来，那么学习Java的种种容器集合是非常有必要的。 Java容器有两个顶级接口 Collection和Map，当然Collection上面还有个Iterable，这就是说数作为集合的话，你都都可以迭代，Map没有实现这个接口，那是不是就不能迭代呢，并不是，虽然Map本身不含有迭代器，但是考内部类Set&lt;Map.Entry&lt;K,V&gt;&gt;实现对内部节点的迭代。 Collection 仔细看上面这张图，我找出来最重要的接口和最重要的实现类。忽略了中间的抽象类，忽略了Vector List：我想List都很熟悉，它就是数据结构里面的线性表，它的实现也从链表 和 顺序表两种存储结构实现 Set：set出现的的作用就是一个去重，但是它的实现几乎全部是靠对应的Map实现的，我们一定要搞清楚储存结构和逻辑结构。Set的种种实现都是不同的储存结构，但是他们都实现了统一的逻辑结构就是必须去重 Queue：从数据结构角度来看，队列就是一种逻辑结构，它要满足先进先出的FIFO。当然它的实现也有很多种不能的储存机构。 Deque：Deque它继承Queue，扩展了什么呢，Queue必须先进先出，从头串到尾的指针，而Deque扩展了什么呢？它还有一个从尾指向头的指针，可以看到我们常用的LinkedList就是一个双向的链表。既让是双向的那也就能后进的先出，这也就是栈（Stack），官方也是推荐使用Deque来实现栈的功能，而不用Stack。 Stack：按上面的惯例来说，栈这种逻辑结构本应该定义为接口，但是没有，它就是一个用List的实现类，其实它继承自Vector，就是用Vector来实现栈的功能（先进后出），但同样我们可以用Deque来实现栈喔。 上面这些除了Stack加了同步锁实现了线程安全，其他全都不是线程安全的，如果你的程序不需要考虑线程安全，你可以从这里面选择你需要的功能的集合。 如果需要线程安全的集合，从这里面找 这里我只列出了部分，其实还有，安全的队列可还有好几个呢，后面我在放一个图专门放队列的。 可以看到对于着三种不同逻辑结构的接口，也有他们安全的的容器，这些容器全部来自于java.util.concurrent包。前面说过，对于Set基本都是用Map实现的，因为Map要求key唯一，着正好对上了set的需求。 但是CopyOnWriteArraySet使用CopyOnWriteList实现的，那它怎么去重，没有一次添加都去遍历看看有没有。。。 Map对于Map，常见的就是下面这些了，带有Concurrent的就是线程安全的，其他的线程不安全 首先确定是不是要线程安全 再看你需要上面功能，能实现的也就是排序的Map和保持插入顺序的Map,TreeMap就是用来排序的，但是在线程安全的Map里用来是使用调表这个数据结构实现的。 几乎所有的Map都有一个对应的Set，Set拿去用就好。但是WeakHashMap是没有对应的WeakHashSet。但是我们强大的集合工具类有这么个方法Collections.newSetFromMap()，这要得到的set也能是weak的了。 QueueQueue它本来就是输入集合的，队列算是一种逻辑结构了，它的实现非常的多，安全的不安全的，各种功能的，用各种不同储存结构实现的。 队列总的来分也是分为线程安全和线程不安全 线程不安全的好说，分别用链表、顺序表、和具有优先级的基于数组的优先队列，为什么不用树实现优先队列？其实也是可以的，但是逻辑复杂不说，效率还不如直接用数组。 线程安全的队列，可以分成两种 ConcurrentLinkedQueue/Deque，基于CAS、volatile实现的安全的队列。 实现BlockingQueue的阻塞队列，BlockingQueue实现线程安全是基于ReentrantLock重入锁实现的线程安全，当然也不全是用ReentrantLock。其中有个LinkedTransferQueue是1.7引入的一个线程安全基于CAS、无界的、可以有SynchronousQueue等待消费功能的一个阻塞队列，反正就是就是挺牛逼的。 看完Java的容器，再回想数据结构，你会发现数据结构是如此的重要，从线性表的链表、顺序表，用他们实现的队列、基于Hash实现键值对，基于树实现排序查找的，还有加上有并发能力的组合，编绘出了Java容器的蓝图。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[七种排序的实现]]></title>
    <url>%2F2019%2F05%2F26%2F%E4%B8%83%E7%A7%8D%E6%8E%92%E5%BA%8F%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[排序是算法里面非常重要的一部分，其实很久之前就学习过一次了，不过这东西还是很容易遗忘，尤其是希尔排序，不去参考之前的我都写不出来了 大多数都可以直接撸出来，除了哪个希尔 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172package suanfa;import java.util.Arrays;/** * @Description: Sort数组 * @CreateDate: Created in 2019/5/26 11:19 * @Author: 摇井 */public class Sort &#123; //交换函数 private void exchange(int[] arr,int L,int R)&#123; int temp=arr[L]; arr[L]=arr[R]; arr[R]=temp; &#125; //快排，快排其实也可以不用递归，用栈储存位置 private void quickSort(int[] arr,int L,int R)&#123; if(L&lt;R)&#123; int[] p=position(arr,L,R); quickSort(arr,L,p[0]); quickSort(arr,p[1],R); &#125; &#125; private int[] position(int[] arr, int l, int r) &#123; int pl=l-1; //记录排序左边界 int pr=r; //记录排序有边界 while(l&lt;pr)&#123; if(arr[l]&lt;arr[r])&#123; exchange(arr,++pl,l++); &#125;else if(arr[l]&gt;arr[r])&#123; exchange(arr,--pr,l); &#125;else &#123; l++; &#125; &#125; exchange(arr,pr,r); return new int[]&#123;pl,++pr&#125;; &#125; //堆排 private void heapSort(int[] arr)&#123; if(arr==null || arr.length&lt;2)&#123; return; &#125; //调堆 for (int i = arr.length/2-1; i &gt;=0 ; i--) &#123; heapAdjust(arr,i,arr.length); &#125; //一个一个向下调堆 for (int j = arr.length-1; j &gt;0 ; j--) &#123; exchange(arr,0,j); heapAdjust(arr,0,j); &#125; &#125; private void heapAdjust(int[] arr, int i, int length) &#123; int L=2*i+1; int R=2*i+2; int max=i; if(L&lt;length &amp;&amp; arr[L]&gt;arr[max])&#123; max=L; &#125;if(R&lt;length &amp;&amp; arr[R]&gt;arr[max])&#123; max=R; &#125;if(max!=i)&#123; exchange(arr,max,i); heapAdjust(arr,max,length); &#125; &#125; //归并 private void mergeSort(int[] arr,int L,int R)&#123; if(L&lt;R)&#123; int mid=(L+R)/2; mergeSort(arr,L,mid); mergeSort(arr,mid+1,R); comeBack(arr,L,mid+1,R); &#125; &#125; //越写与觉得归并好垃圾啊，着复制来复制去的 private void comeBack(int[] arr, int l, int m, int r) &#123; int[] temp1=new int[m-l]; int[] temp2=new int[r-m+1]; for (int i = 0; i &lt;temp2.length; i++) &#123; temp1[i]=arr[m+i]; &#125; for (int j = 0; j &lt;temp1.length ; j++) &#123; temp2[j]=arr[l+j]; &#125; int i=0,j=0; int k=l; while (i&lt;temp1.length &amp;&amp; j&lt;temp2.length)&#123; if(temp1[i]&gt;temp2[j])&#123; arr[k++]=temp2[j++]; &#125;else &#123; arr[k++]=temp1[i++]; &#125; &#125; while (i&lt;temp1.length)&#123; arr[k++]=temp1[i++]; &#125; while (j&lt;temp2.length)&#123; arr[k++]=temp2[j++]; &#125; &#125; //希尔排序，代码很简单但是确不好理解，很容易忘记 //分组思想 step是分多少组，以插入为基础，只不过不是每次都跳1，而是跳step private void shellSort(int[] arr)&#123; if(arr!=null &amp;&amp; arr.length&gt;1)&#123; for (int step = arr.length/2; step &gt;0 ; step/=2) &#123; for (int i =step ; i&lt;arr.length ; i++) &#123; int j=i; int temp=arr[i]; while (j-step&gt;=0 &amp;&amp; arr[j-step]&gt;temp)&#123; arr[j]=arr[j-step]; j=j-step; &#125; arr[j]=temp; &#125; &#125; &#125; &#125; //插入排序 private void insertionSort(int[] arr)&#123; if(arr!=null &amp;&amp; arr.length&gt;1)&#123; for (int i = 1; i &lt;arr.length ; i++) &#123; int j=i; int temp=arr[i]; while (j&gt;0 &amp;&amp; arr[j-1]&gt;temp)&#123; arr[j]=arr[--j]; //这里会把 i 位置替换掉，必须临时保存 i 位置的值 &#125; arr[j]=temp; // 这样这里获得的才能是准确的 i 位置的值 &#125; &#125; &#125; //冒泡 private void bubbleSort(int[] arr)&#123; if (arr!=null &amp;&amp; arr.length&gt;1 ) &#123; for (int i = 1; i &lt;arr.length ; i++) &#123; for (int j = 0; j &lt;arr.length-i ; j++) &#123; if(arr[j]&gt;arr[j+1])&#123; exchange(arr,j,j+1); &#125; &#125; &#125; &#125; &#125; //选择 private void selectSort(int[] arr)&#123; if(arr!=null &amp;&amp; arr.length&gt;1)&#123; for (int i = 0; i &lt;arr.length-1 ; i++) &#123; int min=i; for (int j = i+1; j &lt;arr.length ; j++) &#123; if(arr[j]&lt;arr[min])&#123; min=j; &#125; &#125; exchange(arr,i,min); &#125; &#125; &#125; public static void main(String[] args)&#123; Sort sort=new Sort(); int[] arr= &#123;4, 56, 9, 41, 3, 1, 4,0&#125;; // sort.mergeSort(arr,0,arr.length-1); sort.selectSort(arr); System.out.println(Arrays.toString(arr)); &#125;&#125;]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LRU算法以及缓存]]></title>
    <url>%2F2019%2F05%2F26%2FLRU%E7%AE%97%E6%B3%95%E4%BB%A5%E5%8F%8A%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[主要介绍一下Java中用LinkedHashMap实现LRU的算法 一、LinkedHashMap这个东西其实就是继承自HashMap，然后改写了Entry的结构，让节点有一个before和after指针，就这样把HashMap里面的一个个节点安装先后顺序串起来了。 作为LRU缓存，提供了一个这样的构造方法 123456public LinkedHashMap(int initialCapacity, //缓存大小 float loadFactor, //加载因子 boolean accessOrder) &#123; //是否开启用了之后放最后 super(initialCapacity, loadFactor); this.accessOrder = accessOrder;&#125; 怎样一个逻辑呢？首先我们建立了一个Map，定义他只能有initialCapacity这么大，然后定义accessOrder为true。 我们来看put方法**LinkedHashMap的put就是父类put方法。 在HashMap中定义了下面三个方法，在HashMap都没有实现，就是给LinkedHashMap中的回调。 1234// Callbacks to allow LinkedHashMap post-actionsvoid afterNodeAccess(Node&lt;K,V&gt; p) &#123; &#125; //当节点的值被改变的时候调用void afterNodeInsertion(boolean evict) &#123; &#125; //当节点被添加时被调用void afterNodeRemoval(Node&lt;K,V&gt; p) &#123; &#125; //当节点被删除时调用 我们来看看afterNodeInsertion方法在LinkedHashMap中的实现， 1234567void afterNodeInsertion(boolean evict) &#123; // possibly remove eldest evict在hashMap调用传入的就是true LinkedHashMap.Entry&lt;K,V&gt; first; if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) &#123; K key = first.key; removeNode(hash(key), key, null, false, true); //删除HashMap中的节点，并且回调afterNodeRemoval，让节点从链表中也移除 &#125;&#125; 看到注释也就是知道就是看看要不要移除最老的，判断条件是 removeEldestEntry(first) 而removeEldestEntry(first)方法确实默认放回false的，所以我们需要有删除功能的cache就需要重写这个方法。 123protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123; return false;&#125; 在来看看get方法get方法在LinkedHashMap是重写了的 12345678public V get(Object key) &#123; Node&lt;K,V&gt; e; if ((e = getNode(hash(key), key)) == null) //直接从Map中取出值来 return null; if (accessOrder) //这里就是我们构造传入的时候被调用就放到链表的最后 afterNodeAccess(e); //这里就是实现，把从原来的链表中取出来，然后放到最后。 return e.value;&#125; 有了这样一套get和put的逻辑，就保证了我们最新的数据一定在后面，每次删掉的会使前面的数据 1234567891011//用LinkedHashMap定义一个符合LRU算法的缓存LinkedHashMap&lt;Integer, Integer&gt; cache = new LinkedHashMap&lt;Integer, Integer&gt;(12 ,0.75f,true)&#123; @Override protected boolean removeEldestEntry(Map.Entry&lt;Integer, Integer&gt; eldest) &#123; if(size()&gt;12)&#123; System.out.println(eldest.getKey()+"移除了"); &#125; return size()&gt;12; &#125;&#125;; 二、接着我们用HasMap和LinkedList实现简单的LRU缓存1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class CacheByList&lt;K,V&gt; &#123; LinkedList&lt;K&gt; list; HashMap&lt;K,V&gt; map; Integer capeCity; public CacheByList(Integer capeCity) &#123; this.list = new LinkedList&lt;&gt;(); this.map = new HashMap&lt;&gt;(capeCity); this.capeCity = capeCity; &#125; public void put(K k,V v)&#123; map.put(k,v); if(!list.contains(k))&#123; list.add(k); &#125; afterPut(k,v); &#125; public void get(Object k)&#123; V v = map.get(k); afterGet(k); &#125; public void foreach()&#123; list.forEach(k -&gt; &#123; System.out.println(map.get(k)); &#125;); &#125; private void afterGet(Object k) &#123; list.remove(k); list.add((K)k); &#125; private void afterPut(K k, V v) &#123; if(list.size()&gt;capeCity)&#123; K first = list.removeFirst(); map.remove(first); &#125; &#125; public static void main(String[] args)&#123; CacheByList&lt;String,Integer&gt; cacheByList=new CacheByList&lt;&gt;(3); cacheByList.put("1",1); cacheByList.put("2",2); cacheByList.put("3",3); cacheByList.get("1"); cacheByList.put("4",4); cacheByList.foreach(); &#125;&#125; 三、spirngboot对缓存的操作12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182/** * @Cacheable * *组织原理：以ConcurrentCache为例 * 1、底层有一个ConcurrentHashMap作为缓存管理者，管理着以cacheNames为key，以cache为value的Map * 2、cache又是一个个的ConcurrentHashMap，key可以自己指定、也可以由keyGenerator生成 * 这些可以选的选项都可以点近@Cacheable注释里面看，keyGenerator也可以我们自己定义传入 * * 执行逻辑： * 1、先进来会去看缓存里面有没有，有就取走返回，没有就生成key * 2、然后如果没有才会去数据库里面查。 * 3、查出结果之后会放入缓存。以后就这个方法就不会进去了。 * * 可以配置的条件 * String[] cacheNames() default &#123;&#125;; //缓存名，也可以用value * String key() default ""; //key的值，可以用sqEl表达式 * String keyGenerator() default "" //key生成策略 * String cacheManager() default ""; //各种manager * String cacheResolver() default ""; * String condition() default ""; //满足怎么样，就缓存 * String unless() default ""; //除非怎么样，才不缓存， * boolean sync() default false; //是否异步，异步的时候unless就不启用了 */@Cacheable(cacheNames = &#123;"emp"&#125;)public Employee selectEmpById(Integer id)&#123; System.out.println("进行了查询"); return employeeMapper.selectByPrimaryKey(id);&#125;/** *执行逻辑： * 1、每次都会去执行目标方法 * 2、让后将查询的结果放入缓存中 * * 测试逻辑： * 1、先进行查询 * 2、然后更新 * 3、再查询，发现值没有更新，原因查询和更新的key不一样,只需要将key指定相同就好， */@CachePut(cacheNames = "emp",key ="#result.id" )public Employee updateEmp(Employee employee)&#123; System.out.println("更新操作运行了"); employeeMapper.updateByPrimaryKey(employee); return employee;&#125;/** *执行目标方法并且删除缓存中的内容 * * 特殊属性： * boolean allEntries() default false； //是否全部删除 * boolean beforeInvocation() default false; //是不是再方法执行进行缓存清除，默认再方法之后 * //那么如果方法出错，就不会清除缓存。 * //如果是true，则会先清除缓存 */@CacheEvict(cacheNames = "emp",key = "#id")public void delete(Integer id)&#123; System.out.println("删除操作"); employeeMapper.deleteByPrimaryKey(id);&#125;/** *@Caching * 在前面的注解里面，我们查询结果都是被为一的key查询到，有时候我们希望我们的查询结果 * 不单单被目标方法用到，别的方法的key也能用到，那么就需要复合注解存入多个key * 是一个复合的注解，当我们希望结果被多个key对应时，就需要这样 * 这样查出来就让别的查询也有了缓存。 * * 有下面三个操作 * Cacheable[] cacheable() default &#123;&#125;; * CachePut[] put() default &#123;&#125;; * CacheEvict[] evict() default &#123;&#125;; */@Caching(cacheable = &#123;@Cacheable(value = "emp",key = "#lastName")&#125;, put = &#123;@CachePut(value = "emp",key = "#result.id"), @CachePut(value = "emp",key = "#result.email")&#125; )public List&lt;Employee&gt; selectByLastName(String lastName)&#123; Employee employee=new Employee(); employee.setLastName(lastName); List&lt;Employee&gt; select = employeeMapper.select(employee); return select;&#125; springboot对缓存的支持默认是实现是ConcurrentHashMap，不过我们可以改用其他的，只要对依赖引入就好，主要是我们可以自定义对象序列化，通常采用的是json的方式序列化。 下面看看springboot2.0是如何自定义序列化机制的 1234567891011121314151617181920212223242526272829303132333435@Configurationpublic class MyRedisConfig &#123; /** * 常用序列化还可以自定义模板 * @param redisConnectionFactory * @return * @throws UnknownHostException */ @Bean //这是Redis操作的自定义模板，我们也可以修改模板，用模板操作Redis public RedisTemplate&lt;Object, Employee&gt; MyredisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException &#123; RedisTemplate&lt;Object, Employee&gt; template = new RedisTemplate(); template.setConnectionFactory(redisConnectionFactory); Jackson2JsonRedisSerializer&lt;Employee&gt; objectJackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer&lt;Employee&gt;(Employee.class); template.setDefaultSerializer(objectJackson2JsonRedisSerializer); return template; &#125; @Bean @Primary //自定义一个RedisCacheManager，实现放方式采用Json序列化，用的是FastJsonRedisSerializer（） public RedisCacheManager cust_cacheManager(RedisConnectionFactory redisConnectionFactory) &#123; //创建自定义序列化器 FastJsonRedisSerializer jsonSeria = new FastJsonRedisSerializer(); //包装成SerializationPair类型 RedisSerializationContext.SerializationPair serializationPair = RedisSerializationContext.SerializationPair.fromSerializer(jsonSeria); //redis默认配置文件,并且设置过期时间 RedisCacheConfiguration redisCacheConfiguration = RedisCacheConfiguration.defaultCacheConfig().entryTtl(Duration.ofDays(1)); //设置序列化器 redisCacheConfiguration = redisCacheConfiguration.serializeValuesWith(serializationPair); //RedisCacheManager 生成器创建 RedisCacheManager.RedisCacheManagerBuilder builder = RedisCacheManager.builder(redisConnectionFactory).cacheDefaults(redisCacheConfiguration); return builder.build(); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-boot编写自己的启动器]]></title>
    <url>%2F2019%2F05%2F24%2Fspring-boot%E7%BC%96%E5%86%99%E8%87%AA%E5%B7%B1%E7%9A%84%E5%90%AF%E5%8A%A8%E5%99%A8%2F</url>
    <content type="text"><![CDATA[在面向对象的编程世界里，许许多多的类组成一个良好的程序，他们直接的关系往往是错综复杂的，当对象与对象之间的应用变得非常复杂是，就需要有一个东西来统一管理这些对象，于是，在Java的世界里面就出现了spring。 在面向对象的编程世界里，许许多多的类组成一个良好的程序，他们直接的关系往往是错综复杂的，当对象与对象之间的应用变得非常复杂是，就需要有一个东西来统一管理这些对象，于是，在Java的世界里面就出现了spring。 spring的核心就是IOC容器，让我们对类的管理更加方便，但是初代的spring需要我们自己将类放入容器，就是在xml文件中配置我们需要放入的类希望spring来帮我们管理。xml文件的编写比较麻烦，后面就加入了注解来配置注入我们的类。 可是呢，我们的应用程序越来越大、用到的技术越来越多，我们都希望spring能管理他们，于是一个个的xml文件编写变得非常的麻烦，而且对于同一个技术的应入它的xml文件基本是固定的，也就是这个配置都是差不多的，我们应该统一的配置好，而不应该在每个项目中都去一次一次的配置，于是spring-boot就出现了。 spring-boot的出现帮我们解决了这个配置的问题，我们只需要应入对应的start就能将需要引入的技术配置到spring容器中。 spring-boot是怎么把这些配置类在启动的时候扫描加入容器的呢？其实很简单，基于注解的配置我们应该都是了解的，我们只要提前写好这些配置类，然后再让spring-boot启动的时候就扫描就好了。 先配置当我们在项目中引入一个web模块的starter，你可以在资源引入里面找到这个spring-boot-starter-web的依赖，但是打开一看里面确实什么都没有的，也就是说我们的配置文件根本不再spring-boot-starter-web项目里面 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; 那我们的配置文件在哪呢？ 我想大家都知道，spring-boot为我们写好的配置文件全部都在spring-boot-autoconfigure这个项目里面。打开pom.xml文件点进去，你就会发现这些什么什么starter全部最终都依赖到了spring-boot-autoconfigure 你可以到这里面找很多很多的配置类，如果你对spring-boot的某个技术的配置不满意，你就可以到这里面来看看这个技术的配置文件，然后编写一个自己的配置文件。 再扫描现在当我们的项目引入了某个starter，那么它相关的依赖以及配置文件也就引入进来了，下面重要的是spring-boot再启动的时候是怎么去扫描这些配置、是何使去扫描这些配置的呢？ spring-boot启动的开始 123456@SpringBootApplicationpublic class SpringStartTestApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringStartTestApplication.class, args); &#125;&#125; run里面做了什么 做了两件大事情：准备一个SpringApplication 执行这个SpringApplication 1234public static ConfigurableApplicationContext run(Class&lt;?&gt;[] primarySources, String[] args) &#123; return new SpringApplication(primarySources).run(args);&#125; 准备SpringApplication 比较重要的是去META-INF/spring.factories找了ApplicationContextInitializer和ApplicationListener 12345678910111213141516initialize(sources);private void initialize(Object[] sources) &#123; //保存主配置类 if (sources != null &amp;&amp; sources.length &gt; 0) &#123; this.sources.addAll(Arrays.asList(sources)); &#125; //判断当前是否一个web应用 this.webEnvironment = deduceWebEnvironment(); //从类路径下找到META-INF/spring.factories配置的所有ApplicationContextInitializer；然后保存起来 setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); //从类路径下找到ETA-INF/spring.factories配置的所有ApplicationListener setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); //从多个配置类中找到有main方法的主配置类 this.mainApplicationClass = deduceMainApplicationClass();&#125; 执行App的run 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; configureHeadlessProperty(); //获取SpringApplicationRunListeners；从类路径下META-INF/spring.factories SpringApplicationRunListeners listeners = getRunListeners(args); //回调所有的获取SpringApplicationRunListener.starting()方法 listeners.starting(); try &#123; //封装命令行参数 ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); //准备环境 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); //创建环境完成后回调SpringApplicationRunListener.environmentPrepared()；表示环境准备完成 Banner printedBanner = printBanner(environment); //创建ApplicationContext；决定创建web的ioc还是普通的ioc context = createApplicationContext(); analyzers = new FailureAnalyzers(context); //准备上下文环境;将environment保存到ioc中；而且applyInitializers()； //applyInitializers()：回调之前保存的所有的ApplicationContextInitializer的initialize方法 //回调所有的SpringApplicationRunListener的contextPrepared()； // prepareContext(context, environment, listeners, applicationArguments, printedBanner); //prepareContext运行完成以后回调所有的SpringApplicationRunListener的contextLoaded（）； //s刷新容器；ioc容器初始化（如果是web应用还会创建嵌入式的Tomcat）；Spring注解版 //扫描，创建，加载所有组件的地方；（配置类，组件，自动配置） refreshContext(context); //从ioc容器中获取所有的ApplicationRunner和CommandLineRunner进行回调 //ApplicationRunner先回调，CommandLineRunner再回调 afterRefresh(context, applicationArguments); //所有的SpringApplicationRunListener回调finished方法 listeners.finished(context, null); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; //整个SpringBoot应用启动完成以后返回启动的ioc容器； return context; &#125; catch (Throwable ex) &#123; handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); &#125;&#125; 编写一个自己的starter让spring-boot启动的时候也能扫描，然后别人能直接应用这个starter 理一下逻辑，按照spring-boot编写starter的设计模式。 需要一个启动器，这个启动器什么也不用做，只要引入一个依赖，这个依赖里面来负责写配置。 配置器，定义配置类，添加到spring容器就好。 要在META-INF里面标明配置类，让 spring-boot启动的时候能扫描到。 然后将上面两个项目install到maven仓库，这要其他项目就可以通过引用启动器来获取装配了。 启动器：新建一个maven项目、引入配置器的依赖 12345678&lt;dependencies&gt; &lt;!--引入自动配置--&gt; &lt;dependency&gt; &lt;groupId&gt;com.cfr&lt;/groupId&gt; &lt;artifactId&gt;cfr-spring-boot-start-autoconfig&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置器：配置器需要引入spring-boot-startet的依赖 编写一个目标对象 1234567@Setterpublic class HelloService &#123; HelloProperties properties; public String sayHello(String name)&#123; return properties.getPrefix()+"--"+name+"--"+properties.getSuffix(); &#125;&#125; 编写一个配置文件扫描类（获取properties里面的信息） 123456@ConfigurationProperties(prefix = "cfr.hello")@Datepublic class HelloProperties &#123; private String prefix; private String suffix;&#125; 编写一个配置类（相当于一个xml文件，将我们目标对象装配到容器） 12345678910111213@Configuration //标志位一个配置类@ConditionalOnWebApplication //web才生效@EnableConfigurationProperties(HelloProperties.class) //使得 @ConfigurationProperties生效，所有的Enable...基本都是使得某一类注解生效。某一个东西生效。public class HelloServiceAutoConfiguation &#123; @Autowired HelloProperties properties; @Bean public HelloService helloService()&#123; HelloService helloService = new HelloService(); helloService.setProperties(properties); return helloService; &#125;&#125; 最后还有很重要的一件事情就是再META-INF下面建一个spring.factory文件，将我们的配置类放进去 12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\com.cfr.cfrspringbootstartautoconfig.HelloServiceAutoConfiguation install和使用至此我们的启动器就写好了，只要install到maven仓库然后再新建一个项目测试。 1234567&lt;!--我这里新建立的是一个spring web项目,因为@ConditionalOnWebApplication //web才生效然后引入之前写好的starter--&gt;&lt;dependency&gt; &lt;groupId&gt;com.cfr&lt;/groupId&gt; &lt;artifactId&gt;cfr-spring-boot-start&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 编写一个controller测试 123456789@RestControllerpublic class HelloController &#123; @Autowired HelloService service; @GetMapping("hello") public String hello()&#123; return service.sayHello("zhangsan"); &#125;&#125; 然后再application.properties文件中间中配置 12cfr.hello.prefix=nihaonihaocfr.hello.suffix=hello word 访问成功]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>-spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AIO了解了解]]></title>
    <url>%2F2019%2F05%2F23%2FAIO%E4%BA%86%E8%A7%A3%E4%BA%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[学习了很久的NIO，然后做了个web服务器，emmmm不满足，今天学习了一下AIO，AIO的整体编程难度是小于的NIO的，但是有一些的回调机制编写起来还是有一些麻烦的，一步小心就可能很想要的效果不太一样。 AIO基本概念jdk7中新增了一些与文件(网络)I/O相关的一些api。这些API被称为NIO.2，或称为AIO(Asynchronous I/O)。AIO最大的一个特性就是异步能力，这种能力对socket与文件I/O都起作用。AIO其实是一种在读写操作结束之前允许进行其他操作的I/O处理。AIO是对JDK1.4中提出的同步非阻塞I/O(NIO)的进一步增强。 jdk7主要增加了三个新的异步通道: AsynchronousFileChannel: 用于文件异步读写； AsynchronousSocketChannel: 客户端异步socket； AsynchronousServerSocketChannel: 服务器异步socket。 因为AIO的实施需充分调用OS参与，IO需要操作系统支持、并发也同样需要操作系统的支持，所以性能方面不同操作系统差异会比较明显。 前提概念在具体看AIO之前，我们需要知道一些必要的前提概念。 Unix中的I/O模型Unix定义了五种I/O模型 阻塞I/O 非阻塞I/O I/O复用（select、poll、linux 2.6种改进的epoll） 信号驱动IO（SIGIO） 异步I/O（POSIX的aio_系列函数） 一个戏谑的例子： 如果你想吃一份宫保鸡丁盖饭： 同步阻塞：你到饭馆点餐，然后在那等着，还要一边喊：好了没啊！ 同步非阻塞：在饭馆点完餐，就去遛狗了。不过溜一会儿，就回饭馆喊一声：好了没啊！ 异步阻塞：遛狗的时候，接到饭馆电话，说饭做好了，让您亲自去拿。 异步非阻塞：饭馆打电话说，我们知道您的位置，一会给你送过来，安心遛狗就可以了。 详情参见文章末尾的他山之石-Unix下五种IO模型。 Reactor与Proactor 两种IO多路复用方案:Reactor and Proactor。 Reactor模式是基于同步I/O的，而Proactor模式是和异步I/O相关的。 reactor：能收了你跟俺说一声。proactor: 你给我收十个字节，收好了跟俺说一声。 详情参见文章末尾的他山之石-IO设计模式：Reactor和Proactor对比。 异步的处理异步无非是通知系统做一件事情。然后忘掉它，自己做其他事情去了。很多时候系统做完某一件事情后需要一些后续的操作。怎么办？这时候就是告诉异步调用如何做后续处理。通常有两种方式： 将来式: 当你希望主线程发起异步调用，并轮询等待结果的时候使用将来式; 回调式: 常说的异步回调就是它。 与NIO比较AIO又名NIO2.0，从性能角度来讲似乎没有很显著的提升的，而且Java的AIO的依靠操作系统的AIO的，但是现在的Linux和unix对实现来看，并不是那么的理想。 epoll也不是异步IO啊。异步IO在linux上目前仅限于文件系统，并且还没有得到广泛应用，很多平台都没有这玩意。java aio在windows上是利用iocp实现的，这是真正的异步IO。而在linux上，是通过epoll模拟异步的。 nio是轮询，aio是回调通知或者将来模式。 怎么理解呢，拿烧水打比方。 BIO，就是一个人烧一壶水，等着它开。 NIO，一个人同时烧好多水，他只要不断地轮询检查水是不是开了。 AIO，一个人不但可以烧很多水，而且是开了会叫的电热壶，只要拿个电热壶叫了去处理一下就好。 AIO实现简单的服务端和客户端编程服务端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class Server &#123; static CountDownLatch countDownLatch=new CountDownLatch(1); //保证主线程不会提前结束 static AtomicInteger connectSum=new AtomicInteger(0); //记录连接数量 public static void main(String[] args) throws IOException &#123; final AsynchronousServerSocketChannel channel=AsynchronousServerSocketChannel.open() .bind(new InetSocketAddress(8899)); channel.accept(null, new CompletionHandler&lt;AsynchronousSocketChannel, Void&gt;() &#123; @Override public void completed( AsynchronousSocketChannel result, Void attachment) &#123; int i = connectSum.incrementAndGet(); try &#123; System.out.println(result.getRemoteAddress()+" 加入连接，当前连接数量："+i); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; //继续接受其他客户的连接 channel.accept(null,this); ByteBuffer buffer=ByteBuffer.allocateDirect(1024); //第二个参数就是要带过去的对象， //The object to attach to the I/O operation; can be &#123;@code null&#125; result.read(buffer, buffer,new MyHandle(result)); &#125; @Override public void failed(Throwable exc, Void attachment) &#123; &#125; &#125;); try &#123; countDownLatch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; channel.close(); //最后关闭服务通道 &#125; &#125;&#125;//一个处理读取的响应的Handler,对于每个连接都有一个自己的handler，复用class MyHandle implements CompletionHandler&lt;Integer,ByteBuffer&gt;&#123; private AsynchronousSocketChannel channel; public MyHandle(AsynchronousSocketChannel channel) &#123; this.channel = channel; &#125; @Override public void completed(Integer result, ByteBuffer attachment) &#123; if(result!=-1)&#123; //判断是否还处于连接 attachment.flip(); Future&lt;Integer&gt; write = channel.write(attachment); try &#123; write.get(); //阻塞 &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; attachment.clear(); channel.read(attachment,attachment,this); &#125;else &#123; //说明一个连接已经断开 try &#123; channel.shutdownOutput(); Server.connectSum.getAndDecrement(); //让连接数量减一 &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; try &#123; channel.shutdownOutput(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 客户端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public class Client &#123; static AsynchronousSocketChannel channel; static CountDownLatch countDownLatch=new CountDownLatch(1); static volatile boolean isConnect=true; //一个标志，当写出数据的操作结束通知监听的退出循环 public static void start() throws IOException &#123; channel =AsynchronousSocketChannel.open(); channel.connect(new InetSocketAddress("localhost", 8899), channel, new CompletionHandler&lt;Void, AsynchronousSocketChannel&gt;() &#123; @Override public void completed(Void result, AsynchronousSocketChannel attachment) &#123; System.out.println("连接到服务器。。。。"); ByteBuffer bu = ByteBuffer.allocate(1024); attachment.read(bu,bu,new MyClientHandle(attachment)); &#125; @Override public void failed(Throwable exc, AsynchronousSocketChannel attachment) &#123; countDownLatch.countDown(); &#125; &#125;); &#125; public static void sendMsg() throws ExecutionException, InterruptedException &#123; Scanner scanner=new Scanner(System.in); String next=""; while (!next.equals("-1"))&#123; next= scanner.next(); ByteBuffer wrap = ByteBuffer.wrap(next.getBytes()); Future&lt;Integer&gt; write = channel.write(wrap); /** * Waits if necessary for the computation to complete, and then * retrieves its result. */ write.get(); // System.out.println("send ok "); &#125; isConnect=false; countDownLatch.countDown(); &#125; public static void main(String[] args) throws Exception &#123; Client.start(); try &#123; TimeUnit.SECONDS.sleep(1);&#125;catch (InterruptedException e) &#123; e.printStackTrace();&#125; Client.sendMsg(); countDownLatch.await(); channel.shutdownOutput(); channel.close(); &#125;&#125;//一个监听服务端发送过来数据的 handler。class MyClientHandle implements CompletionHandler&lt;Integer,ByteBuffer&gt;&#123; private AsynchronousSocketChannel channel; public MyClientHandle(AsynchronousSocketChannel channel) &#123; this.channel = channel; &#125; @Override public void completed(Integer result, ByteBuffer attachment) &#123; attachment.flip(); System.out.println(new String(attachment.array(),0,result)); attachment.clear(); while (Client.isConnect)&#123; //当写出数据结束、这里将退出循环。 Future&lt;Integer&gt; read = channel.read(attachment); try &#123; Integer integer = read.get(); attachment.flip(); System.out.println(new String(attachment.array(),0, integer)); attachment.clear(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; Client.countDownLatch.countDown(); &#125;&#125; 整个中我用到了Future和Callback都有用到， 对于客户端的接受消息和发出消息 以及 服务端的发出我用的是Future模型，看源码注释也就知道Future模式下的get()是一个阻塞的操作。对于客户端其实根本不会承受很大的并发量，所以采用阻塞的等待ByteBuffer处理完，可以实现ByteBuffer的复用，所以我在客户端选择了这个模式。 整体感觉确实比NIO要用起来舒服的，NIO的选择关闭注册什么什么的稍有不注意就是bug。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nio的零拷贝]]></title>
    <url>%2F2019%2F05%2F21%2FNio%E7%9A%84%E9%9B%B6%E6%8B%B7%E8%B4%9D%2F</url>
    <content type="text"><![CDATA[nio零拷贝了解一下。 传统I/O在Java中，我们可以通过InputStream从源数据中读取数据流到一个缓冲区里，然后再将它们输入到OutputStream里。我们知道，这种IO方式传输效率是比较低的。那么，当使用上面的代码时操作系统会发生什么情况： 1、JVM发出read() 系统调用。 2、OS上下文切换到内核模式（第一次上下文切换）并将数据读取到内核空间缓冲区。(第一次拷贝：hardware —-&gt; kernel buffer） 3、OS内核然后将数据复制到用户空间缓冲区(第二次拷贝: kernel buffer ——&gt; user buffer)，然后read系统调用返回。而系统调用的返回又会导致一次内核空间到用户空间的上下文切换(第二次上下文切换)。 4、JVM处理代码逻辑并发送write（）系统调用。 5、OS上下文切换到内核模式(第三次上下文切换)并从用户空间缓冲区复制数据到内核空间缓冲区(第三次拷贝: user buffer ——&gt; kernel buffer)。 6、write系统调用返回，导致内核空间到用户空间的再次上下文切换(第四次上下文切换)。将内核空间缓冲区中的数据写到hardware(第四次拷贝: kernel buffer ——&gt; hardware)。 整个过程中文件从内核态拷贝到用户态，再由用户态拷贝到内核态，这多次拷贝中就使得速度性能上大打折扣。 零拷贝I/O 1、发出sendfile系统调用，导致用户空间到内核空间的上下文切换(第一次上下文切换)。通过DMA将磁盘文件中的内容拷贝到内核空间缓冲区中(第一次拷贝: hard driver ——&gt; kernel buffer)。 2、然后再将数据从内核空间缓冲区拷贝到内核中与socket相关的缓冲区中(第二次拷贝: kernel buffer ——&gt; socket buffer)。这里其实这是拷贝了数据的地址和数据的长度。 3、sendfile系统调用返回，导致内核空间到用户空间的上下文切换(第二次上下文切换)。通过DMA引擎将内核空间socket缓冲区中的数据传递到协议引擎(第三次拷贝: socket buffer ——&gt; protocol engine)。通过sendfile实现的零拷贝I/O只使用了2次用户空间与内核空间的上下文切换，以及3次数据的拷贝。 你可能会说操作系统仍然需要在内核内存空间中复制数据（kernel buffer —&gt;socket buffer）。 是的，但从操作系统的角度来看，这已经是零拷贝，因为没有数据从内核空间复制到用户空间。 内核需要复制的原因是因为通用硬件DMA访问需要连续的内存空间（因此需要缓冲区）。 但是，如果硬件支持scatter-and-gather，这是可以避免的。 但这样存在一个问题、对于我们需要加以修改的文件的我们就无能为力了 通过mmap实现的零拷贝I/O整个过程比上面多了一个内存映射，将用户态的文件内存映射到内核态，直接对内核态的文件操作，避免拷贝 mmap系统调用返回，导致内核空间到用户空间的上下文切换(第二次上下文切换)。接着用户空间和内核空间共享这个缓冲区，而不需要将数据从内核空间拷贝到用户空间。因为用户空间和内核空间共享了这个缓冲区数据，所以用户空间就可以像在操作自己缓冲区中数据一般操作这个由内核空间共享的缓冲区数据。 NIO DirectByteBufferJava NIO引入了用于通道的缓冲区的ByteBuffer。 ByteBuffer有三个主要的实现： HeapByteBuffer（并非零拷贝）在调用ByteBuffer.allocate（）时使用。 它被称为堆，因为它保存在JVM的堆空间中，因此你可以获得所有优势，如GC支持和缓存优化。 但是，它不是页面对齐的，这意味着如果你需要通过JNI与本地代码交谈，JVM将不得不复制到对齐的缓冲区空间。 DirectByteBuffer在调用ByteBuffer.allocateDirect（）时使用。 JVM将使用malloc（）在堆空间之外分配内存空间。 因为它不是由JVM管理的，所以你的内存空间是页面对齐的，不受GC影响，这使得它成为处理本地代码的完美选择。 然而，你要C程序员一样，自己管理这个内存，必须自己分配和释放内存来防止内存泄漏。 MappedByteBuffer在调用FileChannel.map（）时使用。 与DirectByteBuffer类似，这也是JVM堆外部的情况。 它基本上作为OS mmap（）系统调用的包装函数，以便代码直接操作映射的物理内存数据。对于这点我之前写的聊聊编码) 12345//获取通道 FileChannel in = input.getChannel(); FileChannel out = output.getChannel(); //读取映射buffer MappedByteBuffer inputData = in.map(FileChannel.MapMode.READ_ONLY, 0, length); 测试普通io和零拷贝的速度差别1、首先我们需要一个服务端接受数据这个服务端其实用io还是用nio都可以，只是接受客户端传过来的二进制文件然后丢弃。我就用Nio 123456789101112131415public class OldServer &#123; public static void main(String[] args) throws IOException &#123; ServerSocket serverSocket=new ServerSocket(8899); byte[] arr=new byte[4096]; DataInputStream in=null; while (true)&#123; Socket accept = serverSocket.accept(); in=new DataInputStream(accept.getInputStream()); int read = in.read(arr,0,arr.length); while (read!=-1)&#123; read=in.read(arr,0,arr.length); &#125; &#125; &#125;&#125; 2、一个io的客户端，读取文件写出文件123456789101112131415161718192021public class OldClient &#123; public static void main(String[] args) throws Exception&#123; String fileName="F:\\一些东西\\迅雷下载\\BaiduNetdisk_v6.2.0.rar"; Socket socket=new Socket("localhost",8899); InputStream inputStream=new FileInputStream(fileName); DirectBuffer byteBuffer = (DirectBuffer) ByteBuffer.allocateDirect(4096); byteBuffer.cleaner().clean(); DataOutputStream outputStream=new DataOutputStream(socket.getOutputStream()); int l=0; byte[] buffer=new byte[4096]; long l1 = System.currentTimeMillis(); while ((l=inputStream.read(buffer))!=-1)&#123; outputStream.write(buffer); outputStream.flush(); &#125; inputStream.close(); socket.shutdownOutput(); //这里还是很重要的一步 System.out.println(System.currentTimeMillis()-l1); &#125;&#125; 3、一个零拷贝Nio的客户端123456789101112131415161718192021public class NewClient &#123; public static void main(String[] args) throws Exception &#123; SocketChannel channel=SocketChannel.open(); channel.configureBlocking(true); channel.connect(new InetSocketAddress("localhost",8899)); String fileName="F:\\一些东西\\迅雷下载\\BaiduNetdisk_v6.2.0.rar"; FileChannel channel1 = new FileInputStream(fileName).getChannel(); // File file=new File(fileName); （mmap模型才需要） // long length = file.length(); // MappedByteBuffer map = channel1.map(FileChannel.MapMode.READ_ONLY, 0, length); long l = System.currentTimeMillis();// mmap模型 channel.write(map);// sendfile channel1.transferTo(0, channel1.size(), channel); System.out.println(System.currentTimeMillis()-l); channel1.close(); channel.shutdownOutput(); &#125;&#125; 结果：（30.0 MB大小的文件） io模型下大约花费时间是350左右 NIO零拷贝下是40左右 基于mmap的零拷贝大约是150左右 结论： 很明显零拷贝再速度上有着显著的提示，对于这种直接将本地文件写入网络的操作推荐使用 fileChannel.transferTo, 如果有需要将文件进行修改，比如编码之类的也推荐使用mmap的内存映射。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>nio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sping-AOP基于注解]]></title>
    <url>%2F2019%2F05%2F20%2FSping-AOP%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[出去了几天，昨晚刚回来今天更新一下文章 1. @AspectJ 的由来提到AspectJ,其实很多人是有误解的，很多人只知道在Spring中使用Aspect那一套注解，以为是Spring开发的这一套注解，这里我觉得有责任和大家澄清一下。 AspectJ是一个AOP框架，它能够对java代码进行AOP编译（一般在编译期进行），让java代码具有AspectJ的AOP功能（当然需要特殊的编译器），可以这样说AspectJ是目前实现AOP框架中最成熟，功能最丰富的语言，更幸运的是，AspectJ与java程序完全兼容，几乎是无缝关联，因此对于有java编程基础的工程师，上手和使用都非常容易. 其实AspectJ单独就是一门语言，它需要专门的编译器(ajc编译器). Spring AOP 与ApectJ的目的一致，都是为了统一处理横切业务，但与AspectJ不同的是，Spring AOP并不尝试提供完整的AOP功能(即使它完全可以实现)，Spring AOP 更注重的是与Spring IOC容器的结合，并结合该优势来解决横切业务的问题，因此在AOP的功能完善方面，相对来说AspectJ具有更大的优势，同时,Spring注意到AspectJ在AOP的实现方式上依赖于特殊编译器(ajc编译器)，因此Spring很机智回避了这点，转向采用动态代理技术的实现原理来构建Spring AOP的内部机制（动态织入），这是与AspectJ（静态织入）最根本的区别。在AspectJ 1.5后，引入@Aspect形式的注解风格的开发，Spring也非常快地跟进了这种方式，因此Spring 2.0后便使用了与AspectJ一样的注解。请注意，Spring 只是使用了与 AspectJ 5 一样的注解，但仍然没有使用 AspectJ 的编译器，底层依是动态代理技术的实现，因此并不依赖于 AspectJ 的编译器。 所以，大家要明白，Spring AOP虽然是使用了那一套注解，其实实现AOP的底层是使用了动态代理(JDK或者CGLib)来动态植入。至于AspectJ的静态植入，不是本文重点，所以只提一提。 2. Spring AOP - AspectJ注解谈到Spring AOP,老程序员应该比较清楚,之前的Spring AOP没有使用@Aspect这一套注解和aop:config这一套XML解决方案，而是开发者自己定义一些类实现一些接口，而且配置贼恶心。本文就不再演示了，后来Spring痛下决心,把AspectJ”整合”进了Spring当中，并开启了aop命名空间。现在的Sping AOP可以算是朗朗乾坤。上例子之前，还是把AOP的概念都提一提: 切点:定位到具体方法的一个表达式 切面: 切点+建言 建言(增强):定位到方法后干什么事 网上有很多概念，什么连接点，织入，目标对象，引入什么的。我个人觉得，在Java的Spring AOP领域，完全不用管。别把自己绕晕了。就按照我说的这三个概念就完事了，好了，先来搞个例子: maven依赖: 1234567891011121314151617181920212223242526272829303132333435 &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;4.2.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;4.2.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;4.2.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; //下面这两个aspectj的依赖是为了引入AspectJ的注解 &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjrt&lt;/artifactId&gt; &lt;version&gt;1.6.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.6.12&lt;/version&gt; &lt;/dependency&gt;//Spring AOP底层会使用CGLib来做动态代理 &lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;/dependency&gt;复制代码 小狗类，会说话: 123456789101112131415161718public class Dog &#123; private String name; public void say()&#123; System.out.println(name + "在汪汪叫!..."); &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125;复制代码 切面类: 1234567891011121314@Aspect //声明自己是一个切面类public class MyAspect &#123; /** * 前置通知 */ //@Before是增强中的方位 // @Before括号中的就是切入点了 //before()就是传说的增强(建言):说白了，就是要干啥事. @Before("execution(* com.zdy..*(..))") public void before()&#123; System.out.println("前置通知...."); &#125;&#125;复制代码 这个类是重点，先用@Aspect声明自己是切面类，然后before()为增强，@Before(方位)+切入点可以具体定位到具体某个类的某个方法的方位. Spring配置文件: 1234567 //开启AspectJ功能. &lt;aop:aspectj-autoproxy /&gt; &lt;bean id="dog" class="com.zdy.Dog" /&gt; &lt;!-- 定义aspect类 --&gt; &lt;bean name="myAspect" class="com.zdy.MyAspect"/&gt;复制代码 然后Main方法: 12345 ApplicationContext ac =new ClassPathXmlApplicationContext("applicationContext.xml"); Dog dog =(Dog) ac.getBean("dog"); System.out.println(dog.getClass()); dog.say();复制代码 输出结果: 1234class com.zdy.Dog$$EnhancerBySpringCGLIB$$80a9ee5f前置通知....null在汪汪叫!...复制代码 说白了，就是把切面类丢到容器，开启一个AdpectJ的功能，Spring AOP就会根据切面类中的(@Before+切入点)定位好具体的类的某个方法(我这里定义的是com.zdy包下的所有类的所有方法)，然后把增强before()切入进去. 然后说下Spring AOP支持的几种类似于@Before的AspectJ注解： 前置通知@Before: 前置通知通过@Before注解进行标注，并可直接传入切点表达式的值，该通知在目标函数执行前执行，注意JoinPoint，是Spring提供的静态变量，通过joinPoint 参数，可以获取目标对象的信息,如类名称,方法参数,方法名称等，该参数是可选的。 12345@Before("execution(...)")public void before(JoinPoint joinPoint)&#123; System.out.println("...");&#125;复制代码 后置通知@AfterReturning: 通过@AfterReturning注解进行标注，该函数在目标函数执行完成后执行，并可以获取到目标函数最终的返回值returnVal，当目标函数没有返回值时，returnVal将返回null，必须通过returning = “returnVal”注明参数的名称而且必须与通知函数的参数名称相同。请注意，在任何通知中这些参数都是可选的，需要使用时直接填写即可，不需要使用时，可以完成不用声明出来。 12345@AfterReturning(value="execution(...)",returning = "returnVal")public void AfterReturning(JoinPoint joinPoint,Object returnVal)&#123; System.out.println("我是后置通知...returnVal+"+returnVal);&#125;复制代码 异常通知 @AfterThrowing:该通知只有在异常时才会被触发，并由throwing来声明一个接收异常信息的变量，同样异常通知也用于Joinpoint参数，需要时加上即可. 12345@AfterThrowing(value="execution(....)",throwing = "e")public void afterThrowable(Throwable e)&#123; System.out.println("出现异常:msg="+e.getMessage());&#125;复制代码 最终通知 @After:该通知有点类似于finally代码块，只要应用了无论什么情况下都会执行. 12345@After("execution(...)")public void after(JoinPoint joinPoint) &#123; System.out.println("最终通知....");&#125;复制代码 环绕通知 @Around: 环绕通知既可以在目标方法前执行也可在目标方法之后执行，更重要的是环绕通知可以控制目标方法是否指向执行，但即使如此，我们应该尽量以最简单的方式满足需求，在仅需在目标方法前执行时，应该采用前置通知而非环绕通知。案例代码如下第一个参数必须是ProceedingJoinPoint，通过该对象的proceed()方法来执行目标函数，proceed()的返回值就是环绕通知的返回值。同样的，ProceedingJoinPoint对象也是可以获取目标对象的信息,如类名称,方法参数,方法名称等等 123456789@Around("execution(...)")public Object around(ProceedingJoinPoint joinPoint) throws Throwable &#123; System.out.println("我是环绕通知前...."); //执行目标函数 Object obj= (Object) joinPoint.proceed(); System.out.println("我是环绕通知后...."); return obj;&#125;复制代码 然后说下一直用”…”忽略掉的切入点表达式，这个表达式可以不是exection(..)，还有其他的一些，我就不说了，说最常用的execution: 12345678//scope ：方法作用域，如public,private,protect//returnt-type：方法返回值类型//fully-qualified-class-name：方法所在类的完全限定名称//parameters 方法参数execution(&lt;scope&gt; &lt;return-type&gt; &lt;fully-qualified-class-name&gt;.*(parameters))复制代码&lt;fully-qualified-class-name&gt;.*(parameters)复制代码 注意这一块，如果没有精确到class-name，而是到包名就停止了，要用两个”..”来表示包下的任意类: execution( com.zdy..(..))：com.zdy包下所有类的所有方法. execution( com.zdy.Dog.(..)): Dog类下的所有方法. 具体详细语法，大家如果有需求自行google了，我最常用的就是这俩了。要么按照包来定位，要么按照具体类来定位. 在使用切入点时，还可以抽出来一个@Pointcut来供使用: 1234567891011121314/** * 使用Pointcut定义切点 */@Pointcut("execution(...)")private void myPointcut()&#123;&#125;/** * 应用切入点函数 */@After(value="myPointcut()")public void afterDemo()&#123; System.out.println("最终通知....");&#125;复制代码 可以避免重复的execution在不同的注解里写很多遍… 作者：我又不是架构师 链接：https://juejin.im/post/5a55af9e518825734d14813f 来源：掘金]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>sping</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单实现IOC和AOP第一版]]></title>
    <url>%2F2019%2F05%2F16%2F%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0IOC%E5%92%8CAOP%2F</url>
    <content type="text"><![CDATA[简单实现一下了一下aop和ico，当然哈还是相当的简陋的。 spring这种顶级框架的学习真的不是一两天的事情，简单的阅读了一下ico的源码之后今天想来实现一下ico和aop。 IOCico比较关键的两个东西一个是要有一个bean的容器、另外就是要搞好bean的属性和依赖的注入。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public class SimpleIOC &#123; Map&lt;String,Object&gt; objectMap=new HashMap&lt;&gt;(); public SimpleIOC(String xmlLocation) &#123; try &#123; loadBean(xmlLocation); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public Object getBean(String beanName)&#123; return objectMap.get(beanName); &#125; //加载xml文件 private void loadBean(String xmlLocation) throws Exception &#123; File file=new File(xmlLocation); DocumentBuilder builder= DocumentBuilderFactory.newInstance().newDocumentBuilder(); Document doc = builder.parse(file); //获取xml文档 Element root = doc.getDocumentElement(); //加载根节点 beans NodeList childNodes = root.getChildNodes(); //一个个的bean for(int i=0;i&lt;childNodes.getLength();i++)&#123; Node item = childNodes.item(i); if(item instanceof Element)&#123; Element element= (Element) item; String id = element.getAttribute("id"); String aClass = element.getAttribute("class"); Class&lt;?&gt; aClass1 = Class.forName(aClass); Object bean=aClass1.newInstance(); NodeList property = element.getElementsByTagName("property"); for (int j = 0; j &lt;property.getLength() ; j++) &#123; Node item1 = property.item(j); if(item1 instanceof Element)&#123; //转换成一个标签 Element pro= (Element) item1; //获取属性 String name = pro.getAttribute("name"); String value = pro.getAttribute("value"); //利用反射设置属性设置位true Field declaredField = bean.getClass().getDeclaredField(name); declaredField.setAccessible(true); //获取属性的类别 String typeName = declaredField.getGenericType().getTypeName(); if(value!=null &amp;&amp; value.length()&gt;0)&#123; if("int".equals(typeName))&#123; //如果是int 类型转换 int values=Integer.valueOf(value); declaredField.set(bean,values); &#125;else &#123; declaredField.set(bean,value); &#125; &#125;else &#123; //依赖注入 String ref = pro.getAttribute("ref"); if (ref == null || ref.length() == 0) &#123; throw new IllegalArgumentException("ref config error"); &#125; // 将引用填充到相关字段中 declaredField.set(bean, getBean(ref)); &#125; // 将 bean 注册到 bean 容器中 registerBean(id, bean); &#125; &#125; &#125; &#125; &#125; //注入bean到容器 public void registerBean(String id, Object bean) &#123; objectMap.put(id,bean); &#125;&#125; 整个方法比较简单，属性dom的xml解析的话、这个看着简单的。 123456789public class Test &#123; public static void main(String[] args)&#123; //SimpleIOC.class.getClassLoader()就获取到了当前的类路径下。 //一个类的classLoader就是加载classpath下的 String file = SimpleIOC.class.getClassLoader().getResource("SimpleIOC.xml").getFile(); SimpleIOC ioc=new SimpleIOC(file); System.out.println(ioc.getBean("person")); &#125;&#125; AOP这里的aop并没有和ioc整合，只是简单的用Java的代理实现了aop编程 aop是实现代理是需要接口的，所有再spring中默认是使用Java的代理，但如果类没有实现接口那么它会自动使用cglib等方式来实现，这是对程序员完全透明的，我们也可以去设置他的代理方式 我们来看看完成一个aop需要一些什么 目标类的他的接口 通知Advice接口、当然这个通知可以是前，后，环绕等等。具体怎么操作要看怎么切 切面去实现InvocationHandler接口，现在invoke方法。 代理类，放回代理对象 其实可以用匿名内部类 123456789101112public class SimpleAOP &#123; public static Object geProxy(Object bean, MethodInvocation invocation)&#123; return Proxy.newProxyInstance(bean.getClass().getClassLoader(), bean.getClass().getInterfaces() , (proxy, method, args) -&gt; &#123; invocation.beforeAdvise(); Object invoke = method.invoke(bean, args); invocation.afterAdvise(); return invoke; &#125;); &#125;&#125; 有没有很简答，就收一个代理对象和一个通知接口，然后返回一个代理对象就ok了。 1234567891011User proxy = (User) SimpleAOP.geProxy(new UserImpl(), new MethodInvocation() &#123; @Override public void beforeAdvise() &#123; System.out.println("开始啦"); &#125; @Override public void afterAdvise() &#123; System.out.println("收钱了"); &#125; &#125;); proxy.doSome(); 怎么扩展嗯？ 也很简单，只要定义五个接口，分别是五种类型的通知，然后重载geProxy方法，使用的时候放入不同的接口不就实现了不同位置的通知了。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊聊编码]]></title>
    <url>%2F2019%2F05%2F14%2F%E8%81%8A%E8%81%8A%E7%BC%96%E7%A0%81%2F</url>
    <content type="text"><![CDATA[之前一直为各种各样的编码搞晕，一不小心中文就乱码了，为啥好好的就会乱码呢。 编码发展的故事ASCII 万恶之源，很久以前计算机只有在美国使用，他们认为128个可以特殊意义的字符就可以表示世间的万物，所以他们拿着一个个七位的0和1组成了一套编码，这就是ASCII编码。 标准ASCII 码也叫基础ASCII码，使用7 位二进制数（剩下的1位二进制为0）来表示所有的大写和小写字母，数字0 到9、标点符号。 iso-8859-1 很快计算机发展到了法国、德国，然后它们发现这128个完全不够表示所有的字符，于是他们将七位变成了八位，可以标识的字符也就有了256中，这就成了iso-8859-1，它没有去改变前面的128个ascii，但注意的是它补全了，每一个字符都是8位的二进制。 ASCII编码是一个7位的容器，ISO-8859-1编码是一个8位的容器。 gb2313 其实这个编码我不是很熟悉，可能是中国老程序员的一种编码了，当计算机传入中国以后，这256个位置哪里够存得下我们中华名族博大精深得汉字，但这难不倒我们聪明得中国人，我们想到了在128位后面加上我们自己得编码汉字，我们用16位得二进制表示一个汉字。就这样我们加上了常用的两三千汉字。这时候你会发现一个英文字母只占一个字节，但一个中文是两个字节喔。 gbk 很快，gb2313也不够用了，中国还有很多得不常见得生僻得字也要加上去，所有就又扩展了gbk。gbk还是很常见得把，在国内还是经常被用到得。 gb18030 这个就是把繁体字啊，几乎所有得汉字都扩展进去。 unicode 终于，世界上各个国家都有了自己的编码，导致各个国家看不懂对方得编码，操作系统就更是蒙蔽了。最后大家终于看不下去了，国际组织就出来将世界上所有的编码收集起来，放入一个编码，这就是unicode， unicode前面256个还是符合iso-8859-1的哦，记住。 Unicode（统一码、万国码、单一码）是计算机科学领域里的一项业界标准，包括字符集、编码方案等。Unicode 是为了解决传统的字符编码方案的局限而产生的，它为每种语言中的每个字符设定了统一并且唯一的二进制编码，以满足跨语言、跨平台进行文本转换、处理的要求。1990年开始研发，1994年正式公布 在unicode里面，任何一个字符都是二个字节，16位二进制数字。 utf-8 最后终于到了utf-8，准确得来说，utf-8不算是编码而来，它并没有去规定什么什么二进制数字是什么什么字符，它只是一种unicode的实现。它是一种存储的方式，本质来讲它是符合unicode编码的，是unicode的压缩 那utf-8和unicode有说明区别呢。我们知道在unicode里面任何字符都是二个字节，这导致说明问题呢，在文件的存储上和网络信息的传播上，造成了极大的空间浪费和流浪浪费，本来只要传一个八位的，最后还是要补全成16位。这显然不是很合理。所有就有了utf-8这样的编码。在utf-8里面低位用一个字节，后面还有2-6个字节，中文大多数都是生成三个字节。 说utf-8是unicode一种压缩、一种储存方式，那到底是怎么储存的呢。 1234567Unicode符号范围 | UTF-8编码方式 (十六进制) | （二进制） --------------------+--------------------------------------------- 0000 0000-0000 007F | 0xxxxxxx //低位0000 0080-0000 07FF | 110xxxxx 10xxxxxx //中位0000 0800-0000 FFFF | 1110xxxx 10xxxxxx 10xxxxxx //高位0001 0000-0010 FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx 解释一下： 1）对于单字节的符号，字节的第一位设为0，后面7位为这个符号的unicode码。因此对于英语字母，UTF-8编码和ASCII码是相同的。 2）对于n字节的符号（n&gt;1），第一个字节的前n位都设为1，第n+1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的unicode码。 模拟一下utf-8解码：如果直接读到0，那么久把接下来的七个解码。如果读到了1，就继续到看读到几个1，它就知道有几个字节要读，读下来在对照unicode解码。 Test12345678910111213141516171819202122232425262728293031323334public class CodeTest &#123; public static void main(String[] args) throws IOException &#123; //获取文件 RandomAccessFile input=new RandomAccessFile("baseStudy\\input","r"); RandomAccessFile output=new RandomAccessFile("baseStudy\\output","rw"); long length = new File("baseStudy\\input").length(); //获取通道 FileChannel in = input.getChannel(); FileChannel out = output.getChannel(); //读取映射到buffer MappedByteBuffer inputData = in.map(FileChannel.MapMode.READ_ONLY, 0, length); //看看系统支持的编码格式// Charset.availableCharsets().forEach((k,v)-&gt;&#123;// System.out.println(k+" :"+" "+v);// &#125;); //获取编码解码的对象 Charset charset=Charset.forName("iso-8859-1"); CharsetEncoder charsetEncoder = charset.newEncoder(); CharsetDecoder charsetDecoder = charset.newDecoder(); // charset.decode(inputData) ; // 直接用charset也可以编码解码，底层其实就是调用CharsetDecoder、CharsetEncoder CharBuffer decode = charsetDecoder.decode(inputData); //打印解码结果 System.out.println(String.valueOf(decode.array())); ByteBuffer encode = charsetEncoder.encode(decode); //写入文件 out.write(encode); input.close(); output.close(); &#125;&#125; 我写了个读取文件写入文件的代码，读取文件里面有中文，然后用iso-8859-1解码然后再编码。 最后写出去的结果没有乱码，但是控制台打印的结果是乱码的 为什么呢？为什么一个utf-8的文件用iso-8859-1编码解码不会乱码。如果有仔细看前面utf-8和iso-8859-1，这就容易理解了，一个utf-8的文件的字节流其实都是8位的字节，这些字节用iso-8859-1去解码成字符不会发生任何的精度数据丢失，只不过是把utf-8的字节流当成一个个的字节去iso-8859-1的编码表里找对应的字符。 这样我们三个字节一个中文的再iso-8859-1这里全是一个字节的字符，所以再控制台打印中文肯定是乱码的 但我们再用iso-8859-1进行编码，字符又变回了一个个八位字节，而且字节内容是没有丢失没有改变喔！所以写入文件之后文件再以utf-8的编码解码，就获得了准确的中文啦。 那如果我直接用 ASCII 编码解码会怎么样的。emmmm就直接出错了。为什么呢？ASCII是七位的啊，直接boom 所以我们用iso-8859-1方式解码保存任何八位组合字节流数据是没问题的！不会有数据丢失，只要再以iso-8859-1编码会去就好。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>计算机基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring加载bean都干了嘛？]]></title>
    <url>%2F2019%2F05%2F13%2FSpring%E5%8A%A0%E8%BD%BDbean%E9%83%BD%E5%B9%B2%E4%BA%86%E5%98%9B%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[Spring一些基础基本概念之前已经复习过，然后说起IOC，AOP也就知道它用了什么原理，但具体怎么实现没有去研究过，今天我就来简单的看看IOC的实现过程。 总览ICO的实现 beans包是spring容器核心的一些组件。包括工厂、配置。和IOC切切相关 context是beans的功能扩展，实现了IOC的容器，容器也分很多种 core是一些核心类和接口，还有工具类 aop负责spring的AOP的实现。 我们用的时候需要一个容器，它来自于context，容器之所以能生产beans，依靠的是beans里面的各种工厂，工厂能跑起来需要core里面的种种功能动力。最后达成了IOC的效果这个效果 ICO容器的使用123// 用我们的配置文件来启动一个 ApplicationContext(配置容器)ApplicationContext context = new ClassPathXmlApplicationContext("classpath:application.xml");context.getBean(SomeBean.class); 我们就直接可以new 出一个容器来，传个它一个配置文件，ApplicationContext、ClassPathXmlApplicationContext它们都属于哪个包呢， 12import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext; 显然它们是一个继承关系ApplicationContext是接口ClassPathXmlApplicationContext是实现，其实context包下面的容器实现还有很多，关系图如下： 重点需要关注的是标红和标绿的 我们可以看到，ClassPathXmlApplicationContext 兜兜转转了好久才到 ApplicationContext 接口，同样的，我们也可以使用绿颜色的 FileSystemXmlApplicationContext 和 AnnotationConfigApplicationContext 这两个类。 FileSystemXmlApplicationContext 的构造函数需要一个 xml 配置文件在系统中的路径，其他和 ClassPathXmlApplicationContext 基本上一样。 AnnotationConfigApplicationContext 是基于注解来使用的，它不需要配置文件，采用 java 配置类和各种注解来配置，是比较简单的方式，也是大势所趋吧。 当然我就不全看它们的实现了，主要看看ClassPathXmlApplicationContext 的实现流程。 BeanFactory 简介BeanFactory，从名字上也很好理解，生产 bean 的工厂，它负责生产和管理各个 bean 实例。 初学者可别以为我之前说那么多和 BeanFactory 无关，前面说的 ApplicationContext 其实就是一个 BeanFactory。我们来看下和 BeanFactory 接口相关的主要的继承结构： 这张图呢，背下来肯定是不需要的，有几个重点和大家说明下就好： ApplicationContext 继承了 ListableBeanFactory，这个 Listable 的意思就是，通过这个接口，我们可以获取多个 Bean，大家看源码会发现，最顶层 BeanFactory 接口的方法都是获取单个 Bean 的。 ApplicationContext 继承了 HierarchicalBeanFactory，Hierarchical 单词本身已经能说明问题了，也就是说我们可以在应用中起多个 BeanFactory，然后可以将各个 BeanFactory 设置为父子关系。 AutowireCapableBeanFactory 这个名字中的 Autowire 大家都非常熟悉，它就是用来自动装配 Bean 用的，但是仔细看上图，ApplicationContext 并没有继承它，不过不用担心，不使用继承，不代表不可以使用组合，如果你看到 ApplicationContext 接口定义中的最后一个方法 getAutowireCapableBeanFactory() 就知道了。 ConfigurableListableBeanFactory 也是一个特殊的接口，看图，特殊之处在于它继承了第二层所有的三个接口，而 ApplicationContext 没有。这点之后会用到。 启动流程前面已经提到我们使用容器的句柄就是 new ClassPathXmlApplicationContext(“classpath:application.xml”);既然是new出来的我们就直接看看ClassPathXmlApplicationContext的构造函数： 123456789101112131415// 如果已经有 ApplicationContext 并需要配置成父子关系，那么调用这个构造方法 public ClassPathXmlApplicationContext(ApplicationContext parent) &#123; super(parent); &#125; ...public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent) throws BeansException &#123; super(parent); // 根据提供的路径，处理成配置文件数组(以分号、逗号、空格、tab、换行符分割) setConfigLocations(configLocations); if (refresh) &#123; refresh(); // 核心方法 &#125;&#125; 逻辑很简单，简单处理之后直接调用refresh()方法进行容器加载。 从源码来看，5.0.8的refresh()方法并没有重写，也是直接使用父类的AbstractXmlApplicationContext的refresh() 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public void refresh() throws BeansException, IllegalStateException &#123; // 来个锁，不然 refresh() 还没结束，你又来个启动或销毁容器的操作，那不就乱套了嘛 synchronized (this.startupShutdownMonitor) &#123; // 准备工作，记录下容器的启动时间、标记“已启动”状态、处理配置文件中的占位符 prepareRefresh(); // 这步比较关键，这步完成后，配置文件就会解析成一个个 Bean 定义，注册到 BeanFactory 中， // 当然，这里说的 Bean 还没有初始化，只是配置信息都提取出来了， // 注册也只是将这些信息都保存到了注册中心(说到底核心是一个 beanName-&gt; beanDefinition 的 map) ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 设置 BeanFactory 的类加载器，添加几个 BeanPostProcessor，手动注册几个特殊的 bean // 这块待会会展开说 prepareBeanFactory(beanFactory); try &#123; // 【这里需要知道 BeanFactoryPostProcessor 这个知识点，Bean 如果实现了此接口， // 那么在容器初始化以后，Spring 会负责调用里面的 postProcessBeanFactory 方法。】 // 这里是提供给子类的扩展点，到这里的时候，所有的 Bean 都加载、注册完成了，但是都还没有初始化 // 具体的子类可以在这步的时候添加一些特殊的 BeanFactoryPostProcessor 的实现类或做点什么事 postProcessBeanFactory(beanFactory); // 调用 BeanFactoryPostProcessor 各个实现类的 postProcessBeanFactory(factory) 方法 invokeBeanFactoryPostProcessors(beanFactory); // 注册 BeanPostProcessor 的实现类，注意看和 BeanFactoryPostProcessor 的区别 // 此接口两个方法: postProcessBeforeInitialization 和 postProcessAfterInitialization // 两个方法分别在 Bean 初始化之前和初始化之后得到执行。注意，到这里 Bean 还没初始化 registerBeanPostProcessors(beanFactory); // 初始化当前 ApplicationContext 的 MessageSource，国际化这里就不展开说了，不然没完没了了 initMessageSource(); // 初始化当前 ApplicationContext 的事件广播器，这里也不展开了 initApplicationEventMulticaster(); // 从方法名就可以知道，典型的模板方法(钩子方法)， // 具体的子类可以在这里初始化一些特殊的 Bean（在初始化 singleton beans 之前） onRefresh(); // 注册事件监听器，监听器需要实现 ApplicationListener 接口。这也不是我们的重点，过 registerListeners(); // 重点，重点，重点 // 初始化所有的 singleton beans //（lazy-init 的除外） finishBeanFactoryInitialization(beanFactory); // 最后，广播事件，ApplicationContext 初始化完成 finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn("Exception encountered during context initialization - " + "cancelling refresh attempt: " + ex); &#125; // Destroy already created singletons to avoid dangling resources. // 销毁已经初始化的 singleton 的 Beans，以免有些 bean 会一直占用资源 destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // 把异常往外抛 throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; 这里做了很多件事情，大致来看就是要做这么两个主要的事情：一个是创建 Bean 容器，一个是初始化 Bean， 好吧，我们一个一个的来看看： 创建 Bean 容器前的准备工作这个比较简单，直接看代码中的几个注释即可。 12345678910111213141516171819protected void prepareRefresh() &#123; // 记录启动时间， // 将 active 属性设置为 true，closed 属性设置为 false，它们都是 AtomicBoolean 类型 this.startupDate = System.currentTimeMillis(); this.closed.set(false); this.active.set(true); if (logger.isInfoEnabled()) &#123; logger.info("Refreshing " + this); &#125; // Initialize any placeholder property sources in the context environment initPropertySources(); // 校验 xml 配置文件 getEnvironment().validateRequiredProperties(); this.earlyApplicationEvents = new LinkedHashSet&lt;ApplicationEvent&gt;();&#125; 创建 Bean 容器，加载并注册 Bean我们回到 refresh() 方法中的下一行 obtainFreshBeanFactory()。 注意，这个方法是全文最重要的部分之一，这里将会初始化 BeanFactory、加载 Bean、注册 Bean 等等。 当然，这步结束后，Bean 并没有完成初始化。这里指的是 Bean 实例并未在这一步生成。 // AbstractApplicationContext.java 1234567891011protected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123; // 关闭旧的 BeanFactory (如果有)，创建新的 BeanFactory，加载 Bean 定义、注册 Bean 等等 refreshBeanFactory(); // 返回刚刚创建的 BeanFactory ConfigurableListableBeanFactory beanFactory = getBeanFactory(); if (logger.isDebugEnabled()) &#123; logger.debug("Bean factory for " + getDisplayName() + ": " + beanFactory); &#125; return beanFactory;&#125; // AbstractRefreshableApplicationContext.java 120 1234567891011121314151617181920212223242526272829@Overrideprotected final void refreshBeanFactory() throws BeansException &#123; // 如果 ApplicationContext 中已经加载过 BeanFactory 了，销毁所有 Bean，关闭 BeanFactory // 注意，应用中 BeanFactory 本来就是可以多个的，这里可不是说应用全局是否有 BeanFactory，而是当前 // ApplicationContext 是否有 BeanFactory if (hasBeanFactory()) &#123; destroyBeans(); closeBeanFactory(); &#125; try &#123; // 初始化一个 DefaultListableBeanFactory，为什么用这个，我们马上说。 DefaultListableBeanFactory beanFactory = createBeanFactory(); // 用于 BeanFactory 的序列化，我想不部分人应该都用不到 beanFactory.setSerializationId(getId()); // 下面这两个方法很重要，别跟丢了，具体细节之后说 // 设置 BeanFactory 的两个配置属性：是否允许 Bean 覆盖、是否允许循环引用 customizeBeanFactory(beanFactory); // 加载 Bean 到 BeanFactory 中 loadBeanDefinitions(beanFactory); synchronized (this.beanFactoryMonitor) &#123; this.beanFactory = beanFactory; &#125; &#125; catch (IOException ex) &#123; throw new ApplicationContextException("I/O error parsing bean definition source for " + getDisplayName(), ex); &#125;&#125; 看到这里的时候，我觉得读者就应该站在高处看 ApplicationContext 了，ApplicationContext 继承自 BeanFactory，但是它不应该被理解为 BeanFactory 的实现类，而是说其内部持有一个实例化的 BeanFactory（DefaultListableBeanFactory）。以后所有的 BeanFactory 相关的操作其实是委托给这个实例来处理的。 我们说说为什么选择实例化 DefaultListableBeanFactory ？前面我们说了有个很重要的接口 ConfigurableListableBeanFactory，它实现了 BeanFactory 下面一层的所有三个接口，我把之前的继承图再拿过来大家再仔细看一下： 我们可以看到 ConfigurableListableBeanFactory 只有一个实现类 DefaultListableBeanFactory，而且实现类 DefaultListableBeanFactory 还通过实现右边的 AbstractAutowireCapableBeanFactory 通吃了右路。所以结论就是，最底下这个家伙 DefaultListableBeanFactory 基本上是最牛的 BeanFactory 了，这也是为什么这边会使用这个类来实例化的原因。 如果你想要在程序运行的时候动态往 Spring IOC 容器注册新的 bean，就会使用到这个类。那我们怎么在运行时获得这个实例呢？ 之前我们说过 ApplicationContext 接口能获取到 AutowireCapableBeanFactory，就是最右上角那个，然后它向下转型就能得到 DefaultListableBeanFactory 了。 在继续往下之前，我们需要先了解 BeanDefinition。我们说 BeanFactory 是 Bean 容器，那么 Bean 又是什么呢？ 这里的 BeanDefinition 就是我们所说的 Spring 的 Bean，我们自己定义的各个 Bean 其实会转换成一个个 BeanDefinition 存在于 Spring 的 BeanFactory 中。 所以，如果有人问你 Bean 是什么的时候，你要知道 Bean 在代码层面上可以认为是 BeanDefinition 的实例。 BeanDefinition 中保存了我们的 Bean 信息，比如这个 Bean 指向的是哪个类、是否是单例的、是否懒加载、这个 Bean 依赖了哪些 Bean 等等。 BeanDefinition 接口定义我们来看下 BeanDefinition 的接口定义： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public interface BeanDefinition extends AttributeAccessor, BeanMetadataElement &#123; // 我们可以看到，默认只提供 sington 和 prototype 两种， // 很多读者可能知道还有 request, session, globalSession, application, websocket 这几种， // 不过，它们属于基于 web 的扩展。 String SCOPE_SINGLETON = ConfigurableBeanFactory.SCOPE_SINGLETON; String SCOPE_PROTOTYPE = ConfigurableBeanFactory.SCOPE_PROTOTYPE; // 比较不重要，直接跳过吧 int ROLE_APPLICATION = 0; int ROLE_SUPPORT = 1; int ROLE_INFRASTRUCTURE = 2; // 设置父 Bean，这里涉及到 bean 继承，不是 java 继承。请参见附录的详细介绍 // 一句话就是：继承父 Bean 的配置信息而已 void setParentName(String parentName); // 获取父 Bean String getParentName(); // 设置 Bean 的类名称，将来是要通过反射来生成实例的 void setBeanClassName(String beanClassName); // 获取 Bean 的类名称 String getBeanClassName(); // 设置 bean 的 scope void setScope(String scope); String getScope(); // 设置是否懒加载 void setLazyInit(boolean lazyInit); boolean isLazyInit(); // 设置该 Bean 依赖的所有的 Bean，注意，这里的依赖不是指属性依赖(如 @Autowire 标记的)， // 是 depends-on="" 属性设置的值。 void setDependsOn(String... dependsOn); // 返回该 Bean 的所有依赖 String[] getDependsOn(); // 设置该 Bean 是否可以注入到其他 Bean 中，只对根据类型注入有效， // 如果根据名称注入，即使这边设置了 false，也是可以的 void setAutowireCandidate(boolean autowireCandidate); // 该 Bean 是否可以注入到其他 Bean 中 boolean isAutowireCandidate(); // 主要的。同一接口的多个实现，如果不指定名字的话，Spring 会优先选择设置 primary 为 true 的 bean void setPrimary(boolean primary); // 是否是 primary 的 boolean isPrimary(); // 如果该 Bean 采用工厂方法生成，指定工厂名称。对工厂不熟悉的读者，请参加附录 // 一句话就是：有些实例不是用反射生成的，而是用工厂模式生成的 void setFactoryBeanName(String factoryBeanName); // 获取工厂名称 String getFactoryBeanName(); // 指定工厂类中的 工厂方法名称 void setFactoryMethodName(String factoryMethodName); // 获取工厂类中的 工厂方法名称 String getFactoryMethodName(); // 构造器参数 ConstructorArgumentValues getConstructorArgumentValues(); // Bean 中的属性值，后面给 bean 注入属性值的时候会说到 MutablePropertyValues getPropertyValues(); // 是否 singleton boolean isSingleton(); // 是否 prototype boolean isPrototype(); // 如果这个 Bean 是被设置为 abstract，那么不能实例化， // 常用于作为 父bean 用于继承，其实也很少用...... boolean isAbstract(); int getRole(); String getDescription(); String getResourceDescription(); BeanDefinition getOriginatingBeanDefinition();&#125; 这个 BeanDefinition 其实已经包含很多的信息了，暂时不清楚所有的方法对应什么东西没关系，希望看完本文后读者可以彻底搞清楚里面的所有东西。 这里接口虽然那么多，但是没有类似 getInstance() 这种方法来获取我们定义的类的实例，真正的我们定义的类生成的实例到哪里去了呢？别着急，这个要很后面才能讲到。 有了 BeanDefinition 的概念以后，我们再往下看 refreshBeanFactory() 方法中的剩余部分： 12customizeBeanFactory(beanFactory);loadBeanDefinitions(beanFactory); 虽然只有两个方法，但路还很长啊。。。 customizeBeanFactorycustomizeBeanFactory(beanFactory) 比较简单，就是配置是否允许 BeanDefinition 覆盖、是否允许循环引用。 12345678910protected void customizeBeanFactory(DefaultListableBeanFactory beanFactory) &#123; if (this.allowBeanDefinitionOverriding != null) &#123; // 是否允许 Bean 定义覆盖 beanFactory.setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding); &#125; if (this.allowCircularReferences != null) &#123; // 是否允许 Bean 间的循环依赖 beanFactory.setAllowCircularReferences(this.allowCircularReferences); &#125;&#125; BeanDefinition 的覆盖问题可能会有开发者碰到这个坑，就是在配置文件中定义 bean 时使用了相同的 id 或 name，默认情况下，allowBeanDefinitionOverriding 属性为 null，如果在同一配置文件中重复了，会抛错，但是如果不是同一配置文件中，会发生覆盖。 循环引用也很好理解：A 依赖 B，而 B 依赖 A。或 A 依赖 B，B 依赖 C，而 C 依赖 A。 默认情况下，Spring 允许循环依赖，当然如果你在 A 的构造方法中依赖 B，在 B 的构造方法中依赖 A 是不行的。 至于这两个属性怎么配置？我在附录中进行了介绍，尤其对于覆盖问题，很多人都希望禁止出现 Bean 覆盖，可是 Spring 默认是不同文件的时候可以覆盖的。 之后的源码中还会出现这两个属性，读者有个印象就可以了。 加载 Bean: loadBeanDefinitions接下来是最重要的 loadBeanDefinitions(beanFactory) 方法了，这个方法将根据配置，加载各个 Bean，然后放到 BeanFactory 中。 读取配置的操作在 XmlBeanDefinitionReader 中，其负责加载配置、解析。 // AbstractXmlApplicationContext.java 80 123456789101112131415161718/** 我们可以看到，此方法将通过一个 XmlBeanDefinitionReader 实例来加载各个 Bean。*/@Overrideprotected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException &#123; // 给这个 BeanFactory 实例化一个 XmlBeanDefinitionReader XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); // Configure the bean definition reader with this context's // resource loading environment. beanDefinitionReader.setEnvironment(this.getEnvironment()); beanDefinitionReader.setResourceLoader(this); beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); // 初始化 BeanDefinitionReader，其实这个是提供给子类覆写的， // 我看了一下，没有类覆写这个方法，我们姑且当做不重要吧 initBeanDefinitionReader(beanDefinitionReader); // 重点来了，继续往下 loadBeanDefinitions(beanDefinitionReader);&#125; 现在还在这个类中，接下来用刚刚初始化的 Reader 开始来加载 xml 配置，这块代码读者可以选择性跳过，不是很重要。也就是说，下面这个代码块，读者可以很轻松地略过。 // AbstractXmlApplicationContext.java 120 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104protected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws BeansException, IOException &#123; Resource[] configResources = getConfigResources(); if (configResources != null) &#123; // 往下看 reader.loadBeanDefinitions(configResources); &#125; String[] configLocations = getConfigLocations(); if (configLocations != null) &#123; // 2 reader.loadBeanDefinitions(configLocations); &#125;&#125;// 上面虽然有两个分支，不过第二个分支很快通过解析路径转换为 Resource 以后也会进到这里@Overridepublic int loadBeanDefinitions(Resource... resources) throws BeanDefinitionStoreException &#123; Assert.notNull(resources, "Resource array must not be null"); int counter = 0; // 注意这里是个 for 循环，也就是每个文件是一个 resource for (Resource resource : resources) &#123; // 继续往下看 counter += loadBeanDefinitions(resource); &#125; // 最后返回 counter，表示总共加载了多少的 BeanDefinition return counter;&#125;// XmlBeanDefinitionReader 303@Overridepublic int loadBeanDefinitions(Resource resource) throws BeanDefinitionStoreException &#123; return loadBeanDefinitions(new EncodedResource(resource));&#125;// XmlBeanDefinitionReader 314public int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreException &#123; Assert.notNull(encodedResource, "EncodedResource must not be null"); if (logger.isInfoEnabled()) &#123; logger.info("Loading XML bean definitions from " + encodedResource.getResource()); &#125; // 用一个 ThreadLocal 来存放配置文件资源 Set&lt;EncodedResource&gt; currentResources = this.resourcesCurrentlyBeingLoaded.get(); if (currentResources == null) &#123; currentResources = new HashSet&lt;EncodedResource&gt;(4); this.resourcesCurrentlyBeingLoaded.set(currentResources); &#125; if (!currentResources.add(encodedResource)) &#123; throw new BeanDefinitionStoreException( "Detected cyclic loading of " + encodedResource + " - check your import definitions!"); &#125; try &#123; InputStream inputStream = encodedResource.getResource().getInputStream(); try &#123; InputSource inputSource = new InputSource(inputStream); if (encodedResource.getEncoding() != null) &#123; inputSource.setEncoding(encodedResource.getEncoding()); &#125; // 核心部分是这里，往下面看 return doLoadBeanDefinitions(inputSource, encodedResource.getResource()); &#125; finally &#123; inputStream.close(); &#125; &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException( "IOException parsing XML document from " + encodedResource.getResource(), ex); &#125; finally &#123; currentResources.remove(encodedResource); if (currentResources.isEmpty()) &#123; this.resourcesCurrentlyBeingLoaded.remove(); &#125; &#125;&#125;// 还在这个文件中，第 388 行protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException &#123; try &#123; // 这里就不看了，将 xml 文件转换为 Document 对象 Document doc = doLoadDocument(inputSource, resource); // 继续 return registerBeanDefinitions(doc, resource); &#125; catch (...&#125;// 还在这个文件中，第 505 行// 返回值：返回从当前配置文件加载了多少数量的 Beanpublic int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException &#123; BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader(); int countBefore = getRegistry().getBeanDefinitionCount(); // 这里 documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); return getRegistry().getBeanDefinitionCount() - countBefore;&#125;// DefaultBeanDefinitionDocumentReader 90@Overridepublic void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) &#123; this.readerContext = readerContext; logger.debug("Loading bean definitions"); Element root = doc.getDocumentElement(); // 从 xml 根节点开始解析文件 doRegisterBeanDefinitions(root);&#125; 经过漫长的链路，一个配置文件终于转换为一颗 DOM 树了，注意，这里指的是其中一个配置文件，不是所有的，读者可以看到上面有个 for 循环的。下面开始从根节点开始解析： doRegisterBeanDefinitions：123456789101112131415161718192021222324252627282930313233// DefaultBeanDefinitionDocumentReader 116protected void doRegisterBeanDefinitions(Element root) &#123; // 我们看名字就知道，BeanDefinitionParserDelegate 必定是一个重要的类，它负责解析 Bean 定义， // 这里为什么要定义一个 parent? 看到后面就知道了，是递归问题， // 因为 &lt;beans /&gt; 内部是可以定义 &lt;beans /&gt; 的，所以这个方法的 root 其实不一定就是 xml 的根节点，也可以是嵌套在里面的 &lt;beans /&gt; 节点，从源码分析的角度，我们当做根节点就好了 BeanDefinitionParserDelegate parent = this.delegate; this.delegate = createDelegate(getReaderContext(), root, parent); if (this.delegate.isDefaultNamespace(root)) &#123; // 这块说的是根节点 &lt;beans ... profile="dev" /&gt; 中的 profile 是否是当前环境需要的， // 如果当前环境配置的 profile 不包含此 profile，那就直接 return 了，不对此 &lt;beans /&gt; 解析 // 不熟悉 profile 为何物，不熟悉怎么配置 profile 读者的请移步附录区 String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE); if (StringUtils.hasText(profileSpec)) &#123; String[] specifiedProfiles = StringUtils.tokenizeToStringArray( profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS); if (!getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) &#123; if (logger.isInfoEnabled()) &#123; logger.info("Skipped XML bean definition file due to specified profiles [" + profileSpec + "] not matching: " + getReaderContext().getResource()); &#125; return; &#125; &#125; &#125; preProcessXml(root); // 钩子 // 往下看 parseBeanDefinitions(root, this.delegate); postProcessXml(root); // 钩子 this.delegate = parent;&#125; preProcessXml(root) 和 postProcessXml(root) 是给子类用的钩子方法，鉴于没有被使用到，也不是我们的重点，我们直接跳过。 这里涉及到了 profile 的问题，对于不了解的读者，我在附录中对 profile 做了简单的解释，读者可以参考一下。 接下来，看核心解析方法 parseBeanDefinitions(root, this.delegate) : 123456789101112131415161718192021222324// default namespace 涉及到的就四个标签 &lt;import /&gt;、&lt;alias /&gt;、&lt;bean /&gt; 和 &lt;beans /&gt;，// 其他的属于 custom 的protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123; if (delegate.isDefaultNamespace(root)) &#123; NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); if (node instanceof Element) &#123; Element ele = (Element) node; if (delegate.isDefaultNamespace(ele)) &#123; // 解析 default namespace 下面的几个元素 parseDefaultElement(ele, delegate); &#125; else &#123; // 解析其他 namespace 的元素 delegate.parseCustomElement(ele); &#125; &#125; &#125; &#125; else &#123; delegate.parseCustomElement(root); &#125;&#125; 从上面的代码，我们可以看到，对于每个配置来说，分别进入到 parseDefaultElement(ele, delegate); 和 delegate.parseCustomElement(ele); 这两个分支了。 parseDefaultElement(ele, delegate) 代表解析的节点是 &lt;import /&gt;、&lt;alias /&gt;、&lt;bean /&gt;、&lt;beans /&gt; 这几个。 这里的四个标签之所以是 default 的，是因为它们是处于这个 namespace 下定义的： 12&gt; http://www.springframework.org/schema/beans&gt; 又到初学者科普时间，不熟悉 namespace 的读者请看下面贴出来的 xml，这里的第二行 xmlns 就是咯。 1234567&gt; &lt;beans xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"&gt; xmlns="http://www.springframework.org/schema/beans"&gt; xsi:schemaLocation="&gt; http://www.springframework.org/schema/beans&gt; http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; default-autowire="byName"&gt;&gt; 而对于其他的标签，将进入到 delegate.parseCustomElement(element) 这个分支。如我们经常会使用到的 &lt;mvc /&gt;、&lt;task /&gt;、&lt;context /&gt;、&lt;aop /&gt;等。 这些属于扩展，如果需要使用上面这些 ”非 default“ 标签，那么上面的 xml 头部的地方也要引入相应的 namespace 和 .xsd 文件的路径，如下所示。同时代码中需要提供相应的 parser 来解析，如 MvcNamespaceHandler、TaskNamespaceHandler、ContextNamespaceHandler、AopNamespaceHandler 等。 假如读者想分析 &lt;context:property-placeholder location=&quot;classpath:xx.properties&quot; /&gt; 的实现原理，就应该到 ContextNamespaceHandler 中找答案。 1234567891011121314&gt; &lt;beans xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"&gt; xmlns="http://www.springframework.org/schema/beans"&gt; xmlns:context="http://www.springframework.org/schema/context"&gt; xmlns:mvc="http://www.springframework.org/schema/mvc"&gt; xsi:schemaLocation="&gt; http://www.springframework.org/schema/beans &gt; http://www.springframework.org/schema/beans/spring-beans.xsd&gt; http://www.springframework.org/schema/context&gt; http://www.springframework.org/schema/context/spring-context.xsd&gt; http://www.springframework.org/schema/mvc &gt; http://www.springframework.org/schema/mvc/spring-mvc.xsd &gt; "&gt; default-autowire="byName"&gt;&gt; 回过神来，看看处理 default 标签的方法： 12345678910111213141516171819private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) &#123; if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) &#123; // 处理 &lt;import /&gt; 标签 importBeanDefinitionResource(ele); &#125; else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) &#123; // 处理 &lt;alias /&gt; 标签定义 // &lt;alias name="fromName" alias="toName"/&gt; processAliasRegistration(ele); &#125; else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) &#123; // 处理 &lt;bean /&gt; 标签定义，这也算是我们的重点吧 processBeanDefinition(ele, delegate); &#125; else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) &#123; // 如果碰到的是嵌套的 &lt;beans /&gt; 标签，需要递归 doRegisterBeanDefinitions(ele); &#125;&#125; 如果每个标签都说，那我不吐血，你们都要吐血了。我们挑我们的重点 &lt;bean /&gt; 标签出来说。 processBeanDefinition 解析 bean 标签下面是 processBeanDefinition 解析 &lt;bean /&gt; 标签： // DefaultBeanDefinitionDocumentReader 298 1234567891011121314151617181920protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) &#123; // 将 &lt;bean /&gt; 节点中的信息提取出来，然后封装到一个 BeanDefinitionHolder 中，细节往下看 BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); // 下面的几行先不要看，跳过先，跳过先，跳过先，后面会继续说的 if (bdHolder != null) &#123; bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); try &#123; // Register the final decorated instance. BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry()); &#125; catch (BeanDefinitionStoreException ex) &#123; getReaderContext().error("Failed to register bean definition with name '" + bdHolder.getBeanName() + "'", ele, ex); &#125; // Send registration event. getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder)); &#125;&#125; 继续往下看怎么解析之前，我们先看下 标签中可以定义哪些属性： Property class 类的全限定名 name 可指定 id、name(用逗号、分号、空格分隔) scope 作用域 constructor arguments 指定构造参数 properties 设置属性的值 autowiring mode no(默认值)、byName、byType、 constructor lazy-initialization mode 是否懒加载(如果被非懒加载的bean依赖了那么其实也就不能懒加载了) initialization method bean 属性设置完成后，会调用这个方法 destruction method bean 销毁后的回调方法 上面表格中的内容我想大家都非常熟悉吧，如果不熟悉，那就是你不够了解 Spring 的配置了。 简单地说就是像下面这样子： 123456789101112131415&lt;bean id="exampleBean" name="name1, name2, name3" class="com.javadoop.ExampleBean" scope="singleton" lazy-init="true" init-method="init" destroy-method="cleanup"&gt; &lt;!-- 可以用下面三种形式指定构造参数 --&gt; &lt;constructor-arg type="int" value="7500000"/&gt; &lt;constructor-arg name="years" value="7500000"/&gt; &lt;constructor-arg index="0" value="7500000"/&gt; &lt;!-- property 的几种情况 --&gt; &lt;property name="beanOne"&gt; &lt;ref bean="anotherExampleBean"/&gt; &lt;/property&gt; &lt;property name="beanTwo" ref="yetAnotherBean"/&gt; &lt;property name="integerProperty" value="1"/&gt;&lt;/bean&gt; 当然，除了上面举例出来的这些，还有 factory-bean、factory-method、&lt;lockup-method /&gt;、&lt;replaced-method /&gt;、&lt;meta /&gt;、&lt;qualifier /&gt; 这几个，大家是不是熟悉呢？自己检验一下自己对 Spring 中 bean 的了解程度。 有了以上这些知识以后，我们再继续往里看怎么解析 bean 元素，是怎么转换到 BeanDefinitionHolder 的。 // BeanDefinitionParserDelegate 428 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public BeanDefinitionHolder parseBeanDefinitionElement(Element ele) &#123; return parseBeanDefinitionElement(ele, null);&#125;public BeanDefinitionHolder parseBeanDefinitionElement(Element ele, BeanDefinition containingBean) &#123; String id = ele.getAttribute(ID_ATTRIBUTE); String nameAttr = ele.getAttribute(NAME_ATTRIBUTE); List&lt;String&gt; aliases = new ArrayList&lt;String&gt;(); // 将 name 属性的定义按照 “逗号、分号、空格” 切分，形成一个 别名列表数组， // 当然，如果你不定义 name 属性的话，就是空的了 // 我在附录中简单介绍了一下 id 和 name 的配置，大家可以看一眼，有个20秒就可以了 if (StringUtils.hasLength(nameAttr)) &#123; String[] nameArr = StringUtils.tokenizeToStringArray(nameAttr, MULTI_VALUE_ATTRIBUTE_DELIMITERS); aliases.addAll(Arrays.asList(nameArr)); &#125; String beanName = id; // 如果没有指定id, 那么用别名列表的第一个名字作为beanName if (!StringUtils.hasText(beanName) &amp;&amp; !aliases.isEmpty()) &#123; beanName = aliases.remove(0); if (logger.isDebugEnabled()) &#123; logger.debug("No XML 'id' specified - using '" + beanName + "' as bean name and " + aliases + " as aliases"); &#125; &#125; if (containingBean == null) &#123; checkNameUniqueness(beanName, aliases, ele); &#125; // 根据 &lt;bean ...&gt;...&lt;/bean&gt; 中的配置创建 BeanDefinition，然后把配置中的信息都设置到实例中, // 细节后面细说，先知道下面这行结束后，一个 BeanDefinition 实例就出来了。 AbstractBeanDefinition beanDefinition = parseBeanDefinitionElement(ele, beanName, containingBean); // 到这里，整个 &lt;bean /&gt; 标签就算解析结束了，一个 BeanDefinition 就形成了。 if (beanDefinition != null) &#123; // 如果都没有设置 id 和 name，那么此时的 beanName 就会为 null，进入下面这块代码产生 // 如果读者不感兴趣的话，我觉得不需要关心这块代码，对本文源码分析来说，这些东西不重要 if (!StringUtils.hasText(beanName)) &#123; try &#123; if (containingBean != null) &#123;// 按照我们的思路，这里 containingBean 是 null 的 beanName = BeanDefinitionReaderUtils.generateBeanName( beanDefinition, this.readerContext.getRegistry(), true); &#125; else &#123; // 如果我们不定义 id 和 name，那么我们引言里的那个例子： // 1. beanName 为：com.javadoop.example.MessageServiceImpl#0 // 2. beanClassName 为：com.javadoop.example.MessageServiceImpl beanName = this.readerContext.generateBeanName(beanDefinition); String beanClassName = beanDefinition.getBeanClassName(); if (beanClassName != null &amp;&amp; beanName.startsWith(beanClassName) &amp;&amp; beanName.length() &gt; beanClassName.length() &amp;&amp; !this.readerContext.getRegistry().isBeanNameInUse(beanClassName)) &#123; // 把 beanClassName 设置为 Bean 的别名 aliases.add(beanClassName); &#125; &#125; if (logger.isDebugEnabled()) &#123; logger.debug("Neither XML 'id' nor 'name' specified - " + "using generated bean name [" + beanName + "]"); &#125; &#125; catch (Exception ex) &#123; error(ex.getMessage(), ele); return null; &#125; &#125; String[] aliasesArray = StringUtils.toStringArray(aliases); // 返回 BeanDefinitionHolder return new BeanDefinitionHolder(beanDefinition, beanName, aliasesArray); &#125; return null;&#125; 然后，我们再看看怎么根据配置创建 BeanDefinition 实例的： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public AbstractBeanDefinition parseBeanDefinitionElement( Element ele, String beanName, BeanDefinition containingBean) &#123; this.parseState.push(new BeanEntry(beanName)); String className = null; if (ele.hasAttribute(CLASS_ATTRIBUTE)) &#123; className = ele.getAttribute(CLASS_ATTRIBUTE).trim(); &#125; try &#123; String parent = null; if (ele.hasAttribute(PARENT_ATTRIBUTE)) &#123; parent = ele.getAttribute(PARENT_ATTRIBUTE); &#125; // 创建 BeanDefinition，然后设置类信息而已，很简单，就不贴代码了 AbstractBeanDefinition bd = createBeanDefinition(className, parent); // 设置 BeanDefinition 的一堆属性，这些属性定义在 AbstractBeanDefinition 中 parseBeanDefinitionAttributes(ele, beanName, containingBean, bd); bd.setDescription(DomUtils.getChildElementValueByTagName(ele, DESCRIPTION_ELEMENT)); /** * 下面的一堆是解析 &lt;bean&gt;......&lt;/bean&gt; 内部的子元素， * 解析出来以后的信息都放到 bd 的属性中 */ // 解析 &lt;meta /&gt; parseMetaElements(ele, bd); // 解析 &lt;lookup-method /&gt; parseLookupOverrideSubElements(ele, bd.getMethodOverrides()); // 解析 &lt;replaced-method /&gt; parseReplacedMethodSubElements(ele, bd.getMethodOverrides()); // 解析 &lt;constructor-arg /&gt; parseConstructorArgElements(ele, bd); // 解析 &lt;property /&gt; parsePropertyElements(ele, bd); // 解析 &lt;qualifier /&gt; parseQualifierElements(ele, bd); bd.setResource(this.readerContext.getResource()); bd.setSource(extractSource(ele)); return bd; &#125; catch (ClassNotFoundException ex) &#123; error("Bean class [" + className + "] not found", ele, ex); &#125; catch (NoClassDefFoundError err) &#123; error("Class that bean class [" + className + "] depends on not found", ele, err); &#125; catch (Throwable ex) &#123; error("Unexpected failure during bean definition parsing", ele, ex); &#125; finally &#123; this.parseState.pop(); &#125; return null;&#125; 到这里，我们已经完成了根据 &lt;bean /&gt; 配置创建了一个 BeanDefinitionHolder 实例。注意，是一个。 我们回到解析 &lt;bean /&gt; 的入口方法: 123456789101112131415161718protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) &#123; // 将 &lt;bean /&gt; 节点转换为 BeanDefinitionHolder，就是上面说的一堆 BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); if (bdHolder != null) &#123; // 如果有自定义属性的话，进行相应的解析，先忽略 bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); try &#123; // 我们把这步叫做 注册Bean 吧 BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry()); &#125; catch (BeanDefinitionStoreException ex) &#123; getReaderContext().error("Failed to register bean definition with name '" + bdHolder.getBeanName() + "'", ele, ex); &#125; // 注册完成后，发送事件，本文不展开说这个 getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder)); &#125;&#125; 大家再仔细看一下这块吧，我们后面就不回来说这个了。这里已经根据一个 &lt;bean /&gt; 标签产生了一个 BeanDefinitionHolder 的实例，这个实例里面也就是一个 BeanDefinition 的实例和它的 beanName、aliases 这三个信息，注意，我们的关注点始终在 BeanDefinition 上： 12345678public class BeanDefinitionHolder implements BeanMetadataElement &#123; private final BeanDefinition beanDefinition; private final String beanName; private final String[] aliases;... 然后我们准备注册这个 BeanDefinition，最后，把这个注册事件发送出去。 下面，我们开始说说注册 Bean 吧。 注册 Bean// BeanDefinitionReaderUtils 143 123456789101112131415161718public static void registerBeanDefinition( BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry) throws BeanDefinitionStoreException &#123; String beanName = definitionHolder.getBeanName(); // 注册这个 Bean registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition()); // 如果还有别名的话，也要根据别名全部注册一遍，不然根据别名就会找不到 Bean 了 String[] aliases = definitionHolder.getAliases(); if (aliases != null) &#123; for (String alias : aliases) &#123; // alias -&gt; beanName 保存它们的别名信息，这个很简单，用一个 map 保存一下就可以了， // 获取的时候，会先将 alias 转换为 beanName，然后再查找 registry.registerAlias(beanName, alias); &#125; &#125;&#125; 别名注册的放一边，毕竟它很简单，我们看看怎么注册 Bean。 // DefaultListableBeanFactory 793 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182@Overridepublic void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException &#123; Assert.hasText(beanName, "Bean name must not be empty"); Assert.notNull(beanDefinition, "BeanDefinition must not be null"); if (beanDefinition instanceof AbstractBeanDefinition) &#123; try &#123; ((AbstractBeanDefinition) beanDefinition).validate(); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanDefinitionStoreException(...); &#125; &#125; // old? 还记得 “允许 bean 覆盖” 这个配置吗？allowBeanDefinitionOverriding BeanDefinition oldBeanDefinition; // 之后会看到，所有的 Bean 注册后会放入这个 beanDefinitionMap 中 oldBeanDefinition = this.beanDefinitionMap.get(beanName); // 处理重复名称的 Bean 定义的情况 if (oldBeanDefinition != null) &#123; if (!isAllowBeanDefinitionOverriding()) &#123; // 如果不允许覆盖的话，抛异常 throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription()... &#125; else if (oldBeanDefinition.getRole() &lt; beanDefinition.getRole()) &#123; // log...用框架定义的 Bean 覆盖用户自定义的 Bean &#125; else if (!beanDefinition.equals(oldBeanDefinition)) &#123; // log...用新的 Bean 覆盖旧的 Bean &#125; else &#123; // log...用同等的 Bean 覆盖旧的 Bean，这里指的是 equals 方法返回 true 的 Bean &#125; // 覆盖 this.beanDefinitionMap.put(beanName, beanDefinition); &#125; else &#123; // 判断是否已经有其他的 Bean 开始初始化了. // 注意，"注册Bean" 这个动作结束，Bean 依然还没有初始化，我们后面会有大篇幅说初始化过程， // 在 Spring 容器启动的最后，会 预初始化 所有的 singleton beans if (hasBeanCreationStarted()) &#123; // Cannot modify startup-time collection elements anymore (for stable iteration) synchronized (this.beanDefinitionMap) &#123; this.beanDefinitionMap.put(beanName, beanDefinition); List&lt;String&gt; updatedDefinitions = new ArrayList&lt;String&gt;(this.beanDefinitionNames.size() + 1); updatedDefinitions.addAll(this.beanDefinitionNames); updatedDefinitions.add(beanName); this.beanDefinitionNames = updatedDefinitions; if (this.manualSingletonNames.contains(beanName)) &#123; Set&lt;String&gt; updatedSingletons = new LinkedHashSet&lt;String&gt;(this.manualSingletonNames); updatedSingletons.remove(beanName); this.manualSingletonNames = updatedSingletons; &#125; &#125; &#125; else &#123; // 最正常的应该是进到这个分支。 // 将 BeanDefinition 放到这个 map 中，这个 map 保存了所有的 BeanDefinition this.beanDefinitionMap.put(beanName, beanDefinition); // 这是个 ArrayList，所以会按照 bean 配置的顺序保存每一个注册的 Bean 的名字 this.beanDefinitionNames.add(beanName); // 这是个 LinkedHashSet，代表的是手动注册的 singleton bean， // 注意这里是 remove 方法，到这里的 Bean 当然不是手动注册的 // 手动指的是通过调用以下方法注册的 bean ： // registerSingleton(String beanName, Object singletonObject) // 这不是重点，解释只是为了不让大家疑惑。Spring 会在后面"手动"注册一些 Bean， // 如 "environment"、"systemProperties" 等 bean，我们自己也可以在运行时注册 Bean 到容器中的 this.manualSingletonNames.remove(beanName); &#125; // 这个不重要，在预初始化的时候会用到，不必管它。 this.frozenBeanDefinitionNames = null; &#125; if (oldBeanDefinition != null || containsSingleton(beanName)) &#123; resetBeanDefinition(beanName); &#125;&#125; 总结一下，到这里已经初始化了 Bean 容器，&lt;bean /&gt; 配置也相应的转换为了一个个 BeanDefinition，然后注册了各个 BeanDefinition 到注册中心，并且发送了注册事件。 到这里是一个分水岭，前面的内容都还算比较简单，大家要清楚地知道前面都做了哪些事情。 Bean 容器实例化完成后说到这里，我们回到 refresh() 方法，我重新贴了一遍代码，看看我们说到哪了。是的，我们才说完 obtainFreshBeanFactory() 方法。 考虑到篇幅，这里开始大幅缩减掉没必要详细介绍的部分，大家直接看下面的代码中的注释就好了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; // 来个锁，不然 refresh() 还没结束，你又来个启动或销毁容器的操作，那不就乱套了嘛 synchronized (this.startupShutdownMonitor) &#123; // 准备工作，记录下容器的启动时间、标记“已启动”状态、处理配置文件中的占位符 prepareRefresh(); // 这步比较关键，这步完成后，配置文件就会解析成一个个 Bean 定义，注册到 BeanFactory 中， // 当然，这里说的 Bean 还没有初始化，只是配置信息都提取出来了， // 注册也只是将这些信息都保存到了注册中心(说到底核心是一个 beanName-&gt; beanDefinition 的 map) ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 设置 BeanFactory 的类加载器，添加几个 BeanPostProcessor，手动注册几个特殊的 bean // 这块待会会展开说 prepareBeanFactory(beanFactory); try &#123; // 【这里需要知道 BeanFactoryPostProcessor 这个知识点，Bean 如果实现了此接口， // 那么在容器初始化以后，Spring 会负责调用里面的 postProcessBeanFactory 方法。】 // 这里是提供给子类的扩展点，到这里的时候，所有的 Bean 都加载、注册完成了，但是都还没有初始化 // 具体的子类可以在这步的时候添加一些特殊的 BeanFactoryPostProcessor 的实现类或做点什么事 postProcessBeanFactory(beanFactory); // 调用 BeanFactoryPostProcessor 各个实现类的 postProcessBeanFactory(factory) 回调方法 invokeBeanFactoryPostProcessors(beanFactory); // 注册 BeanPostProcessor 的实现类，注意看和 BeanFactoryPostProcessor 的区别 // 此接口两个方法: postProcessBeforeInitialization 和 postProcessAfterInitialization // 两个方法分别在 Bean 初始化之前和初始化之后得到执行。这里仅仅是注册，之后会看到回调这两方法的时机 registerBeanPostProcessors(beanFactory); // 初始化当前 ApplicationContext 的 MessageSource，国际化这里就不展开说了，不然没完没了了 initMessageSource(); // 初始化当前 ApplicationContext 的事件广播器，这里也不展开了 initApplicationEventMulticaster(); // 从方法名就可以知道，典型的模板方法(钩子方法)，不展开说 // 具体的子类可以在这里初始化一些特殊的 Bean（在初始化 singleton beans 之前） onRefresh(); // 注册事件监听器，监听器需要实现 ApplicationListener 接口。这也不是我们的重点，过 registerListeners(); // 重点，重点，重点 // 初始化所有的 singleton beans //（lazy-init 的除外） finishBeanFactoryInitialization(beanFactory); // 最后，广播事件，ApplicationContext 初始化完成，不展开 finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn("Exception encountered during context initialization - " + "cancelling refresh attempt: " + ex); &#125; // Destroy already created singletons to avoid dangling resources. // 销毁已经初始化的 singleton 的 Beans，以免有些 bean 会一直占用资源 destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // 把异常往外抛 throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; 准备 Bean 容器: prepareBeanFactory之前我们说过，Spring 把我们在 xml 配置的 bean 都注册以后，会”手动”注册一些特殊的 bean。 这里简单介绍下 prepareBeanFactory(factory) 方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374/** * Configure the factory's standard context characteristics, * such as the context's ClassLoader and post-processors. * @param beanFactory the BeanFactory to configure */protected void prepareBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123; // 设置 BeanFactory 的类加载器，我们知道 BeanFactory 需要加载类，也就需要类加载器， // 这里设置为加载当前 ApplicationContext 类的类加载器 beanFactory.setBeanClassLoader(getClassLoader()); // 设置 BeanExpressionResolver beanFactory.setBeanExpressionResolver(new StandardBeanExpressionResolver(beanFactory.getBeanClassLoader())); // beanFactory.addPropertyEditorRegistrar(new ResourceEditorRegistrar(this, getEnvironment())); // 添加一个 BeanPostProcessor，这个 processor 比较简单： // 实现了 Aware 接口的 beans 在初始化的时候，这个 processor 负责回调， // 这个我们很常用，如我们会为了获取 ApplicationContext 而 implement ApplicationContextAware // 注意：它不仅仅回调 ApplicationContextAware， // 还会负责回调 EnvironmentAware、ResourceLoaderAware 等，看下源码就清楚了 beanFactory.addBeanPostProcessor(new ApplicationContextAwareProcessor(this)); // 下面几行的意思就是，如果某个 bean 依赖于以下几个接口的实现类，在自动装配的时候忽略它们， // Spring 会通过其他方式来处理这些依赖。 beanFactory.ignoreDependencyInterface(EnvironmentAware.class); beanFactory.ignoreDependencyInterface(EmbeddedValueResolverAware.class); beanFactory.ignoreDependencyInterface(ResourceLoaderAware.class); beanFactory.ignoreDependencyInterface(ApplicationEventPublisherAware.class); beanFactory.ignoreDependencyInterface(MessageSourceAware.class); beanFactory.ignoreDependencyInterface(ApplicationContextAware.class); /** * 下面几行就是为特殊的几个 bean 赋值，如果有 bean 依赖了以下几个，会注入这边相应的值， * 之前我们说过，"当前 ApplicationContext 持有一个 BeanFactory"，这里解释了第一行 * ApplicationContext 还继承了 ResourceLoader、ApplicationEventPublisher、MessageSource * 所以对于这几个依赖，可以赋值为 this，注意 this 是一个 ApplicationContext * 那这里怎么没看到为 MessageSource 赋值呢？那是因为 MessageSource 被注册成为了一个普通的 bean */ beanFactory.registerResolvableDependency(BeanFactory.class, beanFactory); beanFactory.registerResolvableDependency(ResourceLoader.class, this); beanFactory.registerResolvableDependency(ApplicationEventPublisher.class, this); beanFactory.registerResolvableDependency(ApplicationContext.class, this); // 这个 BeanPostProcessor 也很简单，在 bean 实例化后，如果是 ApplicationListener 的子类， // 那么将其添加到 listener 列表中，可以理解成：注册 事件监听器 beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(this)); // 这里涉及到特殊的 bean，名为：loadTimeWeaver，这不是我们的重点，忽略它 // tips: ltw 是 AspectJ 的概念，指的是在运行期进行织入，这个和 Spring AOP 不一样， // 感兴趣的读者请参考我写的关于 AspectJ 的另一篇文章 https://www.javadoop.com/post/aspectj if (beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) &#123; beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory)); // Set a temporary ClassLoader for type matching. beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader())); &#125; /** * 从下面几行代码我们可以知道，Spring 往往很 "智能" 就是因为它会帮我们默认注册一些有用的 bean， * 我们也可以选择覆盖 */ // 如果没有定义 "environment" 这个 bean，那么 Spring 会 "手动" 注册一个 if (!beanFactory.containsLocalBean(ENVIRONMENT_BEAN_NAME)) &#123; beanFactory.registerSingleton(ENVIRONMENT_BEAN_NAME, getEnvironment()); &#125; // 如果没有定义 "systemProperties" 这个 bean，那么 Spring 会 "手动" 注册一个 if (!beanFactory.containsLocalBean(SYSTEM_PROPERTIES_BEAN_NAME)) &#123; beanFactory.registerSingleton(SYSTEM_PROPERTIES_BEAN_NAME, getEnvironment().getSystemProperties()); &#125; // 如果没有定义 "systemEnvironment" 这个 bean，那么 Spring 会 "手动" 注册一个 if (!beanFactory.containsLocalBean(SYSTEM_ENVIRONMENT_BEAN_NAME)) &#123; beanFactory.registerSingleton(SYSTEM_ENVIRONMENT_BEAN_NAME, getEnvironment().getSystemEnvironment()); &#125;&#125; 在上面这块代码中，Spring 对一些特殊的 bean 进行了处理，读者如果暂时还不能消化它们也没有关系，慢慢往下看。 初始化所有的 singleton beans我们的重点当然是 finishBeanFactoryInitialization(beanFactory); 这个巨头了，这里会负责初始化所有的 singleton beans。 注意，后面的描述中，我都会使用初始化或预初始化来代表这个阶段，Spring 会在这个阶段完成所有的 singleton beans 的实例化。 我们来总结一下，到目前为止，应该说 BeanFactory 已经创建完成，并且所有的实现了 BeanFactoryPostProcessor 接口的 Bean 都已经初始化并且其中的 postProcessBeanFactory(factory) 方法已经得到回调执行了。而且 Spring 已经“手动”注册了一些特殊的 Bean，如 ‘environment’、‘systemProperties’ 等。 剩下的就是初始化 singleton beans 了，我们知道它们是单例的，如果没有设置懒加载，那么 Spring 会在接下来初始化所有的 singleton beans。 // AbstractApplicationContext.java 834 1234567891011121314151617181920212223242526272829303132333435363738394041// 初始化剩余的 singleton beansprotected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) &#123; // 首先，初始化名字为 conversionService 的 Bean。本着送佛送到西的精神，我在附录中简单介绍了一下 ConversionService，因为这实在太实用了 // 什么，看代码这里没有初始化 Bean 啊！ // 注意了，初始化的动作包装在 beanFactory.getBean(...) 中，这里先不说细节，先往下看吧 if (beanFactory.containsBean(CONVERSION_SERVICE_BEAN_NAME) &amp;&amp; beanFactory.isTypeMatch(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)) &#123; beanFactory.setConversionService( beanFactory.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)); &#125; // Register a default embedded value resolver if no bean post-processor // (such as a PropertyPlaceholderConfigurer bean) registered any before: // at this point, primarily for resolution in annotation attribute values. if (!beanFactory.hasEmbeddedValueResolver()) &#123; beanFactory.addEmbeddedValueResolver(new StringValueResolver() &#123; @Override public String resolveStringValue(String strVal) &#123; return getEnvironment().resolvePlaceholders(strVal); &#125; &#125;); &#125; // 先初始化 LoadTimeWeaverAware 类型的 Bean // 之前也说过，这是 AspectJ 相关的内容，放心跳过吧 String[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false); for (String weaverAwareName : weaverAwareNames) &#123; getBean(weaverAwareName); &#125; // Stop using the temporary ClassLoader for type matching. beanFactory.setTempClassLoader(null); // 没什么别的目的，因为到这一步的时候，Spring 已经开始预初始化 singleton beans 了， // 肯定不希望这个时候还出现 bean 定义解析、加载、注册。 beanFactory.freezeConfiguration(); // 开始初始化 beanFactory.preInstantiateSingletons();&#125; 从上面最后一行往里看，我们就又回到 DefaultListableBeanFactory 这个类了，这个类大家应该都不陌生了吧。 preInstantiateSingletons// DefaultListableBeanFactory 728 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869@Overridepublic void preInstantiateSingletons() throws BeansException &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug("Pre-instantiating singletons in " + this); &#125; // this.beanDefinitionNames 保存了所有的 beanNames List&lt;String&gt; beanNames = new ArrayList&lt;String&gt;(this.beanDefinitionNames); // 触发所有的非懒加载的 singleton beans 的初始化操作 for (String beanName : beanNames) &#123; // 合并父 Bean 中的配置，注意 &lt;bean id="" class="" parent="" /&gt; 中的 parent，用的不多吧， // 考虑到这可能会影响大家的理解，我在附录中解释了一下 "Bean 继承"，不了解的请到附录中看一下 RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName); // 非抽象、非懒加载的 singletons。如果配置了 'abstract = true'，那是不需要初始化的 if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) &#123; // 处理 FactoryBean(读者如果不熟悉 FactoryBean，请移步附录区了解) if (isFactoryBean(beanName)) &#123; // FactoryBean 的话，在 beanName 前面加上 ‘&amp;’ 符号。再调用 getBean，getBean 方法别急 final FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) getBean(FACTORY_BEAN_PREFIX + beanName); // 判断当前 FactoryBean 是否是 SmartFactoryBean 的实现，此处忽略，直接跳过 boolean isEagerInit; if (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) &#123; isEagerInit = AccessController.doPrivileged(new PrivilegedAction&lt;Boolean&gt;() &#123; @Override public Boolean run() &#123; return ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit(); &#125; &#125;, getAccessControlContext()); &#125; else &#123; isEagerInit = (factory instanceof SmartFactoryBean &amp;&amp; ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit()); &#125; if (isEagerInit) &#123; getBean(beanName); &#125; &#125; else &#123; // 对于普通的 Bean，只要调用 getBean(beanName) 这个方法就可以进行初始化了 getBean(beanName); &#125; &#125; &#125; // 到这里说明所有的非懒加载的 singleton beans 已经完成了初始化 // 如果我们定义的 bean 是实现了 SmartInitializingSingleton 接口的，那么在这里得到回调，忽略 for (String beanName : beanNames) &#123; Object singletonInstance = getSingleton(beanName); if (singletonInstance instanceof SmartInitializingSingleton) &#123; final SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; @Override public Object run() &#123; smartSingleton.afterSingletonsInstantiated(); return null; &#125; &#125;, getAccessControlContext()); &#125; else &#123; smartSingleton.afterSingletonsInstantiated(); &#125; &#125; &#125;&#125; 接下来，我们就进入到 getBean(beanName) 方法了，这个方法我们经常用来从 BeanFactory 中获取一个 Bean，而初始化的过程也封装到了这个方法里。 getBean在继续前进之前，读者应该具备 FactoryBean 的知识，如果读者还不熟悉，请移步附录部分了解 FactoryBean。 // AbstractBeanFactory 196 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176@Overridepublic Object getBean(String name) throws BeansException &#123; return doGetBean(name, null, null, false);&#125;// 我们在剖析初始化 Bean 的过程，但是 getBean 方法我们经常是用来从容器中获取 Bean 用的，注意切换思路，// 已经初始化过了就从容器中直接返回，否则就先初始化再返回@SuppressWarnings("unchecked")protected &lt;T&gt; T doGetBean( final String name, final Class&lt;T&gt; requiredType, final Object[] args, boolean typeCheckOnly) throws BeansException &#123; // 获取一个 “正统的” beanName，处理两种情况，一个是前面说的 FactoryBean(前面带 ‘&amp;’)， // 一个是别名问题，因为这个方法是 getBean，获取 Bean 用的，你要是传一个别名进来，是完全可以的 final String beanName = transformedBeanName(name); // 注意跟着这个，这个是返回值 Object bean; // 检查下是不是已经创建过了 Object sharedInstance = getSingleton(beanName); // 这里说下 args 呗，虽然看上去一点不重要。前面我们一路进来的时候都是 getBean(beanName)， // 所以 args 传参其实是 null 的，但是如果 args 不为空的时候，那么意味着调用方不是希望获取 Bean，而是创建 Bean if (sharedInstance != null &amp;&amp; args == null) &#123; if (logger.isDebugEnabled()) &#123; if (isSingletonCurrentlyInCreation(beanName)) &#123; logger.debug("..."); &#125; else &#123; logger.debug("Returning cached instance of singleton bean '" + beanName + "'"); &#125; &#125; // 下面这个方法：如果是普通 Bean 的话，直接返回 sharedInstance， // 如果是 FactoryBean 的话，返回它创建的那个实例对象 // (FactoryBean 知识，读者若不清楚请移步附录) bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &#125; else &#123; if (isPrototypeCurrentlyInCreation(beanName)) &#123; // 创建过了此 beanName 的 prototype 类型的 bean，那么抛异常， // 往往是因为陷入了循环引用 throw new BeanCurrentlyInCreationException(beanName); &#125; // 检查一下这个 BeanDefinition 在容器中是否存在 BeanFactory parentBeanFactory = getParentBeanFactory(); if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &#123; // 如果当前容器不存在这个 BeanDefinition，试试父容器中有没有 String nameToLookup = originalBeanName(name); if (args != null) &#123; // 返回父容器的查询结果 return (T) parentBeanFactory.getBean(nameToLookup, args); &#125; else &#123; // No args -&gt; delegate to standard getBean method. return parentBeanFactory.getBean(nameToLookup, requiredType); &#125; &#125; if (!typeCheckOnly) &#123; // typeCheckOnly 为 false，将当前 beanName 放入一个 alreadyCreated 的 Set 集合中。 markBeanAsCreated(beanName); &#125; /* * 稍稍总结一下： * 到这里的话，要准备创建 Bean 了，对于 singleton 的 Bean 来说，容器中还没创建过此 Bean； * 对于 prototype 的 Bean 来说，本来就是要创建一个新的 Bean。 */ try &#123; final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); checkMergedBeanDefinition(mbd, beanName, args); // 先初始化依赖的所有 Bean，这个很好理解。 // 注意，这里的依赖指的是 depends-on 中定义的依赖 String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) &#123; for (String dep : dependsOn) &#123; // 检查是不是有循环依赖，这里的循环依赖和我们前面说的循环依赖又不一样，这里肯定是不允许出现的，不然要乱套了，读者想一下就知道了 if (isDependent(beanName, dep)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Circular depends-on relationship between '" + beanName + "' and '" + dep + "'"); &#125; // 注册一下依赖关系 registerDependentBean(dep, beanName); // 先初始化被依赖项 getBean(dep); &#125; &#125; // 如果是 singleton scope 的，创建 singleton 的实例 if (mbd.isSingleton()) &#123; sharedInstance = getSingleton(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; try &#123; // 执行创建 Bean，详情后面再说 return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; destroySingleton(beanName); throw ex; &#125; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; // 如果是 prototype scope 的，创建 prototype 的实例 else if (mbd.isPrototype()) &#123; // It's a prototype -&gt; create a new instance. Object prototypeInstance = null; try &#123; beforePrototypeCreation(beanName); // 执行创建 Bean prototypeInstance = createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &#125; // 如果不是 singleton 和 prototype 的话，需要委托给相应的实现类来处理 else &#123; String scopeName = mbd.getScope(); final Scope scope = this.scopes.get(scopeName); if (scope == null) &#123; throw new IllegalStateException("No Scope registered for scope name '" + scopeName + "'"); &#125; try &#123; Object scopedInstance = scope.get(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; beforePrototypeCreation(beanName); try &#123; // 执行创建 Bean return createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; &#125; &#125;); bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &#125; catch (IllegalStateException ex) &#123; throw new BeanCreationException(beanName, "Scope '" + scopeName + "' is not active for the current thread; consider " + "defining a scoped proxy for this bean if you intend to refer to it from a singleton", ex); &#125; &#125; &#125; catch (BeansException ex) &#123; cleanupAfterBeanCreationFailure(beanName); throw ex; &#125; &#125; // 最后，检查一下类型对不对，不对的话就抛异常，对的话就返回了 if (requiredType != null &amp;&amp; bean != null &amp;&amp; !requiredType.isInstance(bean)) &#123; try &#123; return getTypeConverter().convertIfNecessary(bean, requiredType); &#125; catch (TypeMismatchException ex) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Failed to convert bean '" + name + "' to required type '" + ClassUtils.getQualifiedName(requiredType) + "'", ex); &#125; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125; &#125; return (T) bean;&#125; 大家应该也猜到了，接下来当然是分析 createBean 方法： 1protected abstract Object createBean(String beanName, RootBeanDefinition mbd, Object[] args) throws BeanCreationException; 第三个参数 args 数组代表创建实例需要的参数，不就是给构造方法用的参数，或者是工厂 Bean 的参数嘛，不过要注意，在我们的初始化阶段，args 是 null。 这回我们要到一个新的类了 AbstractAutowireCapableBeanFactory，看类名，AutowireCapable？类名是不是也说明了点问题了。 主要是为了以下场景，采用 @Autowired 注解注入属性值： 123456789public class MessageServiceImpl implements MessageService &#123; @Autowired private UserService userService; public String getMessage() &#123; return userService.getMessage(); &#125;&#125;&lt;bean id="messageService" class="com.javadoop.example.MessageServiceImpl" /&gt; 以上这种属于混用了 xml 和 注解 两种方式的配置方式，Spring 会处理这种情况。 好了，读者要知道这么回事就可以了，继续向前。 // AbstractAutowireCapableBeanFactory 447 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * Central method of this class: creates a bean instance, * populates the bean instance, applies post-processors, etc. * @see #doCreateBean */@Overrideprotected Object createBean(String beanName, RootBeanDefinition mbd, Object[] args) throws BeanCreationException &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Creating instance of bean '" + beanName + "'"); &#125; RootBeanDefinition mbdToUse = mbd; // 确保 BeanDefinition 中的 Class 被加载 Class&lt;?&gt; resolvedClass = resolveBeanClass(mbd, beanName); if (resolvedClass != null &amp;&amp; !mbd.hasBeanClass() &amp;&amp; mbd.getBeanClassName() != null) &#123; mbdToUse = new RootBeanDefinition(mbd); mbdToUse.setBeanClass(resolvedClass); &#125; // 准备方法覆写，这里又涉及到一个概念：MethodOverrides，它来自于 bean 定义中的 &lt;lookup-method /&gt; // 和 &lt;replaced-method /&gt;，如果读者感兴趣，回到 bean 解析的地方看看对这两个标签的解析。 // 我在附录中也对这两个标签的相关知识点进行了介绍，读者可以移步去看看 try &#123; mbdToUse.prepareMethodOverrides(); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanDefinitionStoreException(mbdToUse.getResourceDescription(), beanName, "Validation of method overrides failed", ex); &#125; try &#123; // 让 InstantiationAwareBeanPostProcessor 在这一步有机会返回代理， // 在 《Spring AOP 源码分析》那篇文章中有解释，这里先跳过 Object bean = resolveBeforeInstantiation(beanName, mbdToUse); if (bean != null) &#123; return bean; &#125; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbdToUse.getResourceDescription(), beanName, "BeanPostProcessor before instantiation of bean failed", ex); &#125; // 重头戏，创建 bean Object beanInstance = doCreateBean(beanName, mbdToUse, args); if (logger.isDebugEnabled()) &#123; logger.debug("Finished creating instance of bean '" + beanName + "'"); &#125; return beanInstance;&#125; 创建 Bean我们继续往里看 doCreateBean 这个方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125/** * Actually create the specified bean. Pre-creation processing has already happened * at this point, e.g. checking &#123;@code postProcessBeforeInstantiation&#125; callbacks. * &lt;p&gt;Differentiates between default bean instantiation, use of a * factory method, and autowiring a constructor. * @param beanName the name of the bean * @param mbd the merged bean definition for the bean * @param args explicit arguments to use for constructor or factory method invocation * @return a new instance of the bean * @throws BeanCreationException if the bean could not be created * @see #instantiateBean * @see #instantiateUsingFactoryMethod * @see #autowireConstructor */protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final Object[] args) throws BeanCreationException &#123; // Instantiate the bean. BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) &#123; instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); &#125; if (instanceWrapper == null) &#123; // 说明不是 FactoryBean，这里实例化 Bean，这里非常关键，细节之后再说 instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; // 这个就是 Bean 里面的 我们定义的类 的实例，很多地方我直接描述成 "bean 实例" final Object bean = (instanceWrapper != null ? instanceWrapper.getWrappedInstance() : null); // 类型 Class&lt;?&gt; beanType = (instanceWrapper != null ? instanceWrapper.getWrappedClass() : null); mbd.resolvedTargetType = beanType; // 建议跳过吧，涉及接口：MergedBeanDefinitionPostProcessor synchronized (mbd.postProcessingLock) &#123; if (!mbd.postProcessed) &#123; try &#123; // MergedBeanDefinitionPostProcessor，这个我真不展开说了，直接跳过吧，很少用的 applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Post-processing of merged bean definition failed", ex); &#125; mbd.postProcessed = true; &#125; &#125; // Eagerly cache singletons to be able to resolve circular references // even when triggered by lifecycle interfaces like BeanFactoryAware. // 下面这块代码是为了解决循环依赖的问题，以后有时间，我再对循环依赖这个问题进行解析吧 boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Eagerly caching bean '" + beanName + "' to allow for resolving potential circular references"); &#125; addSingletonFactory(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; return getEarlyBeanReference(beanName, mbd, bean); &#125; &#125;); &#125; // Initialize the bean instance. Object exposedObject = bean; try &#123; // 这一步也是非常关键的，这一步负责属性装配，因为前面的实例只是实例化了，并没有设值，这里就是设值 populateBean(beanName, mbd, instanceWrapper); if (exposedObject != null) &#123; // 还记得 init-method 吗？还有 InitializingBean 接口？还有 BeanPostProcessor 接口？ // 这里就是处理 bean 初始化完成后的各种回调 exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; &#125; catch (Throwable ex) &#123; if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) &#123; throw (BeanCreationException) ex; &#125; else &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Initialization of bean failed", ex); &#125; &#125; if (earlySingletonExposure) &#123; // Object earlySingletonReference = getSingleton(beanName, false); if (earlySingletonReference != null) &#123; if (exposedObject == bean) &#123; exposedObject = earlySingletonReference; &#125; else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) &#123; String[] dependentBeans = getDependentBeans(beanName); Set&lt;String&gt; actualDependentBeans = new LinkedHashSet&lt;String&gt;(dependentBeans.length); for (String dependentBean : dependentBeans) &#123; if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) &#123; actualDependentBeans.add(dependentBean); &#125; &#125; if (!actualDependentBeans.isEmpty()) &#123; throw new BeanCurrentlyInCreationException(beanName, "Bean with name '" + beanName + "' has been injected into other beans [" + StringUtils.collectionToCommaDelimitedString(actualDependentBeans) + "] in its raw version as part of a circular reference, but has eventually been " + "wrapped. This means that said other beans do not use the final version of the " + "bean. This is often the result of over-eager type matching - consider using " + "'getBeanNamesOfType' with the 'allowEagerInit' flag turned off, for example."); &#125; &#125; &#125; &#125; // Register bean as disposable. try &#123; registerDisposableBeanIfNecessary(beanName, bean, mbd); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Invalid destruction signature", ex); &#125; return exposedObject;&#125; 到这里，我们已经分析完了 doCreateBean 方法，总的来说，我们已经说完了整个初始化流程。 接下来我们挑 doCreateBean 中的三个细节出来说说。一个是创建 Bean 实例的 createBeanInstance 方法，一个是依赖注入的 populateBean 方法，还有就是回调方法 initializeBean。 注意了，接下来的这三个方法要认真说那也是极其复杂的，很多地方我就点到为止了，感兴趣的读者可以自己往里看，最好就是碰到不懂的，自己写代码去调试它。 创建 Bean 实例我们先看看 createBeanInstance 方法。需要说明的是，这个方法如果每个分支都分析下去，必然也是极其复杂冗长的，我们挑重点说。此方法的目的就是实例化我们指定的类。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, Object[] args) &#123; // 确保已经加载了此 class Class&lt;?&gt; beanClass = resolveBeanClass(mbd, beanName); // 校验一下这个类的访问权限 if (beanClass != null &amp;&amp; !Modifier.isPublic(beanClass.getModifiers()) &amp;&amp; !mbd.isNonPublicAccessAllowed()) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Bean class isn't public, and non-public access not allowed: " + beanClass.getName()); &#125; if (mbd.getFactoryMethodName() != null) &#123; // 采用工厂方法实例化，不熟悉这个概念的读者请看附录，注意，不是 FactoryBean return instantiateUsingFactoryMethod(beanName, mbd, args); &#125; // 如果不是第一次创建，比如第二次创建 prototype bean。 // 这种情况下，我们可以从第一次创建知道，采用无参构造函数，还是构造函数依赖注入 来完成实例化 boolean resolved = false; boolean autowireNecessary = false; if (args == null) &#123; synchronized (mbd.constructorArgumentLock) &#123; if (mbd.resolvedConstructorOrFactoryMethod != null) &#123; resolved = true; autowireNecessary = mbd.constructorArgumentsResolved; &#125; &#125; &#125; if (resolved) &#123; if (autowireNecessary) &#123; // 构造函数依赖注入 return autowireConstructor(beanName, mbd, null, null); &#125; else &#123; // 无参构造函数 return instantiateBean(beanName, mbd); &#125; &#125; // 判断是否采用有参构造函数 Constructor&lt;?&gt;[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName); if (ctors != null || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_CONSTRUCTOR || mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args)) &#123; // 构造函数依赖注入 return autowireConstructor(beanName, mbd, ctors, args); &#125; // 调用无参构造函数 return instantiateBean(beanName, mbd);&#125; 挑个简单的无参构造函数构造实例来看看： 123456789101112131415161718192021222324252627protected BeanWrapper instantiateBean(final String beanName, final RootBeanDefinition mbd) &#123; try &#123; Object beanInstance; final BeanFactory parent = this; if (System.getSecurityManager() != null) &#123; beanInstance = AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; @Override public Object run() &#123; return getInstantiationStrategy().instantiate(mbd, beanName, parent); &#125; &#125;, getAccessControlContext()); &#125; else &#123; // 实例化 beanInstance = getInstantiationStrategy().instantiate(mbd, beanName, parent); &#125; // 包装一下，返回 BeanWrapper bw = new BeanWrapperImpl(beanInstance); initBeanWrapper(bw); return bw; &#125; catch (Throwable ex) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Instantiation of bean failed", ex); &#125;&#125; 我们可以看到，关键的地方在于： 1beanInstance = getInstantiationStrategy().instantiate(mbd, beanName, parent); 这里会进行实际的实例化过程，我们进去看看: // SimpleInstantiationStrategy 59 123456789101112131415161718192021222324252627282930313233343536373839404142@Overridepublic Object instantiate(RootBeanDefinition bd, String beanName, BeanFactory owner) &#123; // 如果不存在方法覆写，那就使用 java 反射进行实例化，否则使用 CGLIB, // 方法覆写 请参见附录"方法注入"中对 lookup-method 和 replaced-method 的介绍 if (bd.getMethodOverrides().isEmpty()) &#123; Constructor&lt;?&gt; constructorToUse; synchronized (bd.constructorArgumentLock) &#123; constructorToUse = (Constructor&lt;?&gt;) bd.resolvedConstructorOrFactoryMethod; if (constructorToUse == null) &#123; final Class&lt;?&gt; clazz = bd.getBeanClass(); if (clazz.isInterface()) &#123; throw new BeanInstantiationException(clazz, "Specified class is an interface"); &#125; try &#123; if (System.getSecurityManager() != null) &#123; constructorToUse = AccessController.doPrivileged(new PrivilegedExceptionAction&lt;Constructor&lt;?&gt;&gt;() &#123; @Override public Constructor&lt;?&gt; run() throws Exception &#123; return clazz.getDeclaredConstructor((Class[]) null); &#125; &#125;); &#125; else &#123; constructorToUse = clazz.getDeclaredConstructor((Class[]) null); &#125; bd.resolvedConstructorOrFactoryMethod = constructorToUse; &#125; catch (Throwable ex) &#123; throw new BeanInstantiationException(clazz, "No default constructor found", ex); &#125; &#125; &#125; // 利用构造方法进行实例化 return BeanUtils.instantiateClass(constructorToUse); &#125; else &#123; // 存在方法覆写，利用 CGLIB 来完成实例化，需要依赖于 CGLIB 生成子类，这里就不展开了。 // tips: 因为如果不使用 CGLIB 的话，存在 override 的情况 JDK 并没有提供相应的实例化支持 return instantiateWithMethodInjection(bd, beanName, owner); &#125;&#125; 到这里，我们就算实例化完成了。我们开始说怎么进行属性注入。 bean 属性注入看完了 createBeanInstance(…) 方法，我们来看看 populateBean(…) 方法，该方法负责进行属性设值，处理依赖。 // AbstractAutowireCapableBeanFactory 1203 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778protected void populateBean(String beanName, RootBeanDefinition mbd, BeanWrapper bw) &#123; // bean 实例的所有属性都在这里了 PropertyValues pvs = mbd.getPropertyValues(); if (bw == null) &#123; if (!pvs.isEmpty()) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Cannot apply property values to null instance"); &#125; else &#123; // Skip property population phase for null instance. return; &#125; &#125; // 到这步的时候，bean 实例化完成（通过工厂方法或构造方法），但是还没开始属性设值， // InstantiationAwareBeanPostProcessor 的实现类可以在这里对 bean 进行状态修改， // 我也没找到有实际的使用，所以我们暂且忽略这块吧 boolean continueWithPropertyPopulation = true; if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; // 如果返回 false，代表不需要进行后续的属性设值，也不需要再经过其他的 BeanPostProcessor 的处理 if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) &#123; continueWithPropertyPopulation = false; break; &#125; &#125; &#125; &#125; if (!continueWithPropertyPopulation) &#123; return; &#125; if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &#123; MutablePropertyValues newPvs = new MutablePropertyValues(pvs); // 通过名字找到所有属性值，如果是 bean 依赖，先初始化依赖的 bean。记录依赖关系 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME) &#123; autowireByName(beanName, mbd, bw, newPvs); &#125; // 通过类型装配。复杂一些 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &#123; autowireByType(beanName, mbd, bw, newPvs); &#125; pvs = newPvs; &#125; boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors(); boolean needsDepCheck = (mbd.getDependencyCheck() != RootBeanDefinition.DEPENDENCY_CHECK_NONE); if (hasInstAwareBpps || needsDepCheck) &#123; PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); if (hasInstAwareBpps) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; // 这里有个非常有用的 BeanPostProcessor 进到这里: AutowiredAnnotationBeanPostProcessor // 对采用 @Autowired、@Value 注解的依赖进行设值，这里的内容也是非常丰富的，不过本文不会展开说了，感兴趣的读者请自行研究 pvs = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvs == null) &#123; return; &#125; &#125; &#125; &#125; if (needsDepCheck) &#123; checkDependencies(beanName, mbd, filteredPds, pvs); &#125; &#125; // 设置 bean 实例的属性值 applyPropertyValues(beanName, mbd, bw, pvs);&#125; initializeBean属性注入完成后，这一步其实就是处理各种回调了，这块代码比较简单。 1234567891011121314151617181920212223242526272829303132333435363738protected Object initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) &#123; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; @Override public Object run() &#123; invokeAwareMethods(beanName, bean); return null; &#125; &#125;, getAccessControlContext()); &#125; else &#123; // 如果 bean 实现了 BeanNameAware、BeanClassLoaderAware 或 BeanFactoryAware 接口，回调 invokeAwareMethods(beanName, bean); &#125; Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) &#123; // BeanPostProcessor 的 postProcessBeforeInitialization 回调 wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); &#125; try &#123; // 处理 bean 中定义的 init-method， // 或者如果 bean 实现了 InitializingBean 接口，调用 afterPropertiesSet() 方法 invokeInitMethods(beanName, wrappedBean, mbd); &#125; catch (Throwable ex) &#123; throw new BeanCreationException( (mbd != null ? mbd.getResourceDescription() : null), beanName, "Invocation of init method failed", ex); &#125; if (mbd == null || !mbd.isSynthetic()) &#123; // BeanPostProcessor 的 postProcessAfterInitialization 回调 wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; return wrappedBean;&#125; 大家发现没有，BeanPostProcessor 的两个回调都发生在这边，只不过中间处理了 init-method，是不是和读者原来的认知有点不一样了？ 附录id 和 name每个 Bean 在 Spring 容器中都有一个唯一的名字（beanName）和 0 个或多个别名（aliases）。 我们从 Spring 容器中获取 Bean 的时候，可以根据 beanName，也可以通过别名。 1beanFactory.getBean("beanName or alias"); 在配置 &lt;bean /&gt; 的过程中，我们可以配置 id 和 name，看几个例子就知道是怎么回事了。 1&lt;bean id="messageService" name="m1, m2, m3" class="com.javadoop.example.MessageServiceImpl"&gt; 以上配置的结果就是：beanName 为 messageService，别名有 3 个，分别为 m1、m2、m3。 1&lt;bean name="m1, m2, m3" class="com.javadoop.example.MessageServiceImpl" /&gt; 以上配置的结果就是：beanName 为 m1，别名有 2 个，分别为 m2、m3。 1&lt;bean class="com.javadoop.example.MessageServiceImpl"&gt; beanName 为：com.javadoop.example.MessageServiceImpl#0， 别名 1 个，为： com.javadoop.example.MessageServiceImpl 1&lt;bean id="messageService" class="com.javadoop.example.MessageServiceImpl"&gt; 以上配置的结果就是：beanName 为 messageService，没有别名。 配置是否允许 Bean 覆盖、是否允许循环依赖我们说过，默认情况下，allowBeanDefinitionOverriding 属性为 null。如果在同一配置文件中 Bean id 或 name 重复了，会抛错，但是如果不是同一配置文件中，会发生覆盖。 可是有些时候我们希望在系统启动的过程中就严格杜绝发生 Bean 覆盖，因为万一出现这种情况，会增加我们排查问题的成本。 循环依赖说的是 A 依赖 B，而 B 又依赖 A。或者是 A 依赖 B，B 依赖 C，而 C 却依赖 A。默认 allowCircularReferences 也是 null。 它们两个属性是一起出现的，必然可以在同一个地方一起进行配置。 添加这两个属性的作者 Juergen Hoeller 在这个 jira 的讨论中说明了怎么配置这两个属性。 1234567891011121314151617181920public class NoBeanOverridingContextLoader extends ContextLoader &#123; @Override protected void customizeContext(ServletContext servletContext, ConfigurableWebApplicationContext applicationContext) &#123; super.customizeContext(servletContext, applicationContext); AbstractRefreshableApplicationContext arac = (AbstractRefreshableApplicationContext) applicationContext; arac.setAllowBeanDefinitionOverriding(false); &#125;&#125;public class MyContextLoaderListener extends org.springframework.web.context.ContextLoaderListener &#123; @Override protected ContextLoader createContextLoader() &#123; return new NoBeanOverridingContextLoader(); &#125;&#125;&lt;listener&gt; &lt;listener-class&gt;com.javadoop.MyContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; 如果以上方式不能满足你的需求，请参考这个链接：解决spring中不同配置文件中存在name或者id相同的bean可能引起的问题 profile我们可以把不同环境的配置分别配置到单独的文件中，举个例子： 12345678910111213141516171819&lt;beans profile="development" xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:jdbc="http://www.springframework.org/schema/jdbc" xsi:schemaLocation="..."&gt; &lt;jdbc:embedded-database id="dataSource"&gt; &lt;jdbc:script location="classpath:com/bank/config/sql/schema.sql"/&gt; &lt;jdbc:script location="classpath:com/bank/config/sql/test-data.sql"/&gt; &lt;/jdbc:embedded-database&gt;&lt;/beans&gt;&lt;beans profile="production" xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:jee="http://www.springframework.org/schema/jee" xsi:schemaLocation="..."&gt; &lt;jee:jndi-lookup id="dataSource" jndi-name="java:comp/env/jdbc/datasource"/&gt;&lt;/beans&gt; 应该不必做过多解释了吧，看每个文件第一行的 profile=””。 当然，我们也可以在一个配置文件中使用： 1234567891011121314151617&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:jdbc="http://www.springframework.org/schema/jdbc" xmlns:jee="http://www.springframework.org/schema/jee" xsi:schemaLocation="..."&gt; &lt;beans profile="development"&gt; &lt;jdbc:embedded-database id="dataSource"&gt; &lt;jdbc:script location="classpath:com/bank/config/sql/schema.sql"/&gt; &lt;jdbc:script location="classpath:com/bank/config/sql/test-data.sql"/&gt; &lt;/jdbc:embedded-database&gt; &lt;/beans&gt; &lt;beans profile="production"&gt; &lt;jee:jndi-lookup id="dataSource" jndi-name="java:comp/env/jdbc/datasource"/&gt; &lt;/beans&gt;&lt;/beans&gt; 理解起来也很简单吧。 接下来的问题是，怎么使用特定的 profile 呢？Spring 在启动的过程中，会去寻找 “spring.profiles.active” 的属性值，根据这个属性值来的。那怎么配置这个值呢？ Spring 会在这几个地方寻找 spring.profiles.active 的属性值：操作系统环境变量、JVM 系统变量、web.xml 中定义的参数、JNDI。 最简单的方式莫过于在程序启动的时候指定： 1-Dspring.profiles.active="profile1,profile2" profile 可以激活多个 当然，我们也可以通过代码的形式从 Environment 中设置 profile： 1234AnnotationConfigApplicationContext ctx = new AnnotationConfigApplicationContext();ctx.getEnvironment().setActiveProfiles("development");ctx.register(SomeConfig.class, StandaloneDataConfig.class, JndiDataConfig.class);ctx.refresh(); // 重启 如果是 Spring Boot 的话更简单，我们一般会创建 application.properties、application-dev.properties、application-prod.properties 等文件，其中 application.properties 配置各个环境通用的配置，application-{profile}.properties 中配置特定环境的配置，然后在启动的时候指定 profile： 1java -Dspring.profiles.active=prod -jar JavaDoop.jar 如果是单元测试中使用的话，在测试类中使用 @ActiveProfiles 指定，这里就不展开了。 工厂模式生成 Bean请读者注意 factory-bean 和 FactoryBean 的区别。这节说的是前者，是说静态工厂或实例工厂，而后者是 Spring 中的特殊接口，代表一类特殊的 Bean，附录的下面一节会介绍 FactoryBean。 设计模式里，工厂方法模式分静态工厂和实例工厂，我们分别看看 Spring 中怎么配置这两个，来个代码示例就什么都清楚了。 静态工厂： 123456789101112&lt;bean id="clientService" class="examples.ClientService" factory-method="createInstance"/&gt;public class ClientService &#123; private static ClientService clientService = new ClientService(); private ClientService() &#123;&#125; // 静态方法 public static ClientService createInstance() &#123; return clientService; &#125;&#125; 实例工厂： 12345678910111213141516171819202122232425&lt;bean id="serviceLocator" class="examples.DefaultServiceLocator"&gt; &lt;!-- inject any dependencies required by this locator bean --&gt;&lt;/bean&gt;&lt;bean id="clientService" factory-bean="serviceLocator" factory-method="createClientServiceInstance"/&gt;&lt;bean id="accountService" factory-bean="serviceLocator" factory-method="createAccountServiceInstance"/&gt;public class DefaultServiceLocator &#123; private static ClientService clientService = new ClientServiceImpl(); private static AccountService accountService = new AccountServiceImpl(); public ClientService createClientServiceInstance() &#123; return clientService; &#125; public AccountService createAccountServiceInstance() &#123; return accountService; &#125;&#125; FactoryBeanFactoryBean 适用于 Bean 的创建过程比较复杂的场景，比如数据库连接池的创建。 123456789public interface FactoryBean&lt;T&gt; &#123; T getObject() throws Exception; Class&lt;T&gt; getObjectType(); boolean isSingleton();&#125;public class Person &#123; private Car car ; private void setCar(Car car)&#123; this.car = car; &#125; &#125; 我们假设现在需要创建一个 Person 的 Bean，首先我们需要一个 Car 的实例，我们这里假设 Car 的实例创建很麻烦，那么我们可以把创建 Car 的复杂过程包装起来： 123456789101112131415161718192021public class MyCarFactoryBean implements FactoryBean&lt;Car&gt;&#123; private String make; private int year ; public void setMake(String m)&#123; this.make =m ; &#125; public void setYear(int y)&#123; this.year = y; &#125; public Car getObject()&#123; // 这里我们假设 Car 的实例化过程非常复杂，反正就不是几行代码可以写完的那种 CarBuilder cb = CarBuilder.car(); if(year!=0) cb.setYear(this.year); if(StringUtils.hasText(this.make)) cb.setMake( this.make ); return cb.factory(); &#125; public Class&lt;Car&gt; getObjectType() &#123; return Car.class ; &#125; public boolean isSingleton() &#123; return false; &#125;&#125; 我们看看装配的时候是怎么配置的： 1234567&lt;bean class = "com.javadoop.MyCarFactoryBean" id = "car"&gt; &lt;property name = "make" value ="Honda"/&gt; &lt;property name = "year" value ="1984"/&gt;&lt;/bean&gt;&lt;bean class = "com.javadoop.Person" id = "josh"&gt; &lt;property name = "car" ref = "car"/&gt;&lt;/bean&gt; 看到不一样了吗？id 为 “car” 的 bean 其实指定的是一个 FactoryBean，不过配置的时候，我们直接让配置 Person 的 Bean 直接依赖于这个 FactoryBean 就可以了。中间的过程 Spring 已经封装好了。 说到这里，我们再来点干货。我们知道，现在还用 xml 配置 Bean 依赖的越来越少了，更多时候，我们可能会采用 java config 的方式来配置，这里有什么不一样呢？ 12345678910111213141516171819@Configuration public class CarConfiguration &#123; @Bean public MyCarFactoryBean carFactoryBean()&#123; MyCarFactoryBean cfb = new MyCarFactoryBean(); cfb.setMake("Honda"); cfb.setYear(1984); return cfb; &#125; @Bean public Person aPerson()&#123; Person person = new Person(); // 注意这里的不同 person.setCar(carFactoryBean().getObject()); return person; &#125; &#125; 这个时候，其实我们的思路也很简单，把 MyCarFactoryBean 看成是一个简单的 Bean 就可以了，不必理会什么 FactoryBean，它是不是 FactoryBean 和我们没关系。 初始化 Bean 的回调有以下四种方案： 123456789101112131415&lt;bean id="exampleInitBean" class="examples.ExampleBean" init-method="init"/&gt;public class AnotherExampleBean implements InitializingBean &#123; public void afterPropertiesSet() &#123; // do some initialization work &#125;&#125;@Bean(initMethod = "init")public Foo foo() &#123; return new Foo();&#125;@PostConstructpublic void init() &#123;&#125; 销毁 Bean 的回调123456789101112131415&lt;bean id="exampleInitBean" class="examples.ExampleBean" destroy-method="cleanup"/&gt;public class AnotherExampleBean implements DisposableBean &#123; public void destroy() &#123; // do some destruction work (like releasing pooled connections) &#125;&#125;@Bean(destroyMethod = "cleanup")public Bar bar() &#123; return new Bar();&#125;@PreDestroypublic void cleanup() &#123;&#125; ConversionService既然文中说到了这个，顺便提一下好了。 最有用的场景就是，它用来将前端传过来的参数和后端的 controller 方法上的参数进行绑定的时候用。 像前端传过来的字符串、整数要转换为后端的 String、Integer 很容易，但是如果 controller 方法需要的是一个枚举值，或者是 Date 这些非基础类型（含基础类型包装类）值的时候，我们就可以考虑采用 ConversionService 来进行转换。 12345678&lt;bean id="conversionService" class="org.springframework.context.support.ConversionServiceFactoryBean"&gt; &lt;property name="converters"&gt; &lt;list&gt; &lt;bean class="com.javadoop.learning.utils.StringToEnumConverterFactory"/&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt; ConversionService 接口很简单，所以要自定义一个 convert 的话也很简单。 下面再说一个实现这种转换很简单的方式，那就是实现 Converter 接口。 来看一个很简单的例子，这样比什么都管用。 1234567891011public class StringToDateConverter implements Converter&lt;String, Date&gt; &#123; @Override public Date convert(String source) &#123; try &#123; return DateUtils.parseDate(source, "yyyy-MM-dd", "yyyy-MM-dd HH:mm:ss", "yyyy-MM-dd HH:mm", "HH:mm:ss", "HH:mm"); &#125; catch (ParseException e) &#123; return null; &#125; &#125;&#125; 只要注册这个 Bean 就可以了。这样，前端往后端传的时间描述字符串就很容易绑定成 Date 类型了，不需要其他任何操作。 Bean 继承在初始化 Bean 的地方，我们说过了这个： 1RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName); 这里涉及到的就是 &lt;bean parent=&quot;&quot; /&gt; 中的 parent 属性，我们来看看 Spring 中是用这个来干什么的。 首先，我们要明白，这里的继承和 java 语法中的继承没有任何关系，不过思路是相通的。child bean 会继承 parent bean 的所有配置，也可以覆盖一些配置，当然也可以新增额外的配置。 Spring 中提供了继承自 AbstractBeanDefinition 的 ChildBeanDefinition 来表示 child bean。 看如下一个例子: 12345678910&lt;bean id="inheritedTestBean" abstract="true" class="org.springframework.beans.TestBean"&gt; &lt;property name="name" value="parent"/&gt; &lt;property name="age" value="1"/&gt;&lt;/bean&gt;&lt;bean id="inheritsWithDifferentClass" class="org.springframework.beans.DerivedTestBean" parent="inheritedTestBean" init-method="initialize"&gt; &lt;property name="name" value="override"/&gt;&lt;/bean&gt; parent bean 设置了 abstract=&quot;true&quot; 所以它不会被实例化，child bean 继承了 parent bean 的两个属性，但是对 name 属性进行了覆写。 child bean 会继承 scope、构造器参数值、属性值、init-method、destroy-method 等等。 当然，我不是说 parent bean 中的 abstract = true 在这里是必须的，只是说如果加上了以后 Spring 在实例化 singleton beans 的时候会忽略这个 bean。 比如下面这个极端 parent bean，它没有指定 class，所以毫无疑问，这个 bean 的作用就是用来充当模板用的 parent bean，此处就必须加上 abstract = true。 1234&lt;bean id="inheritedTestBeanWithoutClass" abstract="true"&gt; &lt;property name="name" value="parent"/&gt; &lt;property name="age" value="1"/&gt;&lt;/bean&gt; 方法注入一般来说，我们的应用中大多数的 Bean 都是 singleton 的。singleton 依赖 singleton，或者 prototype 依赖 prototype 都很好解决，直接设置属性依赖就可以了。 但是，如果是 singleton 依赖 prototype 呢？这个时候不能用属性依赖，因为如果用属性依赖的话，我们每次其实拿到的还是第一次初始化时候的 bean。 一种解决方案就是不要用属性依赖，每次获取依赖的 bean 的时候从 BeanFactory 中取。这个也是大家最常用的方式了吧。怎么取，我就不介绍了，大部分 Spring 项目大家都会定义那么个工具类的。 另一种解决方案就是这里要介绍的通过使用 Lookup method。 lookup-method我们来看一下 Spring Reference 中提供的一个例子： 1234567891011121314151617package fiona.apple;// no more Spring imports!public abstract class CommandManager &#123; public Object process(Object commandState) &#123; // grab a new instance of the appropriate Command interface Command command = createCommand(); // set the state on the (hopefully brand new) Command instance command.setState(commandState); return command.execute(); &#125; // okay... but where is the implementation of this method? protected abstract Command createCommand();&#125; xml 配置 &lt;lookup-method /&gt;： 123456789&lt;!-- a stateful bean deployed as a prototype (non-singleton) --&gt;&lt;bean id="myCommand" class="fiona.apple.AsyncCommand" scope="prototype"&gt; &lt;!-- inject dependencies here as required --&gt;&lt;/bean&gt;&lt;!-- commandProcessor uses statefulCommandHelper --&gt;&lt;bean id="commandManager" class="fiona.apple.CommandManager"&gt; &lt;lookup-method name="createCommand" bean="myCommand"/&gt;&lt;/bean&gt; Spring 采用 CGLIB 生成字节码的方式来生成一个子类。我们定义的类不能定义为 final class，抽象方法上也不能加 final。 lookup-method 上的配置也可以采用注解来完成，这样就可以不用配置 &lt;lookup-method /&gt; 了，其他不变： 1234567891011public abstract class CommandManager &#123; public Object process(Object commandState) &#123; MyCommand command = createCommand(); command.setState(commandState); return command.execute(); &#125; @Lookup("myCommand") protected abstract Command createCommand();&#125; 注意，既然用了注解，要配置注解扫描：&lt;context:component-scan base-package=&quot;com.javadoop&quot; /&gt; 甚至，我们可以像下面这样： 1234567891011public abstract class CommandManager &#123; public Object process(Object commandState) &#123; MyCommand command = createCommand(); command.setState(commandState); return command.execute(); &#125; @Lookup protected abstract MyCommand createCommand();&#125; 上面的返回值用了 MyCommand，当然，如果 Command 只有一个实现类，那返回值也可以写 Command。 replaced-method记住它的功能，就是替换掉 bean 中的一些方法。 12345678public class MyValueCalculator &#123; public String computeValue(String input) &#123; // some real code... &#125; // some other methods...&#125; 方法覆写，注意要实现 MethodReplacer 接口： 123456789public class ReplacementComputeValue implements org.springframework.beans.factory.support.MethodReplacer &#123; public Object reimplement(Object o, Method m, Object[] args) throws Throwable &#123; // get the input value, work with it, and return a computed result String input = (String) args[0]; ... return ...; &#125;&#125; 配置也很简单： 12345678&lt;bean id="myValueCalculator" class="x.y.z.MyValueCalculator"&gt; &lt;!-- 定义 computeValue 这个方法要被替换掉 --&gt; &lt;replaced-method name="computeValue" replacer="replacementComputeValue"&gt; &lt;arg-type&gt;String&lt;/arg-type&gt; &lt;/replaced-method&gt;&lt;/bean&gt;&lt;bean id="replacementComputeValue" class="a.b.c.ReplacementComputeValue"/&gt; arg-type 明显不是必须的，除非存在方法重载，这样必须通过参数类型列表来判断这里要覆盖哪个方法。 BeanPostProcessor应该说 BeanPostProcessor 概念在 Spring 中也是比较重要的。我们看下接口定义： 1234567public interface BeanPostProcessor &#123; Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException; Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException;&#125; 看这个接口中的两个方法名字我们大体上可以猜测 bean 在初始化之前会执行 postProcessBeforeInitialization 这个方法，初始化完成之后会执行 postProcessAfterInitialization 这个方法。但是，这么理解是非常片面的。 首先，我们要明白，除了我们自己定义的 BeanPostProcessor 实现外，Spring 容器在启动时自动给我们也加了几个。如在获取 BeanFactory 的 obtainFactory() 方法结束后的 prepareBeanFactory(factory)，大家仔细看会发现，Spring 往容器中添加了这两个 BeanPostProcessor：ApplicationContextAwareProcessor、ApplicationListenerDetector。 我们回到这个接口本身，读者请看第一个方法，这个方法接受的第一个参数是 bean 实例，第二个参数是 bean 的名字，重点在返回值将会作为新的 bean 实例，所以，没事的话这里不能随便返回个 null。 那意味着什么呢？我们很容易想到的就是，我们这里可以对一些我们想要修饰的 bean 实例做一些事情。但是对于 Spring 框架来说，它会决定是不是要在这个方法中返回 bean 实例的代理，这样就有更大的想象空间了。 最后，我们说说如果我们自己定义一个 bean 实现 BeanPostProcessor 的话，它的执行时机是什么时候？ 如果仔细看了代码分析的话，其实很容易知道了，在 bean 实例化完成、属性注入完成之后，会执行回调方法，具体请参见类 AbstractAutowireCapableBeanFactory#initBean 方法。 首先会回调几个实现了 Aware 接口的 bean，然后就开始回调 BeanPostProcessor 的 postProcessBeforeInitialization 方法，之后是回调 init-method，然后再回调 BeanPostProcessor 的 postProcessAfterInitialization 方法。 总结按理说，总结应该写在附录前面，我就不讲究了。 在花了那么多时间后，这篇文章终于算是基本写完了，大家在惊叹 Spring 给我们做了那么多的事的时候，应该透过现象看本质，去理解 Spring 写得好的地方，去理解它的设计思想。 本文的缺陷在于对 Spring 预初始化 singleton beans 的过程分析不够，主要是代码量真的比较大，分支旁路众多。同时，虽然附录条目不少，但是庞大的 Spring 真的引出了很多的概念，希望日后有精力可以慢慢补充一些。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[J2EE基础知识回回顾]]></title>
    <url>%2F2019%2F05%2F11%2FJ2EE%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE%2F</url>
    <content type="text"><![CDATA[J2EE的复习，感觉已经过时了但还是基础的 Servlet总结 阐述Servlet和CGI的区别? CGI的不足之处: Servlet的优点： Servlet接口中有哪些方法及Servlet生命周期探秘 get和post请求的区别 什么情况下调用doGet()和doPost() 转发（Forward）和重定向（Redirect）的区别 自动刷新(Refresh) Servlet与线程安全 JSP和Servlet是什么关系 JSP工作原理 JSP有哪些内置对象、作用分别是什么 Request对象的主要方法有哪些 request.getAttribute()和 request.getParameter()有何区别 include指令include的行为的区别 JSP九大内置对象，七大动作，三大指令 讲解JSP中的四种作用域 如何实现JSP或Servlet的单线程模式 实现会话跟踪的技术有哪些 Cookie和Session的的区别 Servlet总结在Java Web程序中，Servlet主要负责接收用户请求HttpServletRequest,在doGet(),doPost()中做相应的处理，并将回应HttpServletResponse反馈给用户。Servlet可以设置初始化参数，供Servlet内部使用。一个Servlet类只会有一个实例，在它初始化时调用init()方法，销毁时调用destroy()方法。Servlet需要在web.xml中配置（MyEclipse中创建Servlet会自动配置），一个Servlet可以设置多个URL访问。Servlet不是线程安全，因此要谨慎使用类变量。 阐述Servlet和CGI的区别?CGI的不足之处:1，需要为每个请求启动一个操作CGI程序的系统进程。如果请求频繁，这将会带来很大的开销。 2，需要为每个请求加载和运行一个CGI程序，这将带来很大的开销 3，需要重复编写处理网络协议的代码以及编码，这些工作都是非常耗时的。 Servlet的优点:1，只需要启动一个操作系统进程以及加载一个JVM，大大降低了系统的开销 2，如果多个请求需要做同样处理的时候，这时候只需要加载一个类，这也大大降低了开销 3，所有动态加载的类可以实现对网络协议以及请求解码的共享，大大降低了工作量。 4，Servlet能直接和Web服务器交互，而普通的CGI程序不能。Servlet还能在各个程序之间共享数据，使数据库连接池之类的功能很容易实现。 补充：Sun Microsystems公司在1996年发布Servlet技术就是为了和CGI进行竞争，Servlet是一个特殊的Java程序，一个基于Java的Web应用通常包含一个或多个Servlet类。Servlet不能够自行创建并执行，它是在Servlet容器中运行的，容器将用户的请求传递给Servlet程序，并将Servlet的响应回传给用户。通常一个Servlet会关联一个或多个JSP页面。以前CGI经常因为性能开销上的问题被诟病，然而Fast CGI早就已经解决了CGI效率上的问题，所以面试的时候大可不必信口开河的诟病CGI，事实上有很多你熟悉的网站都使用了CGI技术。 参考：《javaweb整合开发王者归来》P7 Servlet接口中有哪些方法及Servlet生命周期探秘Servlet接口定义了5个方法，其中前三个方法与Servlet生命周期相关： void init(ServletConfig config) throws ServletException void service(ServletRequest req, ServletResponse resp) throws ServletException, java.io.IOException void destory() java.lang.String getServletInfo() ServletConfig getServletConfig() 生命周期： Web容器加载Servlet并将其实例化后，Servlet生命周期开始，容器运行其init()方法进行Servlet的初始化；请求到达时调用Servlet的service()方法，service()方法会根据需要调用与请求对应的doGet或doPost等方法；当服务器关闭或项目被卸载时服务器会将Servlet实例销毁，此时会调用Servlet的destroy()方法。init方法和destroy方法只会执行一次，service方法客户端每次请求Servlet都会执行。Servlet中有时会用到一些需要初始化与销毁的资源，因此可以把初始化资源的代码放入init方法中，销毁资源的代码放入destroy方法中，这样就不需要每次处理客户端的请求都要初始化与销毁资源。 参考：《javaweb整合开发王者归来》P81 get和post请求的区别 网上也有文章说：get和post请求实际上是没有区别，大家可以自行查询相关文章（参考文章：https://www.cnblogs.com/logsharing/p/8448446.html，知乎对应的问题链接：get和post区别？）！我下面给出的只是一种常见的答案。 ①get请求用来从服务器上获得资源，而post是用来向服务器提交数据； ②get将表单中数据按照name=value的形式，添加到action 所指向的URL 后面，并且两者使用”?”连接，而各个变量之间使用”&amp;”连接；post是将表单中的数据放在HTTP协议的请求头或消息体中，传递到action所指向URL； ③get传输的数据要受到URL长度限制（最大长度是 2048 个字符）；而post可以传输大量的数据，上传文件通常要使用post方式； ④使用get时参数会显示在地址栏上，如果这些数据不是敏感数据，那么可以使用get；对于敏感数据还是应用使用post； ⑤get使用MIME类型application/x-www-form-urlencoded的URL编码（也叫百分号编码）文本的格式传递参数，保证被传送的参数由遵循规范的文本组成，例如一个空格的编码是”%20”。 补充：GET方式提交表单的典型应用是搜索引擎。GET方式就是被设计为查询用的。 还有另外一种回答。推荐大家看一下： https://www.zhihu.com/question/28586791 https://mp.weixin.qq.com/s?__biz=MzI3NzIzMzg3Mw==&amp;mid=100000054&amp;idx=1&amp;sn=71f6c214f3833d9ca20b9f7dcd9d33e4#rd 什么情况下调用doGet()和doPost()Form标签里的method的属性为get时调用doGet()，为post时调用doPost()。 转发(Forward)和重定向(Redirect)的区别转发是服务器行为，重定向是客户端行为。 转发（Forward） 通过RequestDispatcher对象的forward（HttpServletRequest request,HttpServletResponse response）方法实现的。RequestDispatcher可以通过HttpServletRequest 的getRequestDispatcher()方法获得。例如下面的代码就是跳转到login_success.jsp页面。 1request.getRequestDispatcher(&quot;login_success.jsp&quot;).forward(request, response); 重定向（Redirect） 是利用服务器返回的状态码来实现的。客户端浏览器请求服务器的时候，服务器会返回一个状态码。服务器通过 HttpServletResponse 的 setStatus(int status) 方法设置状态码。如果服务器返回301或者302，则浏览器会到新的网址重新请求该资源。 从地址栏显示来说 forward是服务器请求资源,服务器直接访问目标地址的URL,把那个URL的响应内容读取过来,然后把这些内容再发给浏览器.浏览器根本不知道服务器发送的内容从哪里来的,所以它的地址栏还是原来的地址. redirect是服务端根据逻辑,发送一个状态码,告诉浏览器重新去请求那个地址.所以地址栏显示的是新的URL. 从数据共享来说 forward:转发页面和转发到的页面可以共享request里面的数据. redirect:不能共享数据. 从运用地方来说 forward:一般用于用户登陆的时候,根据角色转发到相应的模块. redirect:一般用于用户注销登陆时返回主页面和跳转到其它的网站等 从效率来说 forward:高. redirect:低. 自动刷新(Refresh)自动刷新不仅可以实现一段时间之后自动跳转到另一个页面，还可以实现一段时间之后自动刷新本页面。Servlet中通过HttpServletResponse对象设置Header属性实现自动刷新例如： 1Response.setHeader(&quot;Refresh&quot;,&quot;5;URL=http://localhost:8080/servlet/example.htm&quot;); 其中5为时间，单位为秒。URL指定就是要跳转的页面（如果设置自己的路径，就会实现每过5秒自动刷新本页面一次） Servlet与线程安全Servlet不是线程安全的，多线程并发的读写会导致数据不同步的问题。 解决的办法是尽量不要定义name属性，而是要把name变量分别定义在doGet()和doPost()方法内。虽然使用synchronized(name){}语句块可以解决问题，但是会造成线程的等待，不是很科学的办法。 注意：多线程的并发的读写Servlet类属性会导致数据不同步。但是如果只是并发地读取属性而不写入，则不存在数据不同步的问题。因此Servlet里的只读属性最好定义为final类型的。 参考：《javaweb整合开发王者归来》P92 JSP和Servlet是什么关系其实这个问题在上面已经阐述过了，Servlet是一个特殊的Java程序，它运行于服务器的JVM中，能够依靠服务器的支持向浏览器提供显示内容。JSP本质上是Servlet的一种简易形式，JSP会被服务器处理成一个类似于Servlet的Java程序，可以简化页面内容的生成。Servlet和JSP最主要的不同点在于，Servlet的应用逻辑是在Java文件中，并且完全从表示层中的HTML分离开来。而JSP的情况是Java和HTML可以组合成一个扩展名为.jsp的文件。有人说，Servlet就是在Java中写HTML，而JSP就是在HTML中写Java代码，当然这个说法是很片面且不够准确的。JSP侧重于视图，Servlet更侧重于控制逻辑，在MVC架构模式中，JSP适合充当视图（view）而Servlet适合充当控制器（controller）。 JSP工作原理JSP是一种Servlet，但是与HttpServlet的工作方式不太一样。HttpServlet是先由源代码编译为class文件后部署到服务器下，为先编译后部署。而JSP则是先部署后编译。JSP会在客户端第一次请求JSP文件时被编译为HttpJspPage类（接口Servlet的一个子类）。该类会被服务器临时存放在服务器工作目录里面。下面通过实例给大家介绍。 工程JspLoginDemo下有一个名为login.jsp的Jsp文件，把工程第一次部署到服务器上后访问这个Jsp文件，我们发现这个目录下多了下图这两个东东。 .class文件便是JSP对应的Servlet。编译完毕后再运行class文件来响应客户端请求。以后客户端访问login.jsp的时候，Tomcat将不再重新编译JSP文件，而是直接调用class文件来响应客户端请求。 由于JSP只会在客户端第一次请求的时候被编译 ，因此第一次请求JSP时会感觉比较慢，之后就会感觉快很多。如果把服务器保存的class文件删除，服务器也会重新编译JSP。 开发Web程序时经常需要修改JSP。Tomcat能够自动检测到JSP程序的改动。如果检测到JSP源代码发生了改动。Tomcat会在下次客户端请求JSP时重新编译JSP，而不需要重启Tomcat。这种自动检测功能是默认开启的，检测改动会消耗少量的时间，在部署Web应用的时候可以在web.xml中将它关掉。 参考：《javaweb整合开发王者归来》P97 JSP有哪些内置对象、作用分别是什么JSP内置对象 - CSDN博客 JSP有9个内置对象： request：封装客户端的请求，其中包含来自GET或POST请求的参数； response：封装服务器对客户端的响应； pageContext：通过该对象可以获取其他对象； session：封装用户会话的对象； application：封装服务器运行环境的对象； out：输出服务器响应的输出流对象； config：Web应用的配置对象； page：JSP页面本身（相当于Java程序中的this）； exception：封装页面抛出异常的对象。 Request对象的主要方法有哪些 setAttribute(String name,Object)：设置名字为name的request 的参数值 getAttribute(String name)：返回由name指定的属性值 getAttributeNames()：返回request 对象所有属性的名字集合，结果是一个枚举的实例 getCookies()：返回客户端的所有 Cookie 对象，结果是一个Cookie 数组 getCharacterEncoding() ：返回请求中的字符编码方式 = getContentLength() ：返回请求的 Body的长度 getHeader(String name) ：获得HTTP协议定义的文件头信息 getHeaders(String name) ：返回指定名字的request Header 的所有值，结果是一个枚举的实例 getHeaderNames() ：返回所以request Header 的名字，结果是一个枚举的实例 getInputStream() ：返回请求的输入流，用于获得请求中的数据 getMethod() ：获得客户端向服务器端传送数据的方法 getParameter(String name) ：获得客户端传送给服务器端的有 name指定的参数值 getParameterNames() ：获得客户端传送给服务器端的所有参数的名字，结果是一个枚举的实例 getParameterValues(String name)：获得有name指定的参数的所有值 getProtocol()：获取客户端向服务器端传送数据所依据的协议名称 getQueryString() ：获得查询字符串 getRequestURI() ：获取发出请求字符串的客户端地址 getRemoteAddr()：获取客户端的 IP 地址 getRemoteHost() ：获取客户端的名字 getSession([Boolean create]) ：返回和请求相关 Session getServerName() ：获取服务器的名字 getServletPath()：获取客户端所请求的脚本文件的路径 getServerPort()：获取服务器的端口号 removeAttribute(String name)：删除请求中的一个属性 request.getAttribute()和 request.getParameter()有何区别从获取方向来看： getParameter()是获取 POST/GET 传递的参数值； getAttribute()是获取对象容器中的数据值； 从用途来看： getParameter用于客户端重定向时，即点击了链接或提交按扭时传值用，即用于在用表单或url重定向传值时接收数据用。 getAttribute用于服务器端重定向时，即在 sevlet 中使用了 forward 函数,或 struts 中使用了 mapping.findForward。 getAttribute 只能收到程序用 setAttribute 传过来的值。 另外，可以用 setAttribute,getAttribute 发送接收对象.而 getParameter 显然只能传字符串。 setAttribute 是应用服务器把这个对象放在该页面所对应的一块内存中去，当你的页面服务器重定向到另一个页面时，应用服务器会把这块内存拷贝另一个页面所对应的内存中。这样getAttribute就能取得你所设下的值，当然这种方法可以传对象。session也一样，只是对象在内存中的生命周期不一样而已。getParameter只是应用服务器在分析你送上来的 request页面的文本时，取得你设在表单或 url 重定向时的值。 总结： getParameter 返回的是String,用于读取提交的表单中的值;（获取之后会根据实际需要转换为自己需要的相应类型，比如整型，日期类型啊等等） getAttribute 返回的是Object，需进行转换,可用setAttribute 设置成任意对象，使用很灵活，可随时用 include指令include的行为的区别include指令： JSP可以通过include指令来包含其他文件。被包含的文件可以是JSP文件、HTML文件或文本文件。包含的文件就好像是该JSP文件的一部分，会被同时编译执行。 语法格式如下： &lt;%@ include file=”文件相对 url 地址” %&gt; include动作： jsp:include动作元素用来包含静态和动态的文件。该动作把指定文件插入正在生成的页面。语法格式如下： &lt;jsp:include page=”相对 URL 地址” flush=”true” /&gt; JSP九大内置对象，七大动作，三大指令JSP九大内置对象，七大动作，三大指令总结 讲解JSP中的四种作用域JSP中的四种作用域包括page、request、session和application，具体来说： page代表与一个页面相关的对象和属性。 request代表与Web客户机发出的一个请求相关的对象和属性。一个请求可能跨越多个页面，涉及多个Web组件；需要在页面显示的临时数据可以置于此作用域。 session代表与某个用户与服务器建立的一次会话相关的对象和属性。跟某个用户相关的数据应该放在用户自己的session中。 application代表与整个Web应用程序相关的对象和属性，它实质上是跨越整个Web应用程序，包括多个页面、请求和会话的一个全局作用域。 如何实现JSP或Servlet的单线程模式对于JSP页面，可以通过page指令进行设置。 &lt;%@page isThreadSafe=”false”%&gt; 对于Servlet，可以让自定义的Servlet实现SingleThreadModel标识接口。 说明：如果将JSP或Servlet设置成单线程工作模式，会导致每个请求创建一个Servlet实例，这种实践将导致严重的性能问题（服务器的内存压力很大，还会导致频繁的垃圾回收），所以通常情况下并不会这么做。 实现会话跟踪的技术有哪些 使用Cookie 向客户端发送Cookie 123Cookie c =new Cookie("name","value"); //创建Cookie c.setMaxAge(60*60*24); //设置最大时效，此处设置的最大时效为一天response.addCookie(c); //把Cookie放入到HTTP响应中 从客户端读取Cookie 123456789101112String name ="name"; Cookie[]cookies =request.getCookies(); if(cookies !=null)&#123; for(int i= 0;i&lt;cookies.length;i++)&#123; Cookie cookie =cookies[i]; if(name.equals(cookis.getName())) //something is here. //you can get the value cookie.getValue(); &#125; &#125; 优点: 数据可以持久保存，不需要服务器资源，简单，基于文本的Key-Value 缺点: 大小受到限制，用户可以禁用Cookie功能，由于保存在本地，有一定的安全风险。 URL 重写 在URL中添加用户会话的信息作为请求的参数，或者将唯一的会话ID添加到URL结尾以标识一个会话。 优点： 在Cookie被禁用的时候依然可以使用 缺点： 必须对网站的URL进行编码，所有页面必须动态生成，不能用预先记录下来的URL进行访问。 3.隐藏的表单域 1&lt;input type="hidden" name ="session" value="..."/&gt; 优点： Cookie被禁时可以使用 缺点： 所有页面必须是表单提交之后的结果。 HttpSession 在所有会话跟踪技术中，HttpSession对象是最强大也是功能最多的。当一个用户第一次访问某个网站时会自动创建 HttpSession，每个用户可以访问他自己的HttpSession。可以通过HttpServletRequest对象的getSession方 法获得HttpSession，通过HttpSession的setAttribute方法可以将一个值放在HttpSession中，通过调用 HttpSession对象的getAttribute方法，同时传入属性名就可以获取保存在HttpSession中的对象。与上面三种方式不同的 是，HttpSession放在服务器的内存中，因此不要将过大的对象放在里面，即使目前的Servlet容器可以在内存将满时将HttpSession 中的对象移到其他存储设备中，但是这样势必影响性能。添加到HttpSession中的值可以是任意Java对象，这个对象最好实现了 Serializable接口，这样Servlet容器在必要的时候可以将其序列化到文件中，否则在序列化时就会出现异常。 Cookie和Session的的区别 由于HTTP协议是无状态的协议，所以服务端需要记录用户的状态时，就需要用某种机制来识具体的用户，这个机制就是Session.典型的场景比如购物车，当你点击下单按钮时，由于HTTP协议无状态，所以并不知道是哪个用户操作的，所以服务端要为特定的用户创建了特定的Session，用用于标识这个用户，并且跟踪用户，这样才知道购物车里面有几本书。这个Session是保存在服务端的，有一个唯一标识。在服务端保存Session的方法很多，内存、数据库、文件都有。集群的时候也要考虑Session的转移，在大型的网站，一般会有专门的Session服务器集群，用来保存用户会话，这个时候 Session 信息都是放在内存的，使用一些缓存服务比如Memcached之类的来放 Session。 思考一下服务端如何识别特定的客户？这个时候Cookie就登场了。每次HTTP请求的时候，客户端都会发送相应的Cookie信息到服务端。实际上大多数的应用都是用 Cookie 来实现Session跟踪的，第一次创建Session的时候，服务端会在HTTP协议中告诉客户端，需要在 Cookie 里面记录一个Session ID，以后每次请求把这个会话ID发送到服务器，我就知道你是谁了。有人问，如果客户端的浏览器禁用了 Cookie 怎么办？一般这种情况下，会使用一种叫做URL重写的技术来进行会话跟踪，即每次HTTP交互，URL后面都会被附加上一个诸如 sid=xxxxx 这样的参数，服务端据此来识别用户。 Cookie其实还可以用在一些方便用户的场景下，设想你某次登陆过一个网站，下次登录的时候不想再次输入账号了，怎么办？这个信息可以写到Cookie里面，访问网站的时候，网站页面的脚本可以读取这个信息，就自动帮你把用户名给填了，能够方便一下用户。这也是Cookie名称的由来，给用户的一点甜头。所以，总结一下：Session是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中；Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java多线程（二）]]></title>
    <url>%2F2019%2F05%2F10%2FJava%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[最近在重新整理我之前做过的一个web服务器项目，设计到的主要是TCP的Java编程，然后今天做一个笔试题有一些其他Java网络编程的知识，很蒙，今晚学习了一下基本使用 InetAddress获取主机的IP地址等信息 URL，统一资源定位符。通过这个可以打开一个输入流和获取一个连接，从流里面可以获取资源 URLEncoder进行编码，URKLDecoder进行解码 ServertSocket，这个这里就没有案例了，因为我比较了解。 UDP的 DatagramPacket（包装一条信息）和 DatagramSocket（发送/接受 一条信息） 1、InetAddress12345678910111213141516171819202122232425/** * InetAddress主要用于IP地址，有两个子类Inet4Address Inet6Address */public class InetAddressDemo &#123; public static void main(String[] args) throws IOException &#123; //获取本机InetAddress InetAddress locAdd=InetAddress.getLocalHost(); //根据名称获取InetAddress InetAddress baidu=InetAddress.getByName("www.baidu.com"); InetAddress.getByAddress(locAdd.getAddress()); //需要一个字节数组 //获取一些信息 System.out.println("本机主机地址为："+locAdd.getHostAddress()); System.out.println("百度主机地址为："+baidu.getHostAddress()); //getAddress方法和getHostAddress类似，它们的唯一区别是getHostAddress方法返回的是字符串形式的IP地址， // 而getAddress方法返回的是byte数组形式的IP地址。 System.out.println("本机是地址： "); byte[] address = locAdd.getAddress(); for (byte b : address) &#123; System.out.print(b&gt;0?b:256+b); //注意这里的转换 &#125; System.out.println(); System.out.println("本机是否可连接："+locAdd.isReachable(5000)); System.out.println("百度时候可达：" + baidu.isReachable(5000)); &#125;&#125; 2、URL12345678910111213141516171819202122232425262728/** * URL：统一资源定位符，通过这个可以准确的找到一个网页 */public class URLDemo &#123; public static void main(String[] args) throws Exception &#123; //构造方法有两种，根据String的地址 或者 主机+端口+uri URL url=new URL("https://www.cnblogs.com/yulinfeng/p/5844151.html"); URLConnection urlConnection = url.openConnection(); //打开一个连接 System.out.println("内容的大小："+urlConnection.getContentLength()); System.out.println("内容类型"+urlConnection.getContentType()); InputStream inputStream = url.openStream(); //获取一个输入流 File file=new File("H:\\java\\idea-workspace\\jvm\\src\\com\\test.html"); BufferedWriter bufferedWriter=new BufferedWriter(new FileWriter(file,true));//可设置追加 Scanner scanner=new Scanner(inputStream); while (scanner.hasNext())&#123; bufferedWriter.write(scanner.next()); bufferedWriter.newLine(); bufferedWriter.flush(); &#125; scanner.close(); bufferedWriter.close(); System.out.println("ok"); &#125;&#125; 3、编码解码1234567891011121314/** * URL的编码和解码操作：URLEncoder进行编码，URKLDecoder进行解码 * 这个也是比较常用的 */public class URLCoderDemo &#123; public static void main(String[] args) throws UnsupportedEncodingException &#123; String file="中文"; String gb2312 = URLEncoder.encode(file, "utf-8"); //编码 String comeBack= URLDecoder.decode(file,"utf-8"); //解码 System.out.println(file); System.out.println(gb2312); System.out.println(comeBack); &#125;&#125; 4、UDP实现简单客户端和服务端123456789101112131415161718192021222324252627282930313233343536373839404142/** * TCP的socket变成，我有做过一个web服务器，相对比较熟悉、 * 直接UDP, * DatagramPacket（包装一条信息）和DatagramSocket（发送/接受 一条信息） *///客户端public class Server &#123; public static void main(String[] args) throws SocketException &#123; //DatagramPacket提供两个构造方法 byte[] bytes = new byte[1204]; DatagramPacket packet=new DatagramPacket(bytes,1204); //还可以添加主机地址 和 端口号 DatagramSocket socket=new DatagramSocket(6666); System.out.println("等待接受消息"); try &#123; socket.receive(packet); String message=new String(packet.getData(), 0,packet.getLength()); //数据包可以获取数据 和 数据长度 System.out.println("from:"+packet.getAddress()+": "+packet.getPort()); System.out.println("收到信息"); System.out.println(message); socket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125;public class Client &#123; public static void main(String[] args) throws IOException &#123; byte[] bytes = "wo ai ni ".getBytes(); //客户端需要地址，和端口 DatagramPacket datagramPacket=new DatagramPacket (bytes,bytes.length, InetAddress.getByName("localhost"),6666); DatagramSocket datagramSocket=new DatagramSocket(8888); //客户端端口 //socket可以接和发，客户端发，服务端收 //结合 System.out.println("发送 udp ----"); datagramSocket.send(datagramPacket); System.out.println("发送 完毕===="); datagramSocket.close(); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>学习</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Manacher和KMP]]></title>
    <url>%2F2019%2F05%2F09%2FManacher%E5%92%8CKMP%2F</url>
    <content type="text"><![CDATA[Manacher和KMP实现 Manacher和KMP1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/* * Manacher * 1、help数组，用来记录每个位置的最长回文长度 * 2、R，记录最右边界 * 3、C,记录最右边界的中心 * * 思路：一、如果当前位置不被R包裹，直接进行暴力求回文。并跟新C和R * 二、如果当前位置被R包裹 * 1、当前位置以C为中心的对称点，的回文长度没有突破R回文边界，当前位置回文就等于对称位置的回文长度 * 2、当前位置以C为中心的对称点，的回文长度突破了R回文边界，当前位置回文就等于R-i * 3、恰好踩在了R位置，直接以半径为len去暴力求新的len。跟新C和R。 */public class Marnach &#123; public static int difStrlen(String str)&#123; char[] ss=str.toCharArray(); int[] index=new int[128]; int len=0; for(int j=0, i=0;i&lt;ss.length;i++)&#123; j=Math.max(j, index[ss[i]]); len=Math.max(len, i-j+1); index[ss[i]]=i+1; &#125; return len; &#125; public static int findMlen(String str)&#123; char[] c=new char[str.length() * 2 - 1]; int a=0; for (int i = 0; i &lt; str.length(); i++) &#123; c[a++]=str.charAt(i); if(i!=str.length()-1)&#123; c[a++]='#'; &#125; &#125; int R =-1; //右边界 int C=0; //回文中心 int max=0; int[] help=new int[c.length]; int i=0; int len; //记录当前当前位置的回文长度 while(R&lt;c.length &amp;&amp; i&lt;c.length)&#123; if(R==c.length-1)&#123; break; &#125; if(i&gt;R)&#123; len = postLen(c,i,1); help[i]=len; C=i; R=i+len-1; &#125;else&#123; len=help[2*C-i]; if(len+(i-C)&lt;help[C])&#123; help[i]=help[2*C-i]; &#125;else if(len+(i-C)&gt;help[C])&#123; help[i]=help[C]-(i-C); &#125;else&#123; len=postLen(c, i, len); help[i]=len; C=i; R=i+len-1; &#125; &#125; max=Math.max(max, help[i]); i++; &#125; return max; &#125; private static int postLen(char[] c, int i,int len) &#123; while(i-len&gt;-1 &amp;&amp; i+len&lt;c.length &amp;&amp; c[i-len]==c[i+len])&#123; len++; &#125; return len; &#125; public static void main(String[] args) &#123; System.out.println(findMlen("aasdbbbbbbdsaa")); System.out.println(difStrlen("stradad")); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * KmpTest */public class KmpTest &#123; public static int kmp(String str1,String str2)&#123; char[] c1=str1.toCharArray(); char[] c2=str2.toCharArray(); int i=0,j=0; int[] next =findMinlen(str2); while(i&lt;c1.length &amp;&amp; j&lt;c2.length)&#123; if(c1[i]==c2[j])&#123; i++;j++; &#125;else if(next[j]==-1)&#123; i++; &#125;else&#123; j=next[j]; &#125; &#125; return j==c2.length?c1.length-c2.length:-1; &#125; public static int[] findMinlen(String str)&#123; char[] c=str.toCharArray(); int[] next=new int[str.length()+1]; next[0]=-1; next[1]=0; int cn=0; int i=2; while(i&lt;=str.length())&#123; if(c[i-1]==c[cn])&#123; next[i++]=++cn; &#125;else if(cn&gt;0)&#123; cn=next[cn]; &#125;else&#123; next[i++]=0; &#125; &#125; System.out.println(str+str.substring(next[i-1], str.length())); return next; &#125; public static void main(String[] args) &#123; findMinlen("adad"); System.out.println(kmp("str1", "r1")); &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL锁和事务]]></title>
    <url>%2F2019%2F05%2F07%2FMySQL%E9%94%81%E5%92%8C%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[MySQL一些高级知识点也复习了一下啦 回顾一些知识点： 一、事务构成单一逻辑工作单元的操作集合称作事务。例如淘宝买东西，从你账户中扣款到淘宝账户，这就是一个事务，涉及两个读写操作。要么都成功，要么都不成功。事务具有4大特性：ACID 原子性（atomicity）：事务所有操作在数据库中要么全部正确反应，要么完全不反应。 一致性（consistency）：隔离执行事务时，保持数据库前后数据的一致性。这是事务程序员的责任。 隔离性（isolation）：尽管多个事务并发执行，系统也得确保其中一个事务正常执行而不被来自并发执行的数据库语句干扰。 持久性（durability）：事务完成后，对数据库的改变必须是永久的，即使系统出现故障。 二、事务隔离级别为了保证多个事务对同一个表访问的并发执行，MySQL提供了四个事务隔离性级别，事务调用策略将根据隔离级别配置实现不同的事务执行调度尽量保证并发性。级别从低到高依次是 未提交读（read uncommitted）：就是一个事务可以读取另一个未提交事务的数据（脏读问题） 已提交的读（read committed）：就是一个事务要等另一个事务提交后才能读取数据。（不可重复读问题） 可重复读（repeatabl read）：就是在某个事务开始读取数据（事务开启）时，另外事务不再允许修改（update数据）操作。（幻读问题） 可串行化（serializable）：保证事务的以串行化顺序执行。效率最低的一种事务执行方式，导致事务没有并发的可能性。 MySQL的每一条单一的SQL语句都是期望着具有原子性的，也就是一句SQL语句的执行是不会被打断的，但涉及到并发的访问与表资源的共享，会出现一些问题，底部需要有一种锁的机制来维持这种原子性。具体到不同的引擎实现的机制是不一样的，对于Innodb的实现默认是使用的行锁，达到可重复度的隔离级别。 来看看锁 一、表锁表锁是MyISAM的默认锁，它是偏读的锁，建锁的成本低，锁的颗粒度大，并发度低，尤其是写锁，并发度极低。 怎么用： 首先你要使你的表的引擎是MyISAM show open tables 或者 show table status可以查看表的上锁情况 lock table youtable read(write)上锁。 unlock tables 解锁 read锁：自己可读不可改，别人可读改阻塞（共享锁） write锁：自己可读也可改，别人读写都阻塞（独占锁） 表锁不是研究的重点，和事务的第四个隔离级别有关，事务时InnoDB支持的，所以重点看看行锁。 二、行锁行锁时InnoDB的实现事务的锁。它时偏写的锁，建锁的成本也较高，但是锁的颗粒度时最小的，并发度也是最高的。 怎么用： 在一个事务操作里，有update性质或者声明了update的操作，那么这行就会被上锁。 前面说过在一个单一的SQL语句里其实就是一个事务，或者说是一个原子操作，并且每次执行都会自动commit。我们稍微设置一下：set autocommit=0，那么我们就每条sql语句都需要手动提交，变成了一个个事务了。 行锁有什么特点： 读的可见性：A改的A能马上看见，B需要A和B都提交了才能开得到变化===这不就是可重复读 写的原则性：A改某一行，B也去改同一行阻塞，改其他行不阻塞 行锁和事务的隔离级别：都说MySQL的默认隔离级别时可重复读，那么你会发现可重复的要求刚刚时行锁提供的，要求双方都提交才能看到对方的改变，当时因为时行锁，有别人可能会插入数据，提交之后再读可能会多处数据，这就是幻读。 那么读已提交和读未提交是怎么回事呢 读未提交：这个好说，啥也不干，事务修改数据之后直接写如主表（有点像JMM主内存），其他事务读取就会看到变化，那么就出现脏读。 读已提交：读已提交有点像改的内容先放在工作内存，只有当commit的时候才会写入主表，别的事务就能读到改变。这样事务前后读的就不一样的，出现了不可重复读的wenti。 行锁的一一些问题 测试发现，锁行的条件（where语句后面的条件），一定要上索引，没有索引直接变表锁 如果where条件使得索引失效，比如varchar类型没加双引号作为了查询条件，使用了like模糊，组成索引没有符合最左前缀索引失效，都是会使得行锁变表锁 结合上面两点：行锁的锁定是依赖索引的 还有一点是间隙锁：就是当锁定的行是一个范围的时候，再这个范围里面插入也是会阻塞的 总结一下：其实天下并发一个样，既要高并发，又要高可用，为了能安全的用必须要个锁，锁马马虎虎可以全部锁上，这样必然影响并发性，阻塞增加。我们要做的是有一个合理的锁的力度，表锁到行锁的变化和Java中的Hashtable到ConcurrentHashMap的思想是一致的，锁的颗粒度减小必然操作也是更复杂的，我们再高效又高用的道路上一直前进。 最后补上MySQL主从复制 三、MySQL 主从复制原理MySQL主从复制涉及到三个线程，一个运行在主节点（log dump thread），其余两个(I/O thread, SQL thread)运行在从节点，如下图所示: l 主节点 binary log dump 线程 当从节点连接主节点时，主节点会创建一个log dump 线程，用于发送bin-log的内容。在读取bin-log中的操作时，此线程会对主节点上的bin-log加锁，当读取完成，甚至在发动给从节点之前，锁会被释放。 l 从节点I/O线程 当从节点上执行start slave命令之后，从节点会创建一个I/O线程用来连接主节点，请求主库中更新的bin-log。I/O线程接收到主节点binlog dump 进程发来的更新之后，保存在本地relay-log中。 l 从节点SQL线程 SQL线程负责读取relay log中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。 总的流程是，主写dump，主dump io 到从relay，从机读取执行sql。]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java多线程工具类（一）]]></title>
    <url>%2F2019%2F05%2F05%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[记录一下 123456789101112131415161718192021222324/** * 一个线程要在其他线程全部结束后在结束的n种方法。。。。 * 1、sleep，可以估算的情况下可以，最垃圾的办法 * 2、join,将其他线程一个个的join进来，还凑合，但是麻烦 * 3、while(Thread.activeCount()&gt;2) yeild。这个在平时测试还是很不错的一个办法。2表示main线程和gc线程。 * 4、CountDownLacthTest，并发工具。 * 5、CyclicBarrier，同步屏障。 */public class CountDownLacthTest &#123; static CountDownLatch c=new CountDownLatch(20); static AtomicInteger integer=new AtomicInteger(0); public static void main(String[] args) throws InterruptedException &#123; for (int i = 0; i &lt;20 ; i++) &#123; new Thread(() -&gt; &#123; for (int j = 0; j &lt;100 ; j++) &#123; integer.incrementAndGet(); &#125; c.countDown(); &#125;, "i").start(); &#125; c.await(); System.out.println(integer); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041/** * CycliBarrier，也是设置一个初始值，每个线程调用 await方法。 * 当await调用的次数达到了初始值，所有等待线程释放。 * 此外CycliBarrierh还有一些其他功能，比如当都到达屏障可以设置一个先要去执行的方法。 * 还可以reset(),重置计数器，让线程重新执行一次。 * 还有一些其他的有用的方法，isBroken，getNumberwaiting. */public class CycliBarrierTest implements Runnable&#123; CyclicBarrier c=new CyclicBarrier(10, this); ConcurrentHashMap&lt;String,Integer&gt; map=new ConcurrentHashMap&lt;&gt;(); private void count()&#123; for (int i = 0; i &lt;10 ; i++) &#123; int finalI = i; new Thread(() -&gt; &#123; map.put(Thread.currentThread().getName(),Integer.valueOf(finalI)); try &#123; c.await(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125; &#125; @Override public void run() &#123; AtomicInteger result= new AtomicInteger(); map.forEach((k,v) -&gt; &#123; result.addAndGet(v); &#125;); int s=0; for(Map.Entry&lt;String,Integer&gt; entry :map.entrySet())&#123; s+=entry.getValue(); &#125; System.out.println(result+" "+s); &#125; public static void main(String[] args)&#123; CycliBarrierTest cycliBarrierTest=new CycliBarrierTest(); cycliBarrierTest.count(); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL高级知识]]></title>
    <url>%2F2019%2F05%2F04%2FMySQL%E9%AB%98%E7%BA%A7%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[开始学习一些数据库的高级知识，以及复习之前学过的知识 MySQL内部架构 连接层：连接业务 服务层：sql分析，sql优化 引擎层：各种引擎，可以选择使用 存储层：与底层设备打交道 InnoDB和MyISAM 区别：\1. InnoDB支持事务，MyISAM不支持，对于InnoDB每一条SQL语言都默认封装成事务，自动提交，这样会影响速度，所以最好把多条SQL语言放在begin和commit之间，组成一个事务； \2. InnoDB支持外键，而MyISAM不支持。对一个包含外键的InnoDB表转为MYISAM会失败； \3. InnoDB是聚集索引，数据文件是和索引绑在一起的，必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而MyISAM是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。 \4. InnoDB不保存表的具体行数，执行select count(*) from table时需要全表扫描。而MyISAM用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快； \5. Innodb不支持全文索引，而MyISAM支持全文索引，查询效率上MyISAM要高； InnoDB：事务、行锁、外键、聚集索引、不支持全文， sql语句优化：一、join： 记住这个图的前五个，后面的可以直接用union。union可以去重。 1234567896:左连接加有链接就是了select * from u right join t on u.t_id=t.id -&gt; union -&gt; select * from u left join t on u.t_id=t.id;7:4+5就得到了7select * from u right join t on u.t_id=t.id where u.t_id is null -&gt; union -&gt; select * from u left join t on u.t_id=t.id where t.id is null; 二、索引：索引（index）是MySQL高效查询的数据结构索引的两大功能：查找和排序。where和order的影响 1、什么时候需要建立索引： 主键自动建自增的不为空的唯一索引 需要频繁查询的列建立索引 需要排序分组的建立索引 外键 2、什么时候不需要建立索引 数据量比较小 需要频繁修改的 字段重复性高的，比如性别、国籍 索引基础信息我已经再 &gt;&gt;MySQL索引里面记录，这里不再重复。 三、性能分析性能分析主要有三步骤 1、分析MySQL自动优化结果，optirniz，一般我们都是用MySQL默认的，所以这部分罢了 2、机器性能查开：top,free,iostat,vmstat。查看机器性能 3、explian分析sql语句 id：分析sql执行的顺序，id相同从上往下，id不同id大的优先 select-type：sql语句的类型，有simple，primaty, subquery（子查询）,Derived,union type（重要）：查询类型，一般来说，得保证查询至少达到range级别，最好能达到ref。 system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; all table:查询的表 possible_keys 和 key：可能用到的索引和实际用到的索引，也是很重要的指标 key_len： 表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度，在不损失精确性的情况下，长度越短越好。 ref：显示索引的那一列被使用了，如果可能的话，最好是一个常数。哪些列或常量被用于查找索引列上的值。 row：得到结构大致估计需要扫描的行数，自然越小越好，也是很重要的指标 Extra：包含不适合在其他列中显式但十分重要的额外信息 using filesort，文件内部发生了排序，没用用到索引（九死一生） using temporary，使用了历史表保存了中间结果，常见于排序order by和分组查询group by。（十死无生） usring index，使用到了索引，覆盖索引。 四、索引优化索引建立 单表：为查询字段建立索引，并且避免索引失效 双表：为连接进来的表建立索引，因为原表反正都要查看 三表同样，应该让jion进来的表加索引 join用小表驱动大表，就是让大表jion进来，给大表加索引。让被驱动的字段加上索引 索引失效： 复合索引，要遵循最左前缀原则，带头大哥不能没，中间兄弟不能断 复合索引中间兄弟不能有范围查询，会让后面的失去索引 索引的条件不能有任何计算 不等于，与&gt;&lt; 查找都会丢失索引。 like： %x% 和%x 有索引失效，x%不会。 如何让%x%，有索引，这里只能用上覆盖索引，就是给某些列加上复合索引，查询的时候只查其中的列，就可以不用去表里查过，可以用上using index。从type 从 all变成index]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL索引]]></title>
    <url>%2F2019%2F05%2F04%2FMySQL%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[MySQL索引摘抄 mysql的索引分为单列索引(主键索引,唯索引,普通索引)和组合索引. 单列索引:一个索引只包含一个列,一个表可以有多个单列索引. 组合索引:一个组合索引包含两个或两个以上的列, (一)索引的创建 1.单列索引 1-1) 普通索引,这个是最基本的索引, 其sql格式是 CREATE INDEX IndexName ON TableName(字段名(length)) 或者 ALTER TABLE TableName ADD INDEX IndexName(字段名(length)) 第一种方式 : 1CREATE INDEX account_Index ON `award`(`account`); 第二种方式: 1ALTER TABLE award ADD INDEX account_Index(`account`) 如果是CHAR,VARCHAR,类型,length可以小于字段的实际长度,如果是BLOB和TEXT类型就必须指定长度, 1-2) 唯一索引,与普通索引类似,但是不同的是唯一索引要求所有的类的值是唯一的,这一点和主键索引一样.但是他允许有空值, 其sql格式是 CREATE UNIQUE INDEX IndexName ON TableName(字段名(length)); 或者 ALTER TABLE TableName ADD UNIQUE (column_list) 1CREATE UNIQUE INDEX account_UNIQUE_Index ON `award`(`account`); 1-3) 主键索引,不允许有空值,(在B+TREE中的InnoDB引擎中,主键索引起到了至关重要的地位) 主键索引建立的规则是 int优于varchar,一般在建表的时候创建,最好是与表的其他字段不相关的列或者是业务不相关的列.一般会设为 int 而且是 AUTO_INCREMENT自增类型的， 2.组合索引 一个表中含有多个单列索引不代表是组合索引,通俗一点讲 组合索引是:包含多个字段但是只有索引名称 其sql格式是 CREATE INDEX IndexName On TableName(字段名(length),字段名(length),…); 1CREATE INDEX nickname_account_createdTime_Index ON `award`(`nickname`, `account`, `created_time`); 在使用查询的时候遵循mysql组合索引的”最左前缀”,下面我们来分析一下 什么是最左前缀：及索引where时的条件要按照建立索引的时候字段的排序方式，切不支持范围索引。 3、全文索引 文本字段上(text)如果建立的是普通索引,那么只有对文本的字段内容前面的字符进行索引,其字符大小根据索引建立索引时申明的大小来规定. 如果文本中出现多个一样的字符,而且需要查找的话,那么其条件只能是 where column like ‘%xxxx%’ 这样做会让索引失效 .这个时候全文索引就起到了作用了 1ALTER TABLE tablename ADD FULLTEXT(column1, column2) 有了全文索引，就可以用SELECT查询命令去检索那些包含着一个或多个给定单词的数据记录了。 12SELECT * FROM tablenameWHERE MATCH(column1, column2) AGAINST(‘xxx′, ‘sss′, ‘ddd′) 这条命令将把column1和column2字段里有xxx、sss和ddd的数据记录全部查询出来。 (二)索引的删除 删除索引的mysql格式 :DORP INDEX IndexName ON TableName (三)使用索引的优点 1.可以通过建立唯一索引或者主键索引,保证数据库表中每一行数据的唯一性.2.建立索引可以大大提高检索的数据,以及减少表的检索行数3.在表连接的连接条件 可以加速表与表直接的相连4.在分组和排序字句进行数据检索,可以减少查询时间中 分组 和 排序时所消耗的时间(数据库的记录会重新排序)5.建立索引,在查询中使用索引 可以提高性能 (四)使用索引的缺点 1.在创建索引和维护索引 会耗费时间,随着数据量的增加而增加2.索引文件会占用物理空间,除了数据表需要占用物理空间之外,每一个索引还会占用一定的物理空间3.当对表的数据进行 INSERT,UPDATE,DELETE 的时候,索引也要动态的维护,这样就会降低数据的维护速度,(建立索引会占用磁盘空间的索引文件。一般情况这个问题不太严重，但如果你在一个大表上创建了多种组合索引，索引文件的会膨胀很快)。]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人简历]]></title>
    <url>%2F2019%2F04%2F30%2F%E4%B8%AA%E4%BA%BA%E7%AE%80%E5%8E%86%2F</url>
    <content type="text"><![CDATA[这是一份个人简历。。 联系方式 | 期望职位：Java开发实习生 手机（微信号）：173-9651-0930 Email：cwellshake@gmail.com 个人信息 | 陈发荣 / 男 / 1998 教育背景：福州大学（211） 技术博客：http://cfr321.github.io Github：https://github.com/cfr321 证书技能：CTE4 / 自学C语言、数据结构和算法、计算机网络知识等计算机专业知识 技能清单 | 熟悉Java基础，了解常见设计模式 熟悉Servlet、JSP、JDBC等JavaWeb基础知识 熟悉IntelliJ IDEA、eclipse、vscode、Git、Maven等工具 熟悉MySQL关系型数据库，了解Redis 熟悉SringMVC、Spring、Mybatis框架技术；了解SpringBoot、SpringData 了解HTML+CSS+JS，以及BootStrap、Vue.js等前端知识 了解Linux常用命令，能够搭建开发环境 个人项目 | 员工管理系统 项目介绍：这是一个独立完成的员工管理系统，通过这个项目使我更加熟悉了SSM框架，以及学习BootStrap对页面的搭建，项目主要采用页面发送ajax到后端，实现对员工的信息的修改。整个项目业务并不复杂，但第一次做项目还是出现了很多问题，比如bootstrap的cs效果引入问题、MySQL8.0版本连接问题等等，我是完全自学的、遇到了问题我只能不断地去网上搜索，翻阅很多别人的博客，最终让问题得到解决。 CkServer服务器 一个类似tomcat的web服务器，这是在我学习Java网络编程时候做的一个小项目。它能接受HTTP请求以及响应，实现了war包的自动解压、xml的解析获取servlet、以及常见的状态码的响应。一开始它只支持IO流操作，一个请求一个线程；我又去学习了NIO的知识，并运用在这个小项目上。 cako商城 这是一个基于SpringBoot和SpringData的分布式项目，前端用的是vue.js，用nginx实现方向代理。目前并没有完全开发完全，现在在开发后台商品管理系统，从中我也在不断记取不断进步。 其他信息 | 校园经历：曾担任idea精英汇新闻官部长，负责微信公众号管理，有公众号管理和推文撰写经验 性格特点：专注度高，热爱学习，富有创造力 个人爱好：运动、游戏、读书和敲代码]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>分享</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池技术]]></title>
    <url>%2F2019%2F04%2F29%2F%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[线程学到了线程池技术了，可能多线程学习也要告一段落了，回顾，线程我们实现多线程的方式已经有了四种，Thread继承，Runnable接口实现，Callable接口实现，和最后的线程池。 一、Callable以前并没有聊过这个东东，先说一下这个Callable 1234567891011121314151617public class CallableDome implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; System.out.println("call== come in "); return 2; &#125; public static void main(String[] args) throws Exception &#123; FutureTask&lt;Integer&gt; futureTask=new FutureTask&lt;&gt;(new CallableDome()); new Thread(futureTask).start(); new Thread(futureTask).start(); System.out.println(futureTask.get()); &#125;&#125; /** output: * call== come in * 2 */ 对于上面这个代码有以下几点总结： Thread并没有为Callable提供构造方法，不能像Runnable一样直接传入，这时候就需要一个适配器 FutureTask，这个东西实现了Runnable接口，所以能被Thread接受，其次FutureTask 提供了传入 Callable接口的构造方法。- - —–FutureTask在这里就是适配器，这就是典型的适配器模式。 其实这里还有一个策略模式，对于任何类，只要实现了Runnable接口，它就能被Thread接受，这就是策略模式 比较Callable和Runnable，前者的运行方法是call,不再是run，而且有了返回值。 最终的打印结果只有一个 call== come in ，这里也是要注意的，已经得出结果的线程操作不会去在运行一次，当然你要再弄个FutureTask，是能再运行的。 二、线程池 一看类图关系：着重注意TreadPoolExecutor 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 1、线程池：ThreadPoolExecutor * Java中有五种实现： * newFixedThreadPool //一池规定线程数 * newCachedThreadPool //一池n线程数， * newSingleThreadExecutor //一池一线程 * newScheduledThreadPool //延迟加载的 * newWorkStealingPool //根据系统cup确定核心线程数的 * * 2、底层都是时去用ThreadPoolExecutor实现的： * ThreadPoolExecutord有七个属性： * ThreadPoolExecutor threadPool1=new ThreadPoolExecutor( * 5, //corepoolsize 核心线程数 * 8, //maxmumpoolsize 最大线程数 * 1L, //keepAliveTime 普通线程为被使用多久撤销 * TimeUnit.SECONDS, //TimeUnit时间单位 * new LinkedBlockingQueue&lt;Runnable&gt;(5), //阻塞队列的类型 * Executors.defaultThreadFactory(), //线程工厂，默认即可 * new ThreadPoolExecutor.DiscardOldestPolicy()); //拒绝策略，当全都满了怎么处理 * * 3、拒绝策略：有四种 * AbortPolicy //抛异常 * CallerRunsPolicy //给调用线程池的线程去处理 * DiscardOldestPolicy //丢弃等待最久的线程 * DiscardtPolicy //直接丢弃要进来的 * */public class MyThreadPoolDemo &#123; public static void main(String[] args)&#123; ExecutorService threadPool= Executors.newWorkStealingPool(); ThreadPoolExecutor threadPool1=new ThreadPoolExecutor(5,8,1L,TimeUnit.SECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(5), Executors.defaultThreadFactory(), new ThreadPoolExecutor.DiscardOldestPolicy()); try &#123; for (int i = 0; i &lt;14 ; i++) &#123; int finalI = i; threadPool.execute(()-&gt;&#123; System.out.println(Thread.currentThread().getName()+"\t "+ finalI); &#125;); &#125; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; threadPool.shutdown(); &#125; &#125;&#125; 二看具体属性关系 三看流程 三、总结线程池主要要了解的就是 Java中提供的几种实现，线程池构造的七种属性，它们的关系以及操作的流程。 注意：实际生产中我们其实基本不用Java自带的那几种配好的线程池，因为拒绝策略不好，或者阻塞列队直接Integer.MAX也是不合适，还有线程数的设计也可能不符合要求。往往需要我们自己去配置。 关于配置线程池的线程数： cup密集型：电脑cup数加一。 io密集型：一般可以是电脑cup的八到十倍。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池技术]]></title>
    <url>%2F2019%2F04%2F29%2F%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%E4%B9%8BTreeMap%2F</url>
    <content type="text"><![CDATA[源码解读之TreeMap首先我们要了解的 TreeMap底层是一个红黑树结构，搞搞懂TreeMap，TreeSet也就差不多了。 一、那什么是红黑树 首先它是一个二叉查找树，它有二叉查找树的所有特性，（但它不是一颗平衡二叉树，它并不是完全平衡的！） 额外的性质 性质1. 节点是红色或黑色。 性质2. 根节点是黑色。 性质3. 每个叶节点（NIL节点，空节点）是黑色的。 性质4. 每个红色节点的两个子节点都是黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点) 性质5. 从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。 不能同时有两个红色，以及每个节点到它能到的叶子节点的黑节点数相同 二、什么是左旋什么是右旋之前我看的是Java版数据结构和算法分析里面的红黑树介绍，emmmmm可能当时水平不够，看的很晕，现在回过头去看源码，发现左旋右旋也没那么复杂，左旋右旋就是单一的操作，只要合理的组合，就能实现二叉树的平衡。 右旋，讲parent放到左孩子的右边： 这个图片是右旋 很好理解： 就想着先断开，然后把parent结到 left的右边不不就行了 当然还有两个细节，就是left本来右边有东西的啊，所以要把left的右边连接到parent左边。啊？你问我为什么接到左边？因为parent左边本来是left，现在left跑上面去了，parent左边自然就空了。 最后就是把这个旋转好的树，接回整个大树，就是让left取代parent在整个树中的位置。 三、源码走起 继承关系 123public class TreeMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements NavigableMap&lt;K,V&gt;, Cloneable, java.io.Serializable 比较陌生的应该是NavigableMap，NavigableMap接口又继承于SortedMap，简单的来说这就是一个排序的Map，排序的就自然能提供找最大，找最小，按顺序迭代,这里就不仔细研究了。 推荐阅读：!(https://blog.csdn.net/u010126792/article/details/62236367) 节点结构 12345678static final class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; K key; V value; Entry&lt;K,V&gt; left; Entry&lt;K,V&gt; right; Entry&lt;K,V&gt; parent; boolean color = BLACK;&#125; 有左有右还有妈，分黑分白是一家 构造方法 构造方法有普通构造、还可以传入一个Map，底层就自动帮你转成TreeMap，还可以传入比较器，因为这是Sorted的map。 put方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051 public V put(K key, V value) &#123; Entry&lt;K,V&gt; t = root; if (t == null) &#123; compare(key, key); // type (and possibly null) check root = new Entry&lt;&gt;(key, value, null); size = 1; modCount++; return null; &#125; int cmp; Entry&lt;K,V&gt; parent; // 看看是有没有传入的比较器 Comparator&lt;? super K&gt; cpr = comparator; if (cpr != null) &#123; do &#123; parent = t; cmp = cpr.compare(key, t.key); if (cmp &lt; 0) t = t.left; else if (cmp &gt; 0) t = t.right; else return t.setValue(value); &#125; while (t != null); &#125; else &#123; if (key == null) throw new NullPointerException(); @SuppressWarnings("unchecked") Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; do &#123; parent = t; cmp = k.compareTo(t.key); if (cmp &lt; 0) t = t.left; else if (cmp &gt; 0) t = t.right; else return t.setValue(value); &#125; while (t != null); &#125; Entry&lt;K,V&gt; e = new Entry&lt;&gt;(key, value, parent); if (cmp &lt; 0) parent.left = e; else parent.right = e; fixAfterInsertion(e); //重点在这里，调节二叉树 size++; modCount++; return null;&#125; put方法其实很简单嘛，就是普通的二叉查找树的插入收端。 fixAfterInsertion(e); 关键方法，调节红黑树 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** From CLR */ private void fixAfterInsertion(Entry&lt;K,V&gt; x) &#123; x.color = RED; //parent已经是红色了才有必要调节 while (x != null &amp;&amp; x != root &amp;&amp; x.parent.color == RED) &#123; //一、parent是它自己parent的左孩子 // G // / \ // p y // / // x if (parentOf(x) == leftOf(parentOf(parentOf(x)))) &#123; Entry&lt;K,V&gt; y = rightOf(parentOf(parentOf(x))); //看看兄弟节点是否也为红，同为红则可以向上，合二红为一红 if (colorOf(y) == RED) &#123; setColor(parentOf(x), BLACK); setColor(y, BLACK); setColor(parentOf(parentOf(x)), RED); x = parentOf(parentOf(x)); //对G调整 &#125; else &#123; //看x是parent的左还是右孩子，来决定是要单旋还是双旋 if (x == rightOf(parentOf(x))) &#123; x = parentOf(x); rotateLeft(x); //旋转之后x又变成了最下面的， &#125; setColor(parentOf(x), BLACK); setColor(parentOf(parentOf(x)), RED); rotateRight(parentOf(parentOf(x))); &#125; &#125; //二、如果X的父节点（假设为:P）是其父节点的父节点（假设为:G）的右节点 // G // / \ // y P // \ // x // else &#123; Entry&lt;K,V&gt; y = leftOf(parentOf(parentOf(x))); //同样看看时候可以合二红为一红 if (colorOf(y) == RED) &#123; setColor(parentOf(x), BLACK); setColor(y, BLACK); setColor(parentOf(parentOf(x)), RED); x = parentOf(parentOf(x)); &#125; else &#123; //同样看看是要但旋转还是双旋转 if (x == leftOf(parentOf(x))) &#123; x = parentOf(x); rotateRight(x); &#125; setColor(parentOf(x), BLACK); setColor(parentOf(parentOf(x)), RED); rotateLeft(parentOf(parentOf(x))); &#125; &#125; &#125; root.color = BLACK; &#125; 最后来看看旋转操作，下面是左旋的，右旋类似 123456789101112131415161718/** From CLR */ private void rotateLeft(Entry&lt;K,V&gt; p) &#123; if (p != null) &#123; Entry&lt;K,V&gt; r = p.right; p.right = r.left; //不能忘了这一步，得让r的左边有人接手 if (r.left != null) r.left.parent = p; r.parent = p.parent; if (p.parent == null) //这几个判断就是讲r去带原来p的位置 root = r; else if (p.parent.left == p) p.parent.left = r; else p.parent.right = r; r.left = p; p.parent = r; &#125; &#125; 干脆把remove也读了 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * Delete node p, and then rebalance the tree. */ private void deleteEntry(Entry&lt;K,V&gt; p) &#123; modCount++; size--; //如果有左也有右，就到右孩子里面找最左的s节点放大p位置，然后去删掉s //这个就是查找树删除的策略 if (p.left != null &amp;&amp; p.right != null) &#123; Entry&lt;K,V&gt; s = successor(p); //右子树最小的一个 p.key = s.key; p.value = s.value; //将p节点的值更新为 s 的 p = s; //让后让p指向s，这个是将要删掉的 &#125; // p has 2 children //让replacement记录其中存在的孩子 //此时的p一定是最多只有一遍有孩子 Entry&lt;K,V&gt; replacement = (p.left != null ? p.left : p.right); //如果有一个孩子，则让孩子取代之 if (replacement != null) &#123; // 如果存在孩子，就让孩子与 p的parent连接删掉p replacement.parent = p.parent; //上连接 if (p.parent == null) root = replacement; else if (p == p.parent.left) p.parent.left = replacement; //下连接 else p.parent.right = replacement; // Null out links so they are OK to use by fixAfterDeletion. p.left = p.right = p.parent = null; // 调节红黑树，只有当删掉的是黑节点才需要调整 if (p.color == BLACK) fixAfterDeletion(replacement); &#125; else if (p.parent == null) &#123; // 自己就是根节点 root = null; &#125; else &#123; //没有孩子节点，就可以直接删掉了，不过依然要调节红黑树 if (p.color == BLACK) fixAfterDeletion(p); //删除p节点 if (p.parent != null) &#123; if (p == p.parent.left) p.parent.left = null; else if (p == p.parent.right) p.parent.right = null; p.parent = null; &#125; &#125; &#125; 删除操作的整体逻辑也不复杂，和二叉搜素树差不多，差异也是需要调节红黑树 123//判断调节与否的关键就是看p是不是黑节点if (p.color == BLACK) fixAfterDeletion(replacement); 当然接下来看看fixAfterDeletion函数了 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** From CLR */ private void fixAfterDeletion(Entry&lt;K,V&gt; x) &#123; //删除的是一个黑结点，会影响层数 while (x != root &amp;&amp; colorOf(x) == BLACK) &#123; if (x == leftOf(parentOf(x))) &#123; // p // / \ // 'x' sib Entry&lt;K,V&gt; sib = rightOf(parentOf(x)); //另一边是红的，把它变黑，然后p边红，旋转。 if (colorOf(sib) == RED) &#123; setColor(sib, BLACK); setColor(parentOf(x), RED); rotateLeft(parentOf(x)); sib = rightOf(parentOf(x)); &#125; //如果sib左右孩子都是黑的，直接让sib变红，左边黑数都减了，再去调节parentOf(x) if (colorOf(leftOf(sib)) == BLACK &amp;&amp; colorOf(rightOf(sib)) == BLACK) &#123; setColor(sib, RED); x = parentOf(x); &#125; else &#123; //好复杂。。。。。总的来说就是让parent变成黑色，加入左边 //这里是sib的右孩子已经是黑色了，左孩子是红色。 if (colorOf(rightOf(sib)) == BLACK) &#123; setColor(leftOf(sib), BLACK); setColor(sib, RED); rotateRight(sib); sib = rightOf(parentOf(x)); &#125; //将parent变黑，然后然sib与原来parent颜色相同，sib本来是黑色的， //但sib的右孩子或者左孩子左一定有一个不是黑色了，如果是右孩子为红，好说，让它变黑 //取代sib，右边的黑树数量就不会改变。 setColor(sib, colorOf(parentOf(x))); setColor(parentOf(x), BLACK); setColor(rightOf(sib), BLACK); rotateLeft(parentOf(x)); x = root; &#125; &#125; else &#123; // 后面相似，就是x是右孩子，然后就去与左孩子比较就好 Entry&lt;K,V&gt; sib = leftOf(parentOf(x)); 。。。。。。 &#125; &#125; setColor(x, BLACK); &#125; 一、如果P节点是黑色直接插入 二、如果P是红节点 P是G的左孩子还是右孩子： G的另外一个孩子是也是红：向上，把两红变一红，然后去调节G节点 G的另外一个孩子不是红色：那就要旋转了 如果三个 x, p ,G成一条直线，但旋转G,让G变红，P变黑]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中的阻塞队列]]></title>
    <url>%2F2019%2F04%2F28%2FJava%E4%B8%AD%E7%9A%84%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[阻塞列队也是Java高并发里面常用的工具类，今天学习了一下，总结 一下。 注意：该随笔内容完全引自http://wsmajunfeng.iteye.com/blog/1629354，写的很好，非常感谢，复制过来算是个积累，怕以后找不到。 一. 前言 在新增的Concurrent包中，BlockingQueue很好的解决了多线程中，如何高效安全“传输”数据的问题。通过这些高效并且线程安全的队列类，为我们快速搭建高质量的多线程程序带来极大的便利。本文详细介绍了BlockingQueue家庭中的所有成员，包括他们各自的功能以及常见使用场景。 二. 认识BlockingQueue 阻塞队列，顾名思义，首先它是一个队列，而一个队列在数据结构中所起的作用大致如下图所示： 从上图我们可以很清楚看到，通过一个共享的队列，可以使得数据由队列的一端输入，从另外一端输出； 常用的队列主要有以下两种：（当然通过不同的实现方式，还可以延伸出很多不同类型的队列，DelayQueue就是其中的一种） 先进先出（FIFO）：先插入的队列的元素也最先出队列，类似于排队的功能。从某种程度上来说这种队列也体现了一种公平性。 后进先出（LIFO）：后插入队列的元素最先出队列，这种队列优先处理最近发生的事件。 ​ 多线程环境中，通过队列可以很容易实现数据共享，比如经典的“生产者”和“消费者”模型中，通过队列可以很便利地实现两者之间的数据共享。假设我们有若干生产者线程，另外又有若干个消费者线程。如果生产者线程需要把准备好的数据共享给消费者线程，利用队列的方式来传递数据，就可以很方便地解决他们之间的数据共享问题。但如果生产者和消费者在某个时间段内，万一发生数据处理速度不匹配的情况呢？理想情况下，如果生产者产出数据的速度大于消费者消费的速度，并且当生产出来的数据累积到一定程度的时候，那么生产者必须暂停等待一下（阻塞生产者线程），以便等待消费者线程把累积的数据处理完毕，反之亦然。然而，在concurrent包发布以前，在多线程环境下，我们每个程序员都必须去自己控制这些细节，尤其还要兼顾效率和线程安全，而这会给我们的程序带来不小的复杂度。好在此时，强大的concurrent包横空出世了，而他也给我们带来了强大的BlockingQueue。（在多线程领域：所谓阻塞，在某些情况下会挂起线程（即阻塞），一旦条件满足，被挂起的线程又会自动被唤醒），下面两幅图演示了BlockingQueue的两个常见阻塞场景： 如上图所示：当队列中没有数据的情况下，消费者端的所有线程都会被自动阻塞（挂起），直到有数据放入队列。 如上图所示：当队列中填满数据的情况下，生产者端的所有线程都会被自动阻塞（挂起），直到队列中有空的位置，线程被自动唤醒。 这也是我们在多线程环境下，为什么需要BlockingQueue的原因。作为BlockingQueue的使用者，我们再也不需要关心什么时候需要阻塞线程，什么时候需要唤醒线程，因为这一切BlockingQueue都给你一手包办了。既然BlockingQueue如此神通广大，让我们一起来见识下它的常用方法： 三. BlockingQueue的核心方法： 1.放入数据 （1）offer(anObject):表示如果可能的话,将anObject加到BlockingQueue里,即如果BlockingQueue可以容纳,则返回true,否则返回false.（本方法不阻塞当前执行方法 的线程）； （2）offer(E o, long timeout, TimeUnit unit)：可以设定等待的时间，如果在指定的时间内，还不能往队列中加入BlockingQueue，则返回失败。 （3）put(anObject):把anObject加到BlockingQueue里,如果BlockQueue没有空间,则调用此方法的线程被阻断直到BlockingQueue里面有空间再继续. 2. 获取数据 （1）poll(time):取走BlockingQueue里排在首位的对象,若不能立即取出,则可以等time参数规定的时间,取不到时返回null; （2）poll(long timeout, TimeUnit unit)：从BlockingQueue取出一个队首的对象，如果在指定时间内，队列一旦有数据可取，则立即返回队列中的数据。否则知道时间 超时还没有数据可取，返回失败。 （3）take():取走BlockingQueue里排在首位的对象,若BlockingQueue为空,阻断进入等待状态直到BlockingQueue有新的数据被加入; （4）drainTo():一次性从BlockingQueue获取所有可用的数据对象（还可以指定获取数据的个数），通过该方法，可以提升获取数据效率；不需要多次分批加锁或释放锁。 四. 常见BlockingQueue 在了解了BlockingQueue的基本功能后，让我们来看看BlockingQueue家庭大致有哪些成员？ 1. ArrayBlockingQueue 基于数组的阻塞队列实现，在ArrayBlockingQueue内部，维护了一个定长数组，以便缓存队列中的数据对象，这是一个常用的阻塞队列，除了一个定长数组外，ArrayBlockingQueue内部还保存着两个整形变量，分别标识着队列的头部和尾部在数组中的位置。 ArrayBlockingQueue在生产者放入数据和消费者获取数据，都是共用同一个锁对象，由此也意味着两者无法真正并行运行，这点尤其不同于LinkedBlockingQueue；按照实现原理来分析，ArrayBlockingQueue完全可以采用分离锁，从而实现生产者和消费者操作的完全并行运行。Doug Lea之所以没这样去做，也许是因为ArrayBlockingQueue的数据写入和获取操作已经足够轻巧，以至于引入独立的锁机制，除了给代码带来额外的复杂性外，其在性能上完全占不到任何便宜。 ArrayBlockingQueue和LinkedBlockingQueue间还有一个明显的不同之处在于，前者在插入或删除元素时不会产生或销毁任何额外的对象实例，而后者则会生成一个额外的Node对象。这在长时间内需要高效并发地处理大批量数据的系统中，其对于GC的影响还是存在一定的区别。而在创建ArrayBlockingQueue时，我们还可以控制对象的内部锁是否采用公平锁，默认采用非公平锁。 2.LinkedBlockingQueue 基于链表的阻塞队列，同ArrayListBlockingQueue类似，其内部也维持着一个数据缓冲队列（该队列由一个链表构成），当生产者往队列中放入一个数据时，队列会从生产者手中获取数据，并缓存在队列内部，而生产者立即返回；只有当队列缓冲区达到最大值缓存容量时（LinkedBlockingQueue可以通过构造函数指定该值），才会阻塞生产者队列，直到消费者从队列中消费掉一份数据，生产者线程会被唤醒，反之对于消费者这端的处理也基于同样的原理。而LinkedBlockingQueue之所以能够高效的处理并发数据，还因为其对于生产者端和消费者端分别采用了独立的锁来控制数据同步，这也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。 作为开发者，我们需要注意的是，如果构造一个LinkedBlockingQueue对象，而没有指定其容量大小，LinkedBlockingQueue会默认一个类似无限大小的容量（Integer.MAX_VALUE），这样的话，如果生产者的速度一旦大于消费者的速度，也许还没有等到队列满阻塞产生，系统内存就有可能已被消耗殆尽了。 ArrayBlockingQueue和LinkedBlockingQueue是两个最普通也是最常用的阻塞队列，一般情况下，在处理多线程间的生产者消费者问题，使用这两个类足以。 下面的代码演示了如何使用BlockingQueue： 3. DelayQueue DelayQueue中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素。DelayQueue是一个没有大小限制的队列，因此往队列中插入数据的操作（生产者）永远不会被阻塞，而只有获取数据的操作（消费者）才会被阻塞。 使用场景： DelayQueue使用场景较少，但都相当巧妙，常见的例子比如使用一个DelayQueue来管理一个超时未响应的连接队列。 4. PriorityBlockingQueue 基于优先级的阻塞队列（优先级的判断通过构造函数传入的Compator对象来决定），但需要注意的是PriorityBlockingQueue并不会阻塞数据生产者，而只会在没有可消费的数据时，阻塞数据的消费者。因此使用的时候要特别注意，生产者生产数据的速度绝对不能快于消费者消费数据的速度，否则时间一长，会最终耗尽所有的可用堆内存空间。在实现PriorityBlockingQueue时，内部控制线程同步的锁采用的是公平锁。 5. SynchronousQueue 一种无缓冲的等待队列，类似于无中介的直接交易，有点像原始社会中的生产者和消费者，生产者拿着产品去集市销售给产品的最终消费者，而消费者必须亲自去集市找到所要商品的直接生产者，如果一方没有找到合适的目标，那么对不起，大家都在集市等待。相对于有缓冲的BlockingQueue来说，少了一个中间经销商的环节（缓冲区），如果有经销商，生产者直接把产品批发给经销商，而无需在意经销商最终会将这些产品卖给那些消费者，由于经销商可以库存一部分商品，因此相对于直接交易模式，总体来说采用中间经销商的模式会吞吐量高一些（可以批量买卖）；但另一方面，又因为经销商的引入，使得产品从生产者到消费者中间增加了额外的交易环节，单个产品的及时响应性能可能会降低。 声明一个SynchronousQueue有两种不同的方式，它们之间有着不太一样的行为。公平模式和非公平模式的区别: 如果采用公平模式：SynchronousQueue会采用公平锁，并配合一个FIFO队列来阻塞多余的生产者和消费者，从而体系整体的公平策略； 但如果是非公平模式（SynchronousQueue默认）：SynchronousQueue采用非公平锁，同时配合一个LIFO队列来管理多余的生产者和消费者，而后一种模式，如果生产者和消费者的处理速度有差距，则很容易出现饥渴的情况，即可能有某些生产者或者是消费者的数据永远都得不到处理。 五. 小结 BlockingQueue不光实现了一个完整队列所具有的基本功能，同时在多线程环境下，他还自动管理了多线间的自动等待于唤醒功能，从而使得程序员可以忽略这些细节，关注更高级的功能 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566//生产者消费者模式 3.0 class MyResouce&#123; private volatile boolean flag=true; private AtomicInteger atomicInteger=new AtomicInteger(); BlockingQueue&lt;String&gt; blockingDeque=null; public MyResouce(BlockingQueue&lt;String&gt; blockingDeque) &#123; this.blockingDeque = blockingDeque; System.out.println(blockingDeque.getClass().getName()); &#125; public void myProd() throws Exception&#123; String Date=null; boolean reValue; while(flag)&#123; Date=atomicInteger.incrementAndGet()+""; reValue=blockingDeque.offer(Date,2L, TimeUnit.SECONDS); if(reValue)&#123; System.out.println("生产成功"+Date); &#125;else&#123; System.out.println("生产失败"); &#125; TimeUnit.SECONDS.sleep(1); &#125; if(!flag)&#123; System.out.println("停止生产"); &#125; &#125; public void myComsu() throws Exception&#123; String result=null; while (flag)&#123; result=blockingDeque.poll(2L,TimeUnit.SECONDS); if(result==null || result.equalsIgnoreCase(""))&#123; System.out.println("没有取到"); &#125;else&#123; System.out.println("去到蛋糕"+result); &#125; &#125; &#125; public void stop()&#123; flag=false; &#125;&#125;public class ProdConsumer_BlockQueue &#123; public static void main(String[] args)&#123; MyResouce myResouce=new MyResouce(new ArrayBlockingQueue&lt;String&gt;(3)); new Thread(() -&gt; &#123; System.out.println("开始生产"); try &#123; myResouce.myProd(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, "pro").start(); new Thread(() -&gt; &#123; System.out.println("开始消费"); try &#123; myResouce.myComsu(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, "comsu").start(); try &#123; TimeUnit.SECONDS.sleep(5);&#125;catch (InterruptedException e) &#123; e.printStackTrace();&#125; myResouce.stop(); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[锁]]></title>
    <url>%2F2019%2F04%2F27%2F%E9%94%81%2F</url>
    <content type="text"><![CDATA[学习三部曲：理论+实践+总结 一、公平锁和非公平锁公平锁符合先到先得，有先来后到之分；非公平锁就没有，都是同时竞争锁，而且趋于短作业优先。 ReentrantLock默认就是非公平锁，非公平锁有着更好的吞吐率。 1Lock lock=new ReentrantLock(true); //设置为公平锁 synchronized，也是非公平锁 二、可重入锁（递归锁）ReentrantLock 和 Synchronized都是个可重入锁： 重入锁：同一个线程外层获取锁后，这个线程可以进入任何这把锁的方法。 12345678910111213//case1:证明了synchronized是可重入锁private synchronized void method1()&#123; System.out.println("方法一被调用了"); method2();&#125;private synchronized void method2() &#123; System.out.println("方法二被调用了");&#125;public static void main(String[] args)&#123; Doma01 doma01=new Doma01(); doma01.method1();&#125; 1234567891011121314151617181920212223242526272829//case2：证明了ReentrantLock是可重入锁public class Dome2 &#123; static Lock lock=new ReentrantLock(); private static void method1()&#123; lock.lock(); try &#123; System.out.println(Thread.currentThread().getName()+"\t invoked method1"); method2(); &#125;finally &#123; lock.unlock(); &#125; &#125; private static void method2() &#123; lock.lock(); try &#123; System.out.println(Thread.currentThread().getName()+"\t invoked method2"); &#125;finally &#123; lock.unlock(); &#125; &#125; public static void main(String[] args)&#123; new Thread(() -&gt; &#123; method1(); &#125;, "t1").start(); new Thread(() -&gt; &#123; method1(); &#125;, "t2").start(); &#125;&#125; 上面的代码都能正常运行，线程可以访问到其他的同样锁的方法，可重入锁的目的是防止了死锁。自锁。 注意，ReenteankLock，加锁和解锁的次数一定要匹配，调用了几次lock（），就需要几unlock()，才能释放锁，其他线程才能获得到锁。 少了unlock()，会出现锁未释放，程序阻塞。而多了unlock（）程序是会报错的。 java.lang.IllegalMonitorStateException 三、自旋锁自旋：多次来看看时候能获得锁，看了不能获得就去干自己的，然后一段时间后又来看看时候能获得锁。 手写自旋锁： 123456789101112131415161718public class MySpinLock &#123; //设置Thread的原子对象，对其修改具有原子性 AtomicReference&lt;Thread&gt; atomicReference=new AtomicReference&lt;&gt;(); public void myLock()&#123; Thread thread=Thread.currentThread(); System.out.println(thread.getName()+"\t come in"); //自旋的去看atomicReference是否为空了，为空就将自己设置进去。 while(!atomicReference.compareAndSet(null,thread))&#123; &#125; &#125; //释放锁的方法 public void myUnlock()&#123; Thread thread=Thread.currentThread(); atomicReference.compareAndSet(thread,null); System.out.println(thread.getName()+"\t come out"); &#125;&#125; 自旋锁问题：当一个线程长时间占用资源，其他线程将会不断的去尝试获取锁，那么就会消耗cup性能。 四、独占锁（写锁）/共享锁（读锁）/ 读写锁多线程操作资源，有时又需要读的时候可以共同访问，但是写的时候其他线程不能访问子资源。 写操作：原子性+独占，整个过程必须是个完整的过程，不能又其他线程插入其中。 ReentrankReadWriteLock就是典型的读写锁 12345678910111213141516171819202122232425262728293031//利用ReentrankReadWriteLock实现 写时上锁，读读共享class Mychace&#123; private volatile Map&lt;String,Object&gt; map=new HashMap&lt;&gt;(); private ReentrantReadWriteLock lock=new ReentrantReadWriteLock(false); public void put(String k,Object o)&#123; lock.writeLock().lock(); try &#123; System.out.println(Thread.currentThread().getName()+"\t 开始写入"); map.put(k,o); System.out.println(Thread.currentThread().getName()+"\t 写入完成"); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.writeLock().unlock(); &#125; &#125; public void get(String k)&#123; lock.readLock().lock(); try &#123; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.readLock().unlock(); &#125; System.out.println(Thread.currentThread().getName()+"\t 开始读取"); Object o=map.get(k); System.out.println(Thread.currentThread().getName()+"\t 读取完成"+o); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAS-实现原子性]]></title>
    <url>%2F2019%2F04%2F26%2FCAS-%E5%AE%9E%E7%8E%B0%E5%8E%9F%E5%AD%90%E6%80%A7%2F</url>
    <content type="text"><![CDATA[前面学习过volatile，它实现了内存的可见性，但是不保证原子性。于是我们引用了AtomicInteger类实现了非原子操作的线程安全，回过头来想，AtomicInteger类是如果实现 ++ 的原子性的呢。 一、compareAndSet123456789101112131415161718//比较符合预期就更新public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update); &#125;//加一public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1; &#125;//再点进去 unsafe.getAndAddIntpublic final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; &#125; 我们最后发现两个方法最后都有调用 unsafe.compareAndSwapInt (this, valueOffset, expect, update); 那这是是个什么方法呢，unsafe类的这个方法是一个native的本地方法，它是底层的c类语言的对cup直接操作的原语。何为原语，它是一段不能被打断插入的对底层操作。 百度百科：原语 操作系统或计算机网络用语范畴。是由若干条指令组成的，用于完成一定功能的一个过程。primitive or atomic action 是由若干个机器指令构成的完成某种特定功能的一段程序，具有不可分割性·即原语的执行必须是连续的，在执行过程中不允许被中断。 OK我们要知道的就是它不能被分割了的，不会被别的操作再去干扰的机器命令。 那么在看看它传入的参数： this ：表示当前需要修改的对象 valueOffset：对象的内存地址，底层可以通过这个地址获得 this 对象的值。 expect：我们对this对象所期望的值 update：符合期望我们要将它更新的值 2、那么到这里我们的compareAndSet compareAndSet(expect, update)方法就借助底层的compareAndSwapInt (this, valueOffset, expect, update)，实现了是否可以跟新。 3、getAndAddInt（）又是如何借助compareAndSwapInt 实现安全自增呢。我们的++操作是一个必须要成功的操作，不能想compareAndSet一样更新不成功就不更新了。 再来读读getAndAddInt(Object var1, long var2, int var4)源码， var1=&gt;this，var2=&gt;地址，var4=&gt;需要增加的值，var5=&gt;就是自己线程工作内存里面的值 1234567public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); //读取主内存值到工作内存 &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));//跟新不成功，自旋操作,重新读取var5，然后再进行compareAndSwapInt，注意这个方法是原语操作不会被打断，也就是这个操作过程中主内存里面的值是不会被修改的，这个var1也就是当前主内存里面的值。 return var5; &#125; 我们模拟两个线程并发的执行这个操作： 1、A线程读取主内存值得到自己的 Avar5=3，然后被挂起了 2、B线程读取主内存值得到自己的 Bvar5=3，然后进行了加一写入主内存。 3、A线程唤起，进行compareAndSwapInt，但是读取的var1是4，和期望的var5=3不相等，那么不跟新进入下一次循环。 4、再次读取var5=4，执行compareAndSwapInt，对比没问题，更新操作，写入主内存。 二、CAS的问题1、ABA问题：那上面的来讲，要是B线程加完之后又减了，主内存中的值就还是3，那么A线程的跟新操作也会一次就成功。这就是ABA问题。有一种狸猫换太子的感觉 ​ 解决：加上一个版本号，每次操作都让版本号加一，比较更新时除了比较值意外还要比较版本号。AtomicStampedRefrence，就实现了这样的功能， 2、自旋的性能消耗问题 3、无法解决多个变量的原子操作，前面的方法也体现了，这个时只能对一个变量进行比较跟新，多个变量操纵就需要加锁了。 ​]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[volatile轻量级锁-同步机制]]></title>
    <url>%2F2019%2F04%2F25%2Fvolatile%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%9A%84%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[不写点东西他还啥都没有 1、Volatile:轻量级的同步机制 保证可见性 不保证原子性(不保证JMM需要的原子性，所以轻量) 禁止指令重拍 2、JMM(Java内存模型)：是一种抽象概念，并不正式存在， 是一种规范。可见性、原子性、有序性 变量存在主内存、线程变量需要拷贝到自己的工作内存，操作完成后再写入主内存。 线程A读取主内存值，线程B也读取主内存。 3、从内存模型里去分析volatile的各种属性 可见性 此时A线程修改x,并写入主内，此时要求其他线程知道这个x被改变。这部分其实在Java多线程学习中就有学习过，只不过没有从JMM层次这么深刻的去认识。 123456789101112131415161718192021222324252627class MyDate&#123; volatile int number=0; public void addTo60()&#123; this.number=60; &#125;&#125;//1、验证volatile可见性 public class Test1 &#123; public static void main(String[] args)&#123; MyDate date=new MyDate(); //第一个线程AAA， new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName()+"\t come in"); try &#123; TimeUnit.SECONDS.sleep(3);&#125;catch (InterruptedException e) &#123; e.printStackTrace();&#125; date.addTo60(); System.out.println(); &#125;, "AAA").start(); while(date.number==0)&#123; &#125; //1、如果number没有加volatile.这里无法发生，main线程无法读取到AAA线程修改的值，无法读取主内存中改变的值 //2、如果加了volatile，就可以去读取到主内存改变的值 System.out.println("main线程结束"); &#125;&#125; 不保证原子性，JMM要求保证原子性，但是volatile不保证原子性。为什么volatile不能保证原子性呢。比如两个线程同时要对主内存中的i 进行 ++操作。++并不是原子操作，三步，读取i的值，将i加1，赋值给i。最后写入主内存。现在两个线程都完成了i++的操作了，然后写入操作是同步的，那么其中一个被挂起，写入之后主内存里面的值改变，这时候根据volatile的内存语义，其他线程应该通知得到这个值，但是被挂起的线程已经完成了i++的操作，所以这个可见来的有点晚，线程并不会再去对新的这个值去++操作，而是在很快的时间内就把自己加好的值写入主内存，这时候就会造成++操作的丢失。 12345678910111213141516171819202122232425//不保证原子性操作public class Test2 &#123; public static void main(String[] args)&#123; MyDate date=new MyDate(); for(int i=0;i&lt;100;i++)&#123; new Thread(() -&gt; &#123; for(int j=0;j&lt;1000;j++)&#123; date.addSum(); date.sumByAtomic(); &#125; &#125;, "i").start(); &#125; while(Thread.activeCount()&gt;2)&#123; Thread.yield(); &#125; System.out.println("mian中： number="+date.number); //number2是原子类型的 AtomicInteger System.out.println("main中： number2="+date.number2); &#125;&#125;/**mian中： number=98729main中： number2=100000 *///解决这个问题其实只要用上原子类 volatile重排规则，这是比较复杂的一个内容，涉及到JMM中happend-before，在代码编译运行过程中会对我们的代码进些一些重新排序，我们的基本要求是希望这些重新排序不要影响程序的运行结果。 volatile变量对于重拍有了这些内存语义： 对于任何volatile写，其前面的操作都不能重拍到它的后面 对于任何volatile读，其后面的操作都不能重拍到它的前面 先volatile写 再volatile读，也不能重新排序。 volatile要先读了，操作后面，操作好了，再写。如果硬是要先写再读也不能重排序]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap--浅析]]></title>
    <url>%2F2019%2F04%2F23%2FConcurrentHashMap-%E6%B5%85%E6%9E%90%2F</url>
    <content type="text"><![CDATA[ConcurrentHashMap简单小总结 最近一直在看《Java并发编程艺术》一书，书本内容还是相当的丰富，先从并发的底层实现、内存层次剖析了并发的实现，再到各种锁的底层实现原理，然后降到了Java中并发容器和框架。 前面的内容一直没时间整理，主要前面的知识底层读起来还是有难度的，一遍看过来感触不是很深。 今天学习了并发容器里面的ConcurrentHashMap和ConcurrentLinkedQueue，这里主要是写一些ConcurrentHashMap的理解。 Map家族是Java容器里非常重要的一部分，比如HashMap，Hashtable，ConcurrentHashMap。这三个中国HashMap线程不安全，后两者线程安全，但是Hashtable采用的是一种相当重量的锁，在对它进行操作的时候它会把整个表锁起来，是一种悲观锁。 而今天要讲的ConcurrentHashMap则时采用了一种更为巧妙地方式实现了线程安全。 不锁全表，锁局部。 不锁所有操作，只锁有线程安全的操作。 对用量的计算（size)，采用一种乐观锁的机制。 我阅读书本后书本总ConcurrentHashMap的结构大致是这样子的：ConcurrentHashMap的内部结构图： 从上面的结构我们可以了解到，ConcurrentHashMap定位一个元素的过程需要进行两次Hash操作。 锁的思路是put才锁上局部的HashEntry，这些HashEntry都是volatile的，volatile是concurrent包一个非常重要的锁的机制，当然它底层关键的点还是CAS算法。这本书前面讲原理讲锁主要就是讲这些东西。 看完书后我打开电脑翻阅了一下concurrentHashMap的源码，发现似乎和书上的有所差异，我的是jdk1.8，后来看了网上发现书本上应该讲的是1.7及以前的版本。 1.8的ConcurrentHashMap的结构其实我觉得和HashMap结构非常相似： 123456789/** * The array of bins. Lazily initialized upon first insertion. * Size is always a power of two. Accessed directly by iterators. */ transient volatile Node&lt;K,V&gt;[] table;/** * The next table to use; non-null only while resizing. */ private transient volatile Node&lt;K,V&gt;[] nextTable; 但是不一样的是变量前都加了volatile。 卧槽源码越读越卧槽，大概看了下get 和 put 还有扩容， get方法比较简单，和HashMap的思路差不多，先找到table对应的位置，再到链表中找对应的key，无需加锁。 123456789101112131415161718192021222324public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; //计算hash值 int h = spread(key.hashCode()); //根据hash值确定节点位置 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; //如果搜索到的节点key与传入的key相同且不为null,直接返回这个节点 if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; //如果eh&lt;0 说明这个节点在树上 直接寻找 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; //否则遍历链表 找到对应的值并返回 while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null; &#125; put复杂一些:我们看到它锁的是节点， 先计算hash，找到对应位置，当然还有一系列的判断、table是否为空、判断时候需要扩容、判断时候需要调整链表为数、插入的时候还要判断key时候存在过了、其实都和HashMap相似。关键在于它将这个节点锁主其他线程不能访问，当然它的子节点也不能被访问到了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public V put(K key, V value) &#123; return putVal(key, value, false); &#125; /** Implementation for put and putIfAbsent */ final V putVal(K key, V value, boolean onlyIfAbsent) &#123; //不允许 key或value为null if (key == null || value == null) throw new NullPointerException(); //计算hash值 int hash = spread(key.hashCode()); int binCount = 0; //死循环 何时插入成功 何时跳出 for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; //如果table为空的话，初始化table if (tab == null || (n = tab.length) == 0) tab = initTable(); //根据hash值计算出在table里面的位置 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; //如果这个位置没有值 ，直接放进去，不需要加锁 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; //当遇到表连接点时，需要进行整合表的操作 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; V oldVal = null; //结点上锁 这里的结点可以理解为hash值相同组成的链表的头结点 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; //fh〉0 说明这个节点是一个链表的节点 不是树的节点 if (fh &gt;= 0) &#123; binCount = 1; //在这里遍历链表所有的结点 for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; //如果hash值和key值相同 则修改对应结点的value值 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; //如果遍历到了最后一个结点，那么就证明新的节点需要插入 就把它插入在链表尾部 if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; //如果这个节点是树节点，就按照树的方式插入值 else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; //如果链表长度已经达到临界值8 就需要把链表转换为树结构 if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; //将当前ConcurrentHashMap的元素数量+1 addCount(1L, binCount); return null; &#125; 还有就是关于size和扩容的操作，扩容是要复制表的，这个过程要考虑到线程的安全性问题，当然可以简单的单线程一步一步复制，但它是支持了多线程复制的。源码瞄了一两眼实在难看。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring重点归纳]]></title>
    <url>%2F2019%2F04%2F22%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[佛了 计算机网络知识一、TCP/IP物理层：主要解决对接的标准，网络信号的传输，信道的多效利用 数据链路层：1、打包成贞、透明传输、可靠传输、差错检验。。。。。给资源加上MAC地址 网络层一、IP协议IP协议是TCP/IP协议的核心，所有的TCP，UDP，IMCP，IGMP的数据都以IP数据格式传输。要注意的是，IP不是可靠的协议，这是说，IP协议没有提供一种数据未传达以后的处理机制，这被认为是上层协议：TCP或UDP要做的事情。每个计算机都有为一的IP地址 TTL字段。这个字段规定该数据包在穿过多少个路由之后才会被抛弃。某个IP数据包每穿过一个路由器，该数据包的TTL数值就会减少1，当该数据包的TTL成为零，它就会被自动抛弃。 这个字段的最大值也就是255，也就是说一个协议包也就在路由器里面穿行255次就会被抛弃了，根据系统的不同，这个数字也不一样，一般是32或者是64。 二、ARP协议（地址解析协议）这个协议是为IP协议服务的： 做三件事：先查开目的的IP地址在自己的ARP高速缓存（就是一个IP-MAC地址对应表缓存）。 ​ 没有的话就会在自己的局域网中发广播获取目标IP的MAC地址 ​ 没有的话，就会发给网关路由器，等到MAC地址。 描述RARP协议答:RARP是逆地址解析协议，作用是完成硬件地址到IP地址的映射，主要用于无盘工作站，因为给无盘工作站配置的IP地址不能保存。工作流程：在网络中配置一台RARP服务器，里面保存着IP地址和MAC地址的映射关系，当无盘工作站启动后，就封装一个RARP数据包，里面有其MAC地址，然后广播到网络上去，当服务器收到请求包后，就查找对应的MAC地址的IP地址装入响应报文中发回给请求者。因为需要广播请求报文，因此RARP只能用于具有广播能力的网络。 三、ICMP协议（网络控制报文协议）IP协议并不是一个可靠的协议，它不保证数据被送达，那么，自然的，保证数据送达的工作应该由其他的模块来完成。其中一个重要的模块就是ICMP(网络控制报文)协议。ICMP不是高层协议，而是IP层的协议。 当传送IP数据包发生错误。比如主机不可达，路由不可达等等，ICMP协议将会把错误信息封包，然后传送回给主机。给主机一个处理错误的机会，这 也就是为什么说建立在IP层以上的协议是可能做到安全的原因。 ​ 网络层两个应用： pingping可以说是ICMP的最著名的应用，是TCP/IP协议的一部分。利用“ping”命令可以检查网络是否连通，可以很好地帮助我们分析和判定网络故障。 ping这个单词源自声纳定位，而这个程序的作用也确实如此，它利用ICMP协议包来侦测另一个主机是否可达。原理是用类型码为0的ICMP发请 求，受到请求的主机则用类型码为8的ICMP回应。 ping程序来计算间隔时间，并计算有多少个包被送达。用户就可以判断网络大致的情况。我们可以看到， ping给出来了传送的时间和TTL的数据。 TracerouteTraceroute是用来侦测主机到目的主机之间所经路由情况的重要工具，也是最便利的工具。 Traceroute的原理是非常非常的有意思，它收到到目的主机的IP后，首先给目的主机发送一个TTL=1的UDP数据包，而经过的第一个路由器收到这个数据包以后，就自动把TTL减1，而TTL变为0以后，路由器就把这个包给抛弃了，并同时产生 一个主机不可达的ICMP数据报给主机。主机收到这个数据报以后再发一个TTL=2的UDP数据报给目的主机，然后刺激第二个路由器给主机发ICMP数据 报。如此往复直到到达目的主机。这样，traceroute就拿到了所有的路由器IP。 传输层TCP/UDP一个面向连接、可靠传输、面向字节流、能流量控制和阻塞控制，全双工。 TCP对应的协议：（1） FTP：定义了文件传输协议，使用21端口。（2） Telnet：一种用于远程登陆的端口，使用23端口，用户可以以自己的身份远程连接到计算机上，可提供基于DOS模式下的通信服务。（3） SMTP：邮件传送协议，用于发送邮件。服务器开放的是25号端口。（4） POP3：它是和SMTP对应，POP3用于接收邮件。POP3协议所用的是110端口。（5）HTTP：是从Web服务器传输超文本到本地浏览器的传送协议。 一个不连接、不可靠、面向报文、不能流量控制和阻塞控制，一对一、一对多、多对多、多对一，速度快。 UDP对应的协议：（1） DNS：用于域名解析服务，将域名地址转换为IP地址。DNS用的是53号端口。（2） SNMP：简单网络管理协议，使用161号端口，是用来管理网络设备的。由于网络设备很多，无连接的服务就体现出其优势。（3） TFTP(Trival File Transfer Protocal)，简单文件传输协议，该协议在熟知端口69上使用UDP服务。 TCP三次握手第一次握手： 建立连接。客户端发送连接请求报文段，将SYN位置为1，Sequence Number为x；然后，客户端进入SYN_SEND状态，等待服务器的确认； 第二次握手： 服务器收到SYN报文段。服务器收到客户端的SYN报文段，需要对这个SYN报文段进行确认，设置Acknowledgment Number为x+1(Sequence Number+1)；同时，自己自己还要发送SYN请求信息，将SYN位置为1，Sequence Number为y；服务器端将上述所有信息放到一个报文段（即SYN+ACK报文段）中，一并发送给客户端，此时服务器进入SYN_RECV状态； 第三次握手： 客户端收到服务器的SYN+ACK报文段。然后将Acknowledgment Number设置为y+1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。 为什么要三次握手？ 主要是第三次握手的存在，避免了服务端等待确认的资源浪费， 为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。 具体例子：“已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。” 四次分手第一次分手： 主机1（可以使客户端，也可以是服务器端），设置Sequence Number，向主机2发送一个FIN报文段；此时，主机1进入FIN_WAIT_1状态；这表示主机1没有数据要发送给主机2了； 第二次分手： 主机2收到了主机1发送的FIN报文段，向主机1回一个ACK报文段，Acknowledgment Number为Sequence Number加1；主机1进入FIN_WAIT_2状态；主机2告诉主机1，我“同意”你的关闭请求； 第三次分手： 主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入LAST_ACK状态； 第四次分手： 主机1收到主机2发送的FIN报文段，向主机2发送ACK报文段，然后主机1进入TIME_WAIT状态；主机2收到主机1的ACK报文段以后，就关闭连接；此时，主机1等待2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，主机1也可以关闭连接了。 为什么要四次分手？ TCP协议是一种面向连接的、可靠的、基于字节流的运输层通信协议。TCP是全双工模式，这就意味着，当主机1发出FIN报文段时，只是表示主机1已经没有数据要发送了，主机1告诉主机2，它的数据已经全部发送完毕了；但是，这个时候主机1还是可以接受来自主机2的数据；当主机2返回ACK报文段时，表示它已经知道主机1没有数据发送了，但是主机2还是可以发送数据到主机1的；当主机2也发送了FIN报文段时，这个时候就表示主机2也没有数据要发送了，就会告诉主机1，我也没有数据要发送了，之后彼此就会愉快的中断这次TCP连接。 为什么要等待2MSL？ MSL：报文段最大生存时间，它是任何报文段被丢弃前在网络内的最长时间。 原因有二： 保证TCP协议的全双工连接能够可靠关闭 保证这次连接的重复数据段从网络中消失 第一点：如果主机1直接CLOSED了，那么由于IP协议的不可靠性或者是其它网络原因，导致主机2没有收到主机1最后回复的ACK。那么主机2就会在超时之后继续发送FIN，此时由于主机1已经CLOSED了，就找不到与重发的FIN对应的连接。所以，主机1不是直接进入CLOSED，而是要保持TIME_WAIT，当再次收到FIN的时候，能够保证对方收到ACK，最后正确的关闭连接。 第二点：如果主机1直接CLOSED，然后又再向主机2发起一个新连接，我们不能保证这个新连接与刚关闭的连接的端口号是不同的。也就是说有可能新连接和老连接的端口号是相同的。一般来说不会发生什么问题，但是还是有特殊情况出现：假设新连接和已经关闭的老连接端口号是一样的，如果前一次连接的某些数据仍然滞留在网络中，这些延迟数据在建立新连接之后才到达主机2，由于新连接和老连接的端口号是一样的，TCP协议就认为那个延迟的数据是属于新连接的，这样就和真正的新连接的数据包发生混淆了。所以TCP连接还要在TIME_WAIT状态等待2倍MSL，这样可以保证本次连接的所有数据都从网络中消失。 TCP流量控制主要是借助 rwnd,接受端通过不断地响应rwnd的大小给接受端来实现流量的控制 发送窗口时不会大于接受窗口的。 TCP拥塞控制拥塞控制是有一个 cwnd, 拥塞窗口，这是发送端发送数据的窗口， 发送模拟：1、慢开始：发送的第一个数据只有一个包，cwnd的大小为1，如果能够顺利响应 ​ 2、继续满开始的节奏，成指数增长窗口的大小。 ​ 3、然后增长会到达一个慢增长限制 12345为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个慢开始门限ssthresh状态变量。慢开始门限ssthresh的用法如下： 当 cwnd &lt; ssthresh 时，使用上述的慢开始算法。 当 cwnd &gt; ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。 当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞控制避免算法。 ​ 4、接着只会进行，cwnd一个一个的增长 ​ 5、知道增大到某一个值，发生了阻塞，丢包了， ​ 就会向调整 ssthresh等于 档期cwnd大小的一半，然后cwnd的大小回到1，重新慢增长。 快重传 问题：（因为报文是每隔多少 响应一次的，比如M5才会响应，M3丢了，那么要等到M5，传好了之后才响应M3丢了） 快重传算法首先要求接收方每收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时才进行捎带确认。 接收方收到了M1和M2后都分别发出了确认。现在假定接收方没有收到M3但接着收到了M4。 显然，接收方不能确认M4，因为M4是收到的失序报文段。根据 可靠传输原理，接收方可以什么都不做，也可以在适当时机发送一次对M2的确认。 但按照快重传算法的规定，接收方应及时发送对M2的重复确认，这样做可以让 发送方及早知道报文段M3没有到达接收方。发送方接着发送了M5和M6。接收方收到这两个报文后，也还要再次发出对M2的重复确认。这样，发送方共收到了 接收方的四个对M2的确认，其中后三个都是重复确认。 快重传算法还规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段M3，而不必 继续等待M3设置的重传计时器到期。 由于发送方尽早重传未被确认的报文段，因此采用快重传后可以使整个网络吞吐量提高约20%。 快恢复 问题：报文的丢失，可能不是网络拥塞的问题，那么当三个重复确认连续收到，说明网络没有阻塞，没有必要再从1满开始。所以有了快恢复。 与快重传配合使用的还有快恢复算法，其过程有以下两个要点： 当发送方连续收到三个重复确认，就执行“乘法减小”算法，把慢开始门限ssthresh减半。 与慢开始不同之处是现在不执行慢开始算法（即拥塞窗口cwnd现在不设置为1），而是把cwnd值设置为 慢开始门限ssthresh减半后的数值，然后开始执行拥塞避免算法（“加法增大”），使拥塞窗口缓慢地线性增大。]]></content>
      <categories>
        <category>计算机基础</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式简单的思考]]></title>
    <url>%2F2019%2F04%2F20%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%AE%80%E5%8D%95%E7%9A%84%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[这几天学习的几种设计模式，其实学习的和肤浅，我平时做的东西也很少达到要用设计模式的地步，只是对他们有个初步的认识。 面向对象设计原则1.开闭原则 - Open Close Principle（OCP） 一个软件实体如类、模块和函数应该对扩展开放，对修改关闭 功能的扩展应该是定义新的类，而不是对原有的类进行修改 2.单一职责原则 - Single Responsibility Principle（SRP） 不要存在多于一个导致类变更的原因 3.里士替换原则 - Liskov Substitution Principle（LSP） 定义一：所有引用基类的地方必须能透明地使用其子类的对象。 定义二：如果对每一个类型为 T1的对象 o1，都有类型为 T2 的对象o2，使得以 T1定义的所有程序 P 在所有的对象 o1 都代换成 o2 时，程序 P 的行为没有发生变化，那么类型 T2 是类型 T1 的子类型。 4.依赖倒置原则 - Dependence Inversion Principle（DIP） 高层模块不应该依赖低层模块，二者都应该依赖其抽象；抽象不应该依赖细节，细节应该依赖抽象。 5.接口隔离原则 - Interface Segration Principle（ISP） 定义一：客户端不应该依赖它不需要的接口 定义二：类间的依赖关系应该建立在最小的接口上 6.迪米特法则/最少知道原则 - Law of Demeter or Least Knowledge Principle（LoD or LKP） 一个对象应该对其他对象保持最少的了解 这个原理的名称来源于希腊神话中的农业女神，孤独的得墨忒耳。 一、创建者模型单例模式：一个类只有一个对象： 数据库连接池，windows的任务管理器，配置文件加载器，spring的bean也是单例,springmvc，网站技术器都是单例 单例模式优点：只有一个实例减少系统的开销， 实现：饿汉模式，懒汉模式，静态内部类和局部静态块，枚举单例，双重检验锁， CountDownLatch,等待其他线程执行完自己才结束，可以和join一样。就像一个技术器，一个线程执行完毕就让它减一，可以去调用CountDownLatch.await让主线程等待。 工厂模式： 简单工厂模式 简单工厂对功能的拓展是需要对类修改的，那么就违背了acp（开闭原则）。 工厂方法模式 工厂方法模式满足了acp,但是造成了很多类增加了代码的复杂度，在生产的实际中反而简单工厂使用的更多 抽象工厂模式 建造者模式需要构建很多的零件一个复杂的类，我们需要构造（Builder）很多零件，还需要组装成（Director)一个复杂的对象。 通常建造者模式是和工厂模式搭配使用的。 定义一个类，这个类需要有其他几个类组成 定义一构建者接口，定义创建组件的方法。定义一个组装者接口，返回那个复杂的类 实现构建者接口重写构建零件方法，通常这里可以和工厂模式结合，用简单工厂模式来实现各个零件的构建 实现组装者接口，组装者需要传入一个构建者，调用构建者构建零件的方法获得零件，由零件set来组成复杂类 代理模式静态代理 代理类包含被代理的类，其他行为代理类完成，关键步骤调用真实类完成 代理对象需要我们自己取定义，相对繁琐不灵活。 动态代理 动态的去生成我们的代理类， 生成这个代理类需要一个，handler 1234567891011121314151617public class StarHandler implements InvocationHandler &#123; Star star; public StarHandler(Star star) &#123; this.star = star; &#125; //重写invoke方法，以后动态生成的代理的对象都会来执行这个方法。method.incoke是又返回对象的。 @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; method.invoke(star, args); return null; &#125;&#125;//而动态生成代理的方法其实是反射的过程，需要类加载器，被代理类的Class信息，并且有一个处理器 Star proxy= (Star) Proxy.newProxyInstance(ClassLoader.getSystemClassLoader(), new Class[]&#123;Star.class&#125;,handler); 桥接模式类与类之间的继承关系比较多，比如有一个电脑接口，下面有台式、笔记本、平板，下面又有联想、戴尔、神州。 这样不应该设置成联想台式、联想笔记本，这样不符合类的单一指责原则。 这个时候应该用桥接模式：定义品牌接口和样式接口， 桥接模式是典型的多对多的类的交互问题。 装饰模式装饰模式是一个对功能扩展常用的模式。 比如我现在有一个car类，下面可能有飞的car，智能car，水上漂的car，然后他们直接又可以组合，既可以飞又智能，这样如果没个不同类型的功能都定义一个子类，会让子类迅速膨胀。 那么需要装饰模式，装饰模式有一个关键点就是装饰者，装饰者持有最基本的cart这个对象，然后然一些单一功能的继承这个装饰者，去分别实现它们单一增加的功能。如果要组合的时候只要将一个功能的car传给另一个功能的car进行组合，就能实现功能的组合扩展。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455//定义顶级接口public interface Icar &#123; void move();&#125;//实现类，实现最基本的功能class Car implements Icar&#123; @Override public void move() &#123; System.out.println("路上跑"); &#125;&#125;//装饰者，持有基本类的实现class SuCar implements Icar&#123; Icar car; public SuCar(Icar car) &#123; super(); this.car = car; &#125; @Override public void move() &#123; car.move(); &#125;&#125;//具体实现功能扩展的装饰好的class WortCar extends SuCar&#123; public WortCar(Icar car) &#123; super(car); &#125; //功能扩展 public void extend() &#123; System.out.println("水上漂"); &#125; @Override public void move() &#123; super.move(); extend(); &#125;&#125;class FlyCar extends SuCar&#123; public FlyCar(Icar car) &#123; super(car); &#125; //功能扩展 public void extend() &#123; System.out.println("天上飞"); &#125; @Override public void move() &#123; super.move(); extend(); &#125;&#125; 我们的io就是装饰模式的一种，装饰模式和桥接模式看上去很相似，都是去避免定义过多的类。 但实际它们解决的问题是不一样的，桥接是桥接类与类直接的组合关系，在多继承的情况下解决类组合复杂的问题。 而装饰模式是不能功能的扩展导致过多的定义类，是对新功能的扩展性问题。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring重点归纳]]></title>
    <url>%2F2019%2F04%2F18%2Fspring%E9%87%8D%E7%82%B9%E5%BD%92%E7%BA%B3%2F</url>
    <content type="text"><![CDATA[为什么会乱啊 iocioc：控制反转 比如有一个类，在类里面有方法（不是静态的方法），调用类里面的方法，创建类的对象，使用对象调用方法，创建类对象的过程，需要new出来对象 把对象的创建不是通过new方式实现，而是交给spring配置创建类对象 ioc底层原理使用技术 （1）xml配置文件：在xml中配置类信息，类名和类路径。 （2）dom4j解析xml：解析xml获取类信息 （3）工厂设计模式 和反射：这两个应该是结合的，工厂模式的设计理念，工厂制造bean的机制是反射。 Bean标签常用属性 id属性：定义的名称，id属性值名称任意命名 id属性值，不能包含特殊符号 根据id值得到配置对象 class属性：创建对象所在类的全路径 name属性：功能和id属性一样的，id属性值不能包含特殊符号，但是在name属性值里面可以包含特殊符号老版本为兼容struts1的name属性，现在基本只是用id属性 scope属性 singleton：默认值，单例（重点） prototype：多例（用在配置action）（重点） 1&lt;bean id="user" class="me.test.ioc.User" scope="singleton"&gt;&lt;/bean&gt; DL依赖注入： 依赖：一个类需要用到另一个类，而往往我们需要去new另外一个类，这样就增加了耦合。就需要注入 注入：通过setter方法进行另一个对象实例设置。 例如：l 例如： ​ class BookServiceImpl{ ​ //之前开发：接口 = 实现类 （service和dao耦合） ​ //private BookDao bookDao = new BookDaoImpl(); //spring之后 （解耦：service实现类使用dao接口，不知道具体的实现类） ​ private BookDao bookDao; ​ setter（BookDao bookDao) 方法，传入一个bookDao实现注入。 } ​ 模拟spring执行过程 ​ 创建service实例：BookService bookService = new BookServiceImpl() –&gt;IoC ​ 创建dao实例：BookDao bookDao = new BookDaoImple() –&gt;IoC ​ 将dao设置给service：bookService.setBookDao(bookDao); –&gt;DI 12345678910111213141516171819&lt;!-- 模拟spring执行过程 创建service实例：BookService bookService = new BookServiceImpl() IoC &lt;bean&gt; 创建dao实例：BookDao bookDao = new BookDaoImpl() IoC 将dao设置给service：bookService.setBookDao(bookDao); DI &lt;property&gt; &lt;property&gt; 用于进行属性注入 name： bean的属性名，通过setter方法获得 setBookDao ##&gt; BookDao ##&gt; bookDao ref ：另一个bean的id值的引用 --&gt;&lt;!-- 创建service --&gt;&lt;bean id="bookServiceId" class="com.itheima.b_di.BookServiceImpl"&gt; &lt;property name="bookDao" ref="bookDaoId"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 创建dao实例 --&gt;&lt;bean id="bookDaoId" class="com.itheima.b_di.BookDaoImpl"&gt;&lt;/bean&gt; 属性的注入我们都知道，一个类的私有属性其他人想去对其定义，通常有两种方法 一种是在构造这个类的对象的时候就传入相关的属性信息 还有一种是通过setter方法来传入属性 比如一个类: 1234567891011121314class Persen&#123; private String name; private int age; public Persen (String name,int age)&#123; this.age=age; this.name=name &#125; public void setName(String name)&#123; this.name=name; &#125; public void setAge(int age)&#123; this.age=age; &#125;&#125; 这个类提供了公共的构造方法和 set方法，这都是可以对对象属性的进行定义的，那么如果这个类的实例化交给了sping容器来完成，它是怎么实现这两种属性的注入的呢。 构造方法 12345678910111213141516171819&lt;!-- 构造方法注入 * &lt;constructor-arg&gt; 用于配置构造方法一个参数argument name ：参数的名称 value：设置普通数据 ref：引用数据，一般是另一个bean id值 index ：参数的索引号，从0开始 。如果只有索引，匹配到了多个构造方法时，默认使用第一个。 type ：确定参数类型 例如：使用名称name &lt;constructor-arg name="username" value="jack"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name="age" value="18"&gt;&lt;/constructor-arg&gt; 例如2：【类型type 和 索引 index】 &lt;constructor-arg index="0" type="java.lang.String" value="1"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg index="1" type="java.lang.Integer" value="2"&gt;&lt;/constructor-arg&gt;--&gt;&lt;bean id="userId" class="com.itheima.f_xml.a_constructor.User" &gt; &lt;constructor-arg index="0" type="java.lang.String" value="1"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg index="1" type="java.lang.Integer" value="2"&gt;&lt;/constructor-arg&gt;&lt;/bean&gt; set方法：类的注入也是用set方法 123456789101112131415161718192021222324252627282930313233&lt;!-- setter方法注入 * 普通数据 &lt;property name="" value="值"&gt; 等效 &lt;property name=""&gt; &lt;value&gt;值 * 引用数据 &lt;property name="" ref="另一个bean"&gt; 等效 &lt;property name=""&gt; &lt;ref bean="另一个bean"/&gt; --&gt; &lt;bean id="personId" class="com.itheima.f_xml.b_setter.Person"&gt; &lt;property name="pname" value="阳志"&gt;&lt;/property&gt; &lt;property name="age"&gt; &lt;value&gt;1234&lt;/value&gt; &lt;/property&gt; &lt;property name="homeAddr" ref="homeAddrId"&gt;&lt;/property&gt; &lt;property name="companyAddr"&gt; &lt;ref bean="companyAddrId"/&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id="homeAddrId" class="com.itheima.f_xml.b_setter.Address"&gt; &lt;property name="addr" value="阜南"&gt;&lt;/property&gt; &lt;property name="tel" value="911"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id="companyAddrId" class="com.itheima.f_xml.b_setter.Address"&gt; &lt;property name="addr" value="北京八宝山"&gt;&lt;/property&gt; &lt;property name="tel" value="120"&gt;&lt;/property&gt; &lt;/bean&gt; 当然还可以注入一些复杂的数据，比如集合，链表等等，它们的注入就是在标签下面再加上对应的结构标签。 name：注入属性的名字 ref：注入的类id value：注入普通的值 IOC和Dl区别 IOC：控制反转，把对象创建交给spring进行配置 DI：依赖注入，向类里面的属性中设置值 关系：依赖注入不能单独存在，需要在IOC基础之上完成操作 其实这个区别的化还是没什么好说的，更重要的是明白这两个东西，我觉得不是一个类型的。 AOP原理AOP术语 Joinpoint(连接点): 类里面可以被增强的方法，这些方法称为连接点 Pointcut(切入点):所谓切入点是指我们要对哪些Joinpoint进行拦截的定义 Advice(通知/增强):所谓通知是指拦截到Joinpoint之后所要做的事情就是通知.通知分为前置通知,后置通知,异常通知,最终通知,环绕通知(切面要完成的功能) Aspect(切面): 是切入点和通知（引介）的结合 Introduction(引介):引介是一种特殊的通知在不修改类代码的前提下, Introduction可以在运行期为类动态地添加一些方法或Field Target(目标对象):代理的目标对象(要增强的类) Weaving(织入):是把增强应用到目标的过程把advice 应用到 target的过程 Proxy（代理）:一个类被AOP织入增强后，就产生一个结果代理类 AOP中文名就是切面编程，前面编程有三个关键点 一个是我们要被切的基本业务类，也就是目标对象 一个是通知增强的类，就是要对我们的目标类进行前后异常操作的。 还有一个就是把它们结合其他的形成的切面了，一个类被AOP增强之后就会形成一个它的代理类，这个代理类不仅仅有目标类的方法，还有增强类的方法，并且能让增强类方法在合适的位置出现。 spring是用cglib字节码操作，结合代理模式和工厂模式和反射实现。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//目标类public class MyService implements Service&#123; public void service()&#123; System.out.println("服务业务被调用"); &#125;&#125;//切入类public class MyAspect &#123; public void before()&#123; System.out.println("前方法"); &#125; public void after()&#123; System.out.println("后方法"); &#125;&#125;//结合类public class MyBeanFactory &#123; public static MyService createService()&#123; final MyAspect aspect=new MyAspect(); final MyService service=new MyService(); Enhancer enhancer = new Enhancer(); //确定父类 enhancer.setSuperclass(MyService.class); /* 设置回调函数 , MethodInterceptor接口 等效 jdk InvocationHandler接口 * intercept() 等效 jdk实现代理模式的 invoke() * 参数1、参数2、参数3：以invoke一样 * 参数4：methodProxy 方法的代理 */ enhancer.setCallback((MethodInterceptor) (o, method, objects, methodProxy) -&gt; &#123; aspect.before(); //两种调用业务的方法1、2. //1、执行目标类的方法 Object objet=method.invoke(service,objects); //2、执行代理类的父类 ，执行目标类 （目标类和代理类 父子关系） methodProxy.invokeSuper(o,objects); aspect.after(); return objet; &#125;); //创建代理 MyService proxService = (MyService) enhancer.create(); return proxService; &#125;&#125; 这种代理模式也可以用JDK自带的反射包的proxy和invokhandler实现 12345678910111213141516public class MyBeanFactorybyjdk &#123; public static Service createService() &#123; MyAspect aspect = new MyAspect(); Service service = new MyService(); Service serviceProxy = (Service) Proxy.newProxyInstance( service.getClass().getClassLoader(), service.getClass().getInterfaces(), (InvocationHandler) (proxy, method, args) -&gt; &#123; aspect.before(); Object object=method.invoke(service,args); aspect.after(); return object; &#125;); return serviceProxy; &#125;&#125; spring通过配置实现AOP这个工厂肯定不是我们手写的，因为spring天生就是来创建bean的，实现AOP我们只要编写好我们的目标类和切入类，讲它们放入spring容器，然后将他们相切，怎么切呢 12345678910111213141516171819202122232425262728293031323334353637&lt;!-- 3 aop编程 3.1 导入命名空间 3.2 使用 &lt;aop:config&gt;进行配置 proxy-target-class="true" 声明时使用cglib代理 &lt;aop:pointcut&gt; 切入点 ，从目标对象获得具体方法 &lt;aop:advisor&gt; 特殊的切面，只有一个通知 和 一个切入点 advice-ref 通知引用 pointcut-ref 切入点引用 3.3 切入点表达式（重要） execution(* com.itheima.c_spring_aop.*.*(..)) 选择方法 返回值任意 包 类名任意 方法名任意 参数任意 --&gt; &lt;!-- 1 创建目标类 --&gt; &lt;bean id="userServiceId" class="路径"&gt;&lt;/bean&gt; &lt;!-- 2 创建切面类（通知） --&gt; &lt;bean id="myAspectId" class="路径"&gt;&lt;/bean&gt;&lt;aop:config&gt;方法1： &lt;aop:pointcut expression="切入点表达式" id=""&gt; &lt;aop:advisor advice-ref="通知引用" pointcut-ref="切入点的引用"&gt;方法2： &lt;aop:advisor advice-ref="通知引用" pointcut="切入点表达式"&gt;&lt;/aop:config&gt; &lt;!--AspectJ xml--&gt;&lt;aop:config&gt; &lt;aop:aspect ref="切面类"&gt; &lt;aop:pointcut expression="切入点表达式" id=""&gt; &lt;aop:before&gt; 前置 &lt;aop:afterReturning returning="第二个参数名称"&gt; 后置 &lt;aop:around&gt; 环绕 &lt;aop:afterThrowing throwing="第二。。。"&gt; 抛出异常 &lt;aop:after&gt; 最终 AspectJ 是AOP实现的一个框架，整合到了spring中，前面aop:advisor 特殊的切面，只有一个通知 和 一个切入点，那么如果我有多个需要切入的点或者说我要在这个切入点的不能位置进行操作，那么就需要AspectJ，如上面配置，它实现了五个位置对切入点的操作。 明天继续复习事务———— 明天到来了 spring事务1.1 回顾事务l 事务：一组业务操作ABCD，要么全部成功，要么全部不成功。 l 特性：ACID ​ 原子性：整体 ​ 一致性：完成 ​ 隔离性：并发 ​ 持久性：结果 l 隔离问题： ​ 脏读：一个事务读到另一个事务没有提交的数据 ​ 不可重复读：一个事务读到另一个事务已提交的数据（update） ​ 虚读(幻读)：一个事务读到另一个事务已提交的数据（insert） l 隔离级别： ​ read uncommitted：读未提交。存在3个问题 ​ read committed：读已提交。解决脏读，存在2个问题 ​ repeatable read：可重复读。解决：脏读、不可重复读，存在1个问题。 ​ serializable ：串行化。都解决，单事务。 l PlatformTransactionManager 平台事务管理器，spring要管理事务，必须使用事务管理器 ​ 进行事务配置时，必须配置事务管理器。 l TransactionDefinition：事务详情（事务定义、事务属性），spring用于确定事务具体详情， ​ 例如：隔离级别、是否只读、超时时间 等 ​ 进行事务配置时，必须配置详情。spring将配置项封装到该对象实例。 l TransactionStatus：事务状态，spring用于记录当前事务运行状态。例如：是否有保存点，事务是否完成。 ​ spring底层根据状态进行相应操作。 AOP是事务的基础]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis学习心得]]></title>
    <url>%2F2019%2F04%2F17%2FLinux%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[简单罗列一些Linux和jvm性能分析的工具和命令、 Linux性能分析命令 top(整机）：（uptime)：查开整机性能，cup和load average（平局超过0.6）就比较高了 vmstat -n 2 3（cpu) : 看procs: 轮转进程数 cpu ：us+sy mpstat pidstat。 free（内存）: free m free g（后面是单位，兆还是g） df（硬盘）: iostat（磁盘io) ： ifstat（网络io）： pidstat：查看具体进程号对应信息： pidstat -r -p 13084 1 pidstat命令指定采样周期和采样次数，命令形式为”pidstat [option] interval [count]”，以下pidstat输出以2秒为采样周期，输出10次cpu使用统计信息： cpu使用情况统计(-u) 内存使用情况统计(-r) IO情况统计(-d) JVM性能分析工具 jps （虚拟机进程）like ps jstat （统计信息监视）like pidstat，可以查看进程的某种信息，比如-gc -gcold jinfo（配置信息） jmap (堆内存，dump heap，查看进程堆信息) jstack（堆栈跟踪工具） jhat （堆转储快照分析） CUP占用过高： ​ 分析流程: top==&gt;找到哪个程序，记录pid ​ 用 jps -l 或者 ps -ef | grep -v grep 得到进程 id ​ ps -mp 进程id -o THREAD，tid,time 得到线程 id （-m 显示所有线程，-p进程号，-o 用户自定义格式） ​ 线程id变成16 进制 或者用 ”printf “%x\n” ​ jstack 进程号 | grep (16进制线程号) -A60]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis学习心得]]></title>
    <url>%2F2019%2F04%2F17%2Fredis%E5%AD%A6%E4%B9%A0%E5%BF%83%E5%BE%97%2F</url>
    <content type="text"><![CDATA[学习redis已经有几天了，主要都是断断续续的，这几天看Java高级知识也花了很多时间，今天来给redis的一些知识点做一下总结回顾。 redis是什么介绍Redis之前，先了解下NoSQL （Not noly SQL）不仅仅是SQL 属于非关系型数据库；Redis就属于非关系型数据库 传统的Mysql ,oracle ,sql server 等 都是关系型数据库 redis是基于内存的，单线程操作的，多路IO(NIO)复用的，key value型缓存数据库。 为什么要学redis为什么需要NoSQL，主要应对以下问题，传统关系型数据库力不从心 High performance -高并发读写 Huge Storage-海量数据的高效率存储和访问 High Scalablility &amp;&amp; High Availability 高可扩展性和高可用性 redis主要的数据类型1.STRING redis的STRING十分神奇，它不单指字符串，还可以代表数值型数据，可以进行字符串以及数值的各种处理 2.LIST redis的列表，列表的每一个节点都包含了一个字符串 LIST可以从表头和表尾push和put数据，也可以根据偏移量对链表进行修剪（trim）；读取单个/多个元素，查询或者删除元素 3.SET 包含字符串的无序收集器，并且包含的每一个字符串都是唯一的 操作就是基本的增删改查，计算交集，并集以及差集，并且可以随机获取元素 4.ZSET 有序集合 字符串成员（member）与浮点数分值（sorce）之间的有序映射，元素排列顺序由分值决定 操作就是基本的增，查，删单个元素，获取分值范围内的或者成员来获取元素 5.HASH 包换键值对的无序列表 增，删，查单个键值对，获取所有键值对 redis一些高级特性【聊聊redis持久化 – 两种方式】 redis提供了两种持久化的方式，分别是RDB（Redis DataBase）和AOF（Append Only File）。 RDB，简而言之，就是在不同的时间点，将redis存储的数据生成快照并存储到磁盘等介质上； AOF，则是换了一个角度来实现持久化，那就是将redis执行过的所有写指令记录下来，在下次redis重新启动时，只要把这些写指令从前到后再重复执行一遍，就可以实现数据恢复了。 其实RDB和AOF两种方式也可以同时使用，在这种情况下，如果redis重启的话，则会优先采用AOF方式来进行数据恢复，这是因为AOF方式的数据恢复完整度更高。 如果你没有数据持久化的需求，也完全可以关闭RDB和AOF方式，这样的话，redis将变成一个纯内存数据库，就像memcache一样。 【聊聊redis持久化 – RDB】 RDB方式，是将redis某一时刻的数据持久化到磁盘中，是一种快照式的持久化方法。 redis在进行数据持久化的过程中，会先将数据写入到一个临时文件中，待持久化过程都结束了，才会用这个临时文件替换上次持久化好的文件。正是这种特性，让我们可以随时来进行备份，因为快照文件总是完整可用的。 对于RDB方式，redis会单独创建（fork）一个子进程来进行持久化，而主进程是不会进行任何IO操作的，这样就确保了redis极高的性能。 如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。 虽然RDB有不少优点，但它的缺点也是不容忽视的。如果你对数据的完整性非常敏感，那么RDB方式就不太适合你，因为即使你每5分钟都持久化一次，当redis故障时，仍然会有近5分钟的数据丢失。所以，redis还提供了另一种持久化方式，那就是AOF。 【聊聊redis持久化 – AOF】 AOF，英文是Append Only File，即只允许追加不允许改写的文件。 如前面介绍的，AOF方式是将执行过的写指令记录下来，在数据恢复时按照从前到后的顺序再将指令都执行一遍，就这么简单。 我们通过配置redis.conf中的appendonly yes就可以打开AOF功能。如果有写操作（如SET等），redis就会被追加到AOF文件的末尾。 默认的AOF持久化策略是每秒钟fsync一次（fsync是指把缓存中的写指令记录到磁盘中），因为在这种情况下，redis仍然可以保持很好的处理性能，即使redis故障，也只会丢失最近1秒钟的数据。 如果在追加日志时，恰好遇到磁盘空间满、inode满或断电等情况导致日志写入不完整，也没有关系，redis提供了redis-check-aof工具，可以用来进行日志修复。 因为采用了追加方式，如果不做任何处理的话，AOF文件会变得越来越大，为此，redis提供了AOF文件重写（rewrite）机制，即当AOF文件的大小超过所设定的阈值时，redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。举个例子或许更形象，假如我们调用了100次INCR指令，在AOF文件中就要存储100条指令，但这明显是很低效的，完全可以把这100条指令合并成一条SET指令，这就是重写机制的原理。 在进行AOF重写时，仍然是采用先写临时文件，全部完成后再替换的流程，所以断电、磁盘满等问题都不会影响AOF文件的可用性，这点大家可以放心。 AOF方式的另一个好处，我们通过一个“场景再现”来说明。某同学在操作redis时，不小心执行了FLUSHALL，导致redis内存中的数据全部被清空了，这是很悲剧的事情。不过这也不是世界末日，只要redis配置了AOF持久化方式，且AOF文件还没有被重写（rewrite），我们就可以用最快的速度暂停redis并编辑AOF文件，将最后一行的FLUSHALL命令删除，然后重启redis，就可以恢复redis的所有数据到FLUSHALL之前的状态了。是不是很神奇，这就是AOF持久化方式的好处之一。但是如果AOF文件已经被重写了，那就无法通过这种方法来恢复数据了。 虽然优点多多，但AOF方式也同样存在缺陷，比如在同样数据规模的情况下，AOF文件要比RDB文件的体积大。而且，AOF方式的恢复速度也要慢于RDB方式。 如果你直接执行BGREWRITEAOF命令，那么redis会生成一个全新的AOF文件，其中便包括了可以恢复现有数据的最少的命令集。 如果运气比较差，AOF文件出现了被写坏的情况，也不必过分担忧，redis并不会贸然加载这个有问题的AOF文件，而是报错退出。这时可以通过以下步骤来修复出错的文件： 1.备份被写坏的AOF文件 2.运行redis-check-aof –fix进行修复 3.用diff -u来看下两个文件的差异，确认问题点 4.重启redis，加载修复后的AOF文件 【聊聊redis持久化 – AOF重写】 AOF重写的内部运行原理，我们有必要了解一下。 在重写即将开始之际，redis会创建（fork）一个“重写子进程”，这个子进程会首先读取现有的AOF文件，并将其包含的指令进行分析压缩并写入到一个临时文件中。 与此同时，主工作进程会将新接收到的写指令一边累积到内存缓冲区中，一边继续写入到原有的AOF文件中，这样做是保证原有的AOF文件的可用性，避免在重写过程中出现意外。 当“重写子进程”完成重写工作后，它会给父进程发一个信号，父进程收到信号后就会将内存中缓存的写指令追加到新AOF文件中。 当追加结束后，redis就会用新AOF文件来代替旧AOF文件，之后再有新的写指令，就都会追加到新的AOF文件中了。 【聊聊redis持久化 – 如何选择RDB和AOF】 对于我们应该选择RDB还是AOF，官方的建议是两个同时使用。这样可以提供更可靠的持久化方案。 【聊聊主从 – 用法】 像MySQL一样，redis是支持主从同步的，而且也支持一主多从以及多级从结构。 主从结构，一是为了纯粹的冗余备份，二是为了提升读性能，比如很消耗性能的SORT就可以由从服务器来承担。 redis的主从同步是异步进行的，这意味着主从同步不会影响主逻辑，也不会降低redis的处理性能。 主从架构中，可以考虑关闭主服务器的数据持久化功能，只让从服务器进行持久化，这样可以提高主服务器的处理性能。 在主从架构中，从服务器通常被设置为只读模式，这样可以避免从服务器的数据被误修改。但是从服务器仍然可以接受CONFIG等指令，所以还是不应该将从服务器直接暴露到不安全的网络环境中。如果必须如此，那可以考虑给重要指令进行重命名，来避免命令被外人误执行。 【聊聊主从 – 同步原理】 从服务器会向主服务器发出SYNC指令，当主服务器接到此命令后，就会调用BGSAVE指令来创建一个子进程专门进行数据持久化工作，也就是将主服务器的数据写入RDB文件中。在数据持久化期间，主服务器将执行的写指令都缓存在内存中。 在BGSAVE指令执行完成后，主服务器会将持久化好的RDB文件发送给从服务器，从服务器接到此文件后会将其存储到磁盘上，然后再将其读取到内存中。这个动作完成后，主服务器会将这段时间缓存的写指令再以redis协议的格式发送给从服务器。 另外，要说的一点是，即使有多个从服务器同时发来SYNC指令，主服务器也只会执行一次BGSAVE，然后把持久化好的RDB文件发给多个下游。在redis2.8版本之前，如果从服务器与主服务器因某些原因断开连接的话，都会进行一次主从之间的全量的数据同步；而在2.8版本之后，redis支持了效率更高的增量同步策略，这大大降低了连接断开的恢复成本。 主服务器会在内存中维护一个缓冲区，缓冲区中存储着将要发给从服务器的内容。从服务器在与主服务器出现网络瞬断之后，从服务器会尝试再次与主服务器连接，一旦连接成功，从服务器就会把“希望同步的主服务器ID”和“希望请求的数据的偏移位置（replication offset）”发送出去。主服务器接收到这样的同步请求后，首先会验证主服务器ID是否和自己的ID匹配，其次会检查“请求的偏移位置”是否存在于自己的缓冲区中，如果两者都满足的话，主服务器就会向从服务器发送增量内容。 增量同步功能，需要服务器端支持全新的PSYNC指令。这个指令，只有在redis-2.8之后才具有。 【聊聊redis的事务处理】 众所周知，事务是指“一个完整的动作，要么全部执行，要么什么也没有做”。 在聊redis事务处理之前，要先和大家介绍四个redis指令，即MULTI、EXEC、DISCARD、WATCH。这四个指令构成了redis事务处理的基础。 1.MULTI用来组装一个事务； 2.EXEC用来执行一个事务； 3.DISCARD用来取消一个事务； 4.WATCH用来监视一些key，一旦这些key在事务执行之前被改变，则取消事务的执行。 redis没有实际的事务的感念，这里的事务也不想关系型数据库里的事务那样。当在组装的时候某个语句组装没出错，比如取一个空key，那么在执行的时候也只有这一句是不行的。但在exec执行前就报出来语法错误则整个事务失败。 redis面试题Redis与Memcached的区别与比较1 、Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。memcache支持简单的数据类型，String。 2 、Redis支持数据的备份，即master-slave模式的数据备份。 3 、Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而Memecache把数据全部存在内存之中 4、 redis的速度比memcached快很多 5、Memcached是多线程，非阻塞IO复用的网络模型；Redis使用单线程的IO复用模型。 MySQL里有2000w数据，Redis中只存20w的数据，如何保证Redis中的数据都是热点数据（redis有哪些数据淘汰策略？？？）相关知识：redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略（回收策略）。redis 提供 6种数据淘汰策略： volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-enviction（驱逐）：禁止驱逐数据 lru算法是一种用hashmap和链表实现的算法，没使用一次就将数据放在链表的最后，要回收的时候就回收前面的。 Redis常见性能问题和解决方案:1、Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件2、如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次3、为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内4、尽量避免在压力很大的主库上增加从库]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java多线程（二）]]></title>
    <url>%2F2019%2F04%2F16%2FJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[继续Java多线程的学习，这一部分主要是书本上的Lock章节和Java多线程实现单例模式，以及最后一章补充知识的简单总结，后续我还会读Java并发编程艺术。好好学习Java的高级知识。 Java多线程（二）一、Lock在Java中实现线程的同步出了之前的synchronized同步锁的使用，在JDK1.5新增了ReentrantLock可以实现同样的效果，而且使用起来更加的灵活，新增了嗅探锁定和多路分支通知等功能。这个IPA属于Java的concurrent包。 学习之后我的感受是，这把锁像是在房间外我们给它加上的一把锁，什么时候锁上，什么时候不锁了都由我们说了算，而synchromized更像是线程自己把自己锁在了房间里，在里面做操作，只有当线程完了任务自己要出来了，才会把锁释放出去。 ReentrantLock 使用ReentrantLock实现线程的同步 1、定义Lock:private static Lock lock=new ReentrantLock(); 2、上锁：lock.lock(); 3、执行完了要释放锁：lock.unlock(); 这样就实现了线程的同步。ReentrantLock对象就像一个管理者，为线程上锁，为线程开锁。 12345678910111213141516171819202122232425public class ReentrantLock1 &#123; private static Lock lock=new ReentrantLock(); private static void menthdA()&#123; lock.lock(); for(int i=0;i&lt;10;i++)&#123; System.out.println("方法A被调用了"); &#125; lock.unlock(); &#125; private static void menthdB()&#123; lock.lock(); for(int i=0;i&lt;10;i++)&#123; System.out.println("方法B被调用了"); &#125; lock.unlock(); &#125; public static void main(String[] args)&#123; new Thread(()-&gt;&#123; menthdA(); &#125;).start(); new Thread(()-&gt;&#123; menthdB(); &#125;).start(); &#125;&#125; 使用Condition实现线程之间的等待/通知 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 用Condition实现等待通知: * 使用：1、private Condition condition=lock.newCondition(); 获得condition对象 * 2、lock.lock(); 一定要获得了锁，才能执行后面的方法进入等待 * 3、condition.await(),同时就会释放了锁。 * 4、condition.signal(); 其他线程调用signal唤醒等待线程 * 5、signal线程释放锁，lock.unlock(); 释放锁，让其他线程获得锁，因为signal不释放锁。 */public class Reentranlock2 &#123; private Lock lock=new ReentrantLock(); private Condition condition=lock.newCondition(); private void menthdA()&#123; try &#123; lock.lock(); System.out.println("方法A被调用了,现在时间="+System.currentTimeMillis()); condition.await(); System.out.println("A:我终于被唤醒了"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125; private void menthdB()&#123; try &#123; lock.lock(); System.out.println("方法B被调用了,现在时间="+System.currentTimeMillis()); condition.signal(); Thread.sleep(500); System.out.println("B:放你出去你也得先等我执行完"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; Reentranlock2 reentranlock2=new Reentranlock2(); new Thread(()-&gt;&#123; reentranlock2.menthdA(); &#125;).start(); Thread.sleep(2000); new Thread(()-&gt;&#123; reentranlock2.menthdB(); &#125;).start(); &#125;&#125; 生产者消费者模式的实现 实现这个模式的关键其实就是利用线程的等待通知机制，另外加上一个在变化的条件。 这里也一样当有多个生产者消费者是，需要全部唤起，condition也有一个signalAll，功能和notifyAll相似。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * 用Condition实现生产者消费者模式 * 实现两个线程交替打印。。。 */public class Reentranlock4 &#123; private boolean hasValue=false; private Lock lock=new ReentrantLock(); private Condition condition=lock.newCondition(); private void set() throws InterruptedException &#123; lock.lock(); while(hasValue)&#123; condition.await(); &#125; System.out.println("*********"); hasValue=true; condition.signal(); lock.unlock(); &#125; private void get() throws InterruptedException &#123; lock.lock(); while(!hasValue)&#123; condition.await(); &#125; System.out.println("------------"); hasValue=false; condition.signal(); lock.unlock(); &#125; public static void main(String[] args)&#123; Reentranlock4 reentranlock4=new Reentranlock4(); new Thread(()-&gt;&#123; for(int i=0;i&lt;50;i++)&#123; try &#123; reentranlock4.set(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); new Thread(()-&gt;&#123; for(int i=0;i&lt;50;i++)&#123; try &#123; reentranlock4.get(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125;&#125; 公平锁与非公平锁 这就是锁的ReentrantLock的两种形态，公平锁就是先到先得，也就是在main方法中先调用start会先获得锁，当然这不是绝对的，知识基本有序，而非公平锁就是和不排队，先后来都一样，一起抢锁。 123//再锁定义的时候可以确定它是什么锁，true公平锁，false非公平锁。Lock lock=new ReentrantLock(true);Lock lock=new ReentrantLock(false); ReentrantLock的一些其他方法 因为这把锁像我们管理者加的，所以我们在外面就能清晰的知道谁上锁了，谁没锁，谁在等，有没有人在等，线程是不是在等…..这样就有很多方法，我觉得这个不需要去记，因为API这么多哪里都记得住，只要知道有，有需要用的时候翻翻api就好。 ReentrantReadWriteLock​ ReentrantReadWriteLock有两把锁，一把读的锁，一把写的锁，当上的是读的锁，他们其他线程也是可以读的不可以写，但上的是写的锁，那么其他线程不能读不能写。 如何理解? ReentrantReadWriteLock按照字面意思是读写锁，如果你把它理解为对IO的控制，那就大错特错了（其实大多数人的直觉是这样）。其实你只要把它理解成一个数据库的事务锁就对了。 众所周知数据库事务锁的特点就是，读写分离。而ReentrantReadWriteLock是类似最高级的事务级别Serializable可串行化（严格讲比这个还更严谨）。什么意思呢，意思就是，对一条数据的更新操作只影响其它对该条数据的更新操作，而读操作是不影响的。 而并发锁Lock也好，synchronizy也好，是直接把读写都锁住的。就是说，该代码块一但锁住之后，既不能读也不能写。 但这样是有问题的，有些线程只是想读取一下数据，我又不改数据，你锁它干嘛呢？（类似事物吧） 所以ReentrantReadWriteLock把锁拆分成了读锁和写锁。 写锁之间的互斥的，但读锁不互斥（大家一起读数据么，压根就没冲突）。 但是有一点要注意。就是你想获取写锁，是除当前线程外，不能存在其它的读锁的。 好比就是说，我要改里面的数据了，那些获取了读锁的线程，必须通通退出来，否则会出现读到老数据的问题（类似事物里面的脏读） ，获取到写锁之后，其它线程也不能再获取到读锁了。 Lock和synchronized对比？1）Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现； 2）synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁； 3）Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断； 4）通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。 5）Lock可以提高多个线程进行读操作的效率。 6）在JDK1.5中，synchronized是性能低效的。因为这是一个重量级操作，它对性能最大的影响是阻塞式的实现，挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作给系统的并发性带来了很大的压力。相比之下使用Java提供的Lock对象，性能更高一些。 但是，JDK1.6，发生了变化，对synchronize加入了很多优化措施，有自适应自旋，锁消除，锁粗化，轻量级锁，偏向锁等等。导致在JDK1.6上synchronize的性能并不比Lock差。因此。提倡优先考虑使用synchronized来进行同步。 二、多线程与单例模式单例模式单例模式有两种加载模式： 立即加载/“饿汉模式”：当需要这个类的时候就立即加载出这个类的对象返回回去。 延迟加载/“懒汉模式”：对象的事例不会随着类的加载而马上事例化，而是真正调用某个方法的时候才去事例化。 这样一来，延迟加载的时候多个线程同时加载这个类，就会为每一个线程实例化一个对象，这就不符合单例模式的要求了。 后面介绍几种解决这种问题的方法 多线程实现单例的几种方法 直接上全锁，把真个建立事例对像的方法锁起来，但是效率低 DCL双检查锁机制 123456789101112131415161718private volatile static Danli danli; public static Danli getInstance()&#123; try &#123; if(danli!=null)&#123; return danli; &#125;else&#123; //模拟创建对象的准备工作 Thread.sleep(2000); synchronized (Danli.class)&#123; if(danli!=null)&#123; //再次检验，以确保等待之后是否有对象创建了 danli=new Danli(); &#125; &#125; return danli; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; 使用静态内部类 1234567891011public class Danli2 &#123; //利用静态内部类实现多线程的单例 private static class Help&#123; private volatile static Danli2 danli=new Danli2(); &#125; private Danli2()&#123; &#125; public static Danli2 getInstance()&#123; return Help.danli; &#125;&#125; 使用静态代码块 这两个我觉得是一个意思，利用类的初始化对静态资源只加载一次，下此要用的时候直接去方法区里面找的原则，所以只会有一个类的实例化对象. 123456789public class Danli2 &#123; private volatile static Danli2 danli=null; static &#123; danli=new Danli2(); &#125; public static Danli2 getInstance()&#123; return danli; &#125;&#125; 序列化和反序列化的单例模式的实现 问题：在遇到对象序列化，使用默认的运行方式和静态内置类的方法还是对出现多例 序列化：把对象转换为字节序列的过程称为对象的序列化。反序列化：把字节序列恢复为对象的过程称为对象的反序列化。 实现是借助io流操作，ObjectOutputStream、ObjectInputStream 123456789101112131415161718192021private static void serializeFlyPig() throws IOException &#123; FlyPig flyPig = new FlyPig(); flyPig.setColor("black"); flyPig.setName("naruto"); flyPig.setCar("0000"); // ObjectOutputStream 对象输出流，将 flyPig 对象存储到E盘的 flyPig.txt 文件中，完成对 flyPig 对象的序列化操作 ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(new File("d:/flyPig.txt"))); oos.writeObject(flyPig); System.out.println("FlyPig 对象序列化成功！"); oos.close(); &#125; /** * 反序列化 */ private static FlyPig deserializeFlyPig() throws Exception &#123; ObjectInputStream ois = new ObjectInputStream(new FileInputStream(new File("d:/flyPig.txt"))); FlyPig person = (FlyPig) ois.readObject(); System.out.println("FlyPig 对象反序列化成功！"); return person; &#125; 三、其他知识的补充线程的状态 NEW: 子线程被创建，在父线程中子线程的状态就是new RUNNABLE：线程在执行的时候的状态 BLOCKED：线程在等待锁的状态 WAITING：线程在等待通知的状态 TIMED WAITING：sleep时候的状态 TERMINATED：线程运行完毕 调用 thread.getState()，可以查开线程的状态 线程组（ThreadGroup）直接new出来的对象，可以规定组名，其他线程可以指定自己的组，组里面也可以包含线程组。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM学习笔记（二）]]></title>
    <url>%2F2019%2F04%2F15%2FJVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[继续JVM知识，这次主要总分解类得加载，深入了解JVM这本书我就先看这部分，实在是难啃，很多名词都没接触过，知识概念性得东西又多，关于调优部分一些常用得调优工具我就不总结了，后面有机会再来读读这本书 类加载机制 类加载得全过程 什么时候类加载 类加载器 一、类加载全过程 先看看一张完整的类的生命周期图 整个过程分为七步，其中验证、准备、解析属于连接，前面五部总的来说就是类的加载，加载、验证、准备、初始化和卸载这些步骤的顺序是固定的，其他的可能不确定，解析可能在初始化之后，比如反射机制。 下面主题看看加载的步骤： 加载加载主要做三件事： 通过一个类的全限定名来获取定义此类的二进制字节流，后面介绍类加载器时，会自定义一个类加载器，就是需要一个io的字节流，来实现类的加载。 将字节流的静态储存结构转化为方法区的运行时的数据结构；也就是类加载先会去加载那些静态的资源放入方法区。 还有就是会在堆里面生成一个 java.lang.class的对象，作为访问这个类在方法区里面内容的接口。 验证验证的几个内容： 文件格式的验证：检查是不是以魔数开头，版本对不对。。。 元数据验证：对一些类需要的数据进行验证，必有这个类有没有父类，这个父类是不是不能被继承的，父类是不是抽象的 字节码验证：这是比较麻烦的一个部分，主要是验证程序是不是语义合法，是不是逻辑符合，这个其实idea也会去做….所以在编译器调优时可以把JVM 的这些验证功能关掉。-Xverify:none 符号引用验证：这个其实是在解析的时候发生。是对常量池中各种符号引用的一种验证 准备准备阶段就是为类的变量分配内存，并设置类变量的初始值的阶段，注意的是这个阶段只是对类变量（被static修饰的变量）进行准备，不包括实例变量。 public static int a=123; 这里再准备阶段a 的值将只是 0，不是123，因为只是给一个初始值，要解析的时候才会真正被复制。 public final static int a=123; 这里的a在准备阶段是123，因为加了final那么就会为变量赋值—-注意一下 解析 解析的主要目的是：将虚拟机常量池中的符号引用替换为直接引用的过程。 解释一下符号引用和直接引用：比如在方法A中使用方法B，A（）{B（）；}，这里的B（）就是符号引用，初学java时我们都是知道这是java的引用，以为B指向B方法的内存地址，但是这是不完整的，这里的B只是一个符号引用，它对于方法的调用没有太多的实际意义，可以这么认为，他就是给程序员看的一个标志，让程序员知道，这个方法可以这么调用，但是B方法实际调用时是通过一个指针指向B方法的内存地址，这个指针才是真正负责方法调用，他就是直接引用。 初始化初始化简单来讲就是去执行 &lt; clinit&gt;()构造方法的过程，为类的静态变量赋予正确的初始值，上述的准备阶段为静态变量赋予的是虚拟机默认的初始值，此处赋予的才是程序编写者为变量分配的真正的初始值。 对 类变量 和 静态语句块 进行赋值动作，这个过程先后就是开谁在前谁在后。 下面代码值得一看 123456789public class Test1 &#123; static &#123; i=0; //可以赋值，即使还没定义，但是不能访问，也就是你不能对i进行其他操作，除了赋值 &#125; static int i=1; public static void main(String[] args)&#123; System.out.println(i); //结果为1，如果调整静态块顺序结构就为0. &#125;&#125; 12345678910111213//对子类的静态值调用会先去加载父类的 static class Parent&#123; public static int A=1; static &#123; A=2; &#125; &#125; static class Sun extends Parent&#123; public static int B=A; &#125; public static void main(String[] args)&#123; System.out.println(Sun.B); //打印结果为2 &#125; 而且静态块的赋值操作还是阻塞的。 二、什么时候类加载类的主动加载主动加载就是出现下面情况，会里面对类进行初始化，当然初始化之前肯定还有加载、验证、准备、解析。。 java对类的主动使用有五种情况： 创建类的实例 (new），或者定义类用 final 修饰 访问某个类或接口的静态变量，或者对该静态变量赋值 ，调用类的静态方法 。类的static你要用就得先加载这个类。 反射（如Class.forName(“com.shengsiyuan.Test”)） 初始化一个类的子类（先初始化所有的父类，最后初始化本身，接口除外，类初始化的时候，它所实现的接口不会初始化，就算字接口初始化，父接口也不会初始化，只有当程序调用接口的静态变量的时候才会导致接口的初始化） Java虚拟机启动时被标明为启动类的类，如main方法的那个类。 写点代码吧,下面代码差不多概括了2和4和5，1好理解，3记一下 12345678910111213141516171819202122232425262728class Parent&#123; static &#123; System.out.println("我是妈妈，我要先被加载"); &#125;&#125;class Son extends Parent&#123; static &#123; System.out.println("我是儿子，我被加载了"); &#125; public static void function()&#123; System.out.println("我是儿子的静态方法，调用我要先加载我"); &#125;&#125;public class Test3 &#123; static &#123; System.out.println("我是有main方法的类，我第一个加载"); &#125; public static void main(String[] args)&#123; Son.function(); &#125;&#125; /** * 打印结果： * 我是有main方法的类，我第一个加载 * 我是妈妈，我要先被加载 * 我是儿子，我被加载了 * 我是儿子的静态方法，调用我要先加载我 */ 类的被动加载有以下三种情况 访问类的静态变量，只会去初始化这个变量真正被定义的类。 new一个类的数组是不会马上去加载这个类的，只有最后操作数组具体对象才会加载。 访问类的final变量不会去加载这个类 也写点代码吧。很有意义的代码，值得思考 123456789101112131415161718192021class Parent2&#123; static &#123; System.out.println("我是妈妈，我要先被加载"); &#125; public static int value=123;&#125;class Son2 extends Parent2&#123; public static final int sonvalue=123; static &#123; System.out.println("我是儿子，我被加载了"); &#125;&#125;public class Test4 &#123; public static void main(String[] args)&#123; System.out.println(Son2.value); //Son2不加载 Son2[] son2s=new Son2[10]; //Son2不加载 System.out.println(Son2.sonvalue); //Son2不加载 &#125;&#125;//打印结果是之后Parent2被加载了 三、类加载器JDK 默认提供了如下几种ClassLoader Bootstrp loaderBootstrp 加载器是用C++语言写的，它是在Java虚拟机启动后初始化的，它主要负责加载%JAVA_HOME%/jre/lib,-Xbootclasspath参数指定的路径以及%JAVA_HOME%/jre/classes中的类。 ExtClassLoader Bootstrp loader 加载ExtClassLoader,并且将ExtClassLoader的父加载器设置为Bootstrp loader.ExtClassLoader是用Java写的，具体来说就是 sun.misc.Launcher$ExtClassLoader，ExtClassLoader主要加载%JAVA_HOME%/jre/lib/ext，此路径下的所有classes目录以及java.ext.dirs系统变量指定的路径中类库。 AppClassLoader Bootstrp loader 加载完ExtClassLoader后，就会加载AppClassLoader,并且将AppClassLoader的父加载器指定为 ExtClassLoader。AppClassLoader也是用Java写成的，它的实现类是 sun.misc.Launcher$AppClassLoader，另外我们知道ClassLoader中有个getSystemClassLoader方法,此方法返回的正是AppclassLoader.AppClassLoader主要负责加载classpath所指定的位置的类或者是jar文档，它也是Java程序默认的类加载器。 综上所述，它们之间的关系可以通过下图形象的描述： 为什么要有三个类加载器，一方面是分工，各自负责各自的区块，另一方面为了实现委托模型。 双亲委派模型就是一个类加载器收到类加载的要求，它先不会去加载，会先让上一层的的类加载器去加载，一致到启动类加载器，然后启动类加载器就回去加载，它加载不了又丢回给扩展类加载器，下来每个都会去是试着加载知道加载出来，到最后加载不出来就报错。 目的就是为了安全，对Java层序稳定性有很重要的作用。 破坏双亲委派模型这个就是类加载器收到类加载的要求，它就回去加载，它加载不了再去个ParentClassLoader加载。比如tomcat就是这个干的，这样做灵活性更高。 自定义类加载器最后写一个自定义的文件类加载器，很简单，实现了双亲委派模型。先丢个parent。也就是会丢个App-ClassLoader。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class FileSystemClassLoader extends ClassLoader &#123; private String rootDir; public FileSystemClassLoader(String rootDir) &#123; this.rootDir=rootDir; &#125; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; Class c=findLoadedClass(name); if(c!=null)&#123; //已经加载过了 return c; &#125;else&#123; ClassLoader parent=this.getParent(); try &#123; c=parent.loadClass(name); &#125;catch (Exception e) &#123; &#125; if(c!=null)&#123; return c; &#125;else&#123; byte[] classdate= new byte[0]; try &#123; classdate = getClassDate(name); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; if(classdate==null)&#123; throw new ClassNotFoundException(); &#125;else&#123; c=defineClass(name,classdate,0,classdate.length); &#125; &#125; &#125; return c; &#125; private byte[] getClassDate(String className) throws IOException &#123; String path=rootDir+"/"+className.replace('.','/'); InputStream is = null; StringBuffer a=new StringBuffer(); try &#123; is=new FileInputStream(path); byte[] buffer=new byte[1024]; int tmp=0; while((tmp=is.read(buffer))!=-1)&#123; a.append(buffer); &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125;finally &#123; if(is!=null)&#123; is.close(); &#125; &#125; return a.toString().getBytes(); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>学习</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java多线程学习笔记（一）]]></title>
    <url>%2F2019%2F04%2F14%2FJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Java多线程编程核心技术也看了大半了，感觉时候做点总结了，这本书看着还是比较轻松愉快的，推荐推荐。书本用的了很多事例去讲解多线程的种种API，作为多线程学习还是很不错的。 Java多线程开山篇我就不一点一点总结了，毕竟别人总结的已经很好了，需要总体复习的时候看看别人总结的就挺不错了，学习时间够写博客时间自然得zip一下。 Thread 主要API一、体验多线程继承Thread类，实现Runnable接口，一般推荐后面的方法，因为继承只能有一个嘛。 1234567891011121314151617/** * 体验线程 * 线程的调用不是跟随程序书写的先后来决定的 */class Tread extends Thread&#123; @Override public void run() &#123; System.out.println("我被调用了"); &#125;&#125;public class Thread01 &#123; public static void main(String[] args)&#123; Tread s=new Tread(); s.start(); System.out.println("主线程被调用了"); &#125;&#125; 二、Thread主要的方法基本方法 currentThread() 获取当前线程 isAlive 判断线程时候已经结束 sleep 让线程进入阻塞状态，并且是规定时间的 getId 获得线程的ID，这相当于给每个线程编号，每个线程都有一个自己的ID 线程的停止 1234567891011121314151617181920212223242526272829303132333435363738/** * 线程的停止： * 1、run方法结束线程自然停止 * 2、调用stop方法，强行停止线程，但这是不安全的，不建议使用 * 3、调用interruput，这个方法并不是马上的停止线程，而是基于线程一个 interruput的值得改变 * 作为一个标记，通过这个boolen值得改变，进行if判断来终止循环，从而终止线程。 * interruputed是当前线程又类调用得，它得调用会使得true变成false,而且测试来看 * 调用interruput方法，先interruputed变成true，后isInterruputed变为true， * 因为我多次测试，用interruputed方法作为判断条件，打印得isInterruputed得结果依然还是false * Interruputed方法得调用，不会改变自身得值 * * 但是这个停止只是停止了 循环，并没有停止整个线程，通过抛出异常得方式可以使得整个线程真正得停下来 */ class Th7 extends Thread&#123; @Override public void run() &#123; for(int i=0;i&lt;10000;i++)&#123; if(Thread.interrupted())&#123; System.out.println(this.isInterrupted()); break; &#125; System.out.println(i); &#125; System.out.println("heihei,我还在运行喔"); &#125;&#125;public class Thread07 &#123; public static void main(String[] args) throws InterruptedException &#123; Th7 th7=new Th7(); th7.start(); Thread.sleep(50); //调整线程状态 th7.interrupt(); System.out.println(Thread.interrupted()); &#125;&#125; interruput 这个方法一般是配合着条件判断，或者抛异常来停止线程。 值得注意的是 ：当一个线程再阻塞，也就是再 sleep,wait,被join的时候，被interrupt是会抛出异常的。 线程的其他小点 suspend 和 resume 将线程挂起，resume使线程恢复，这个也不是安全的也不推荐。 yield ，这个就是放弃资源，重新排队，这个不退进入阻塞，而是直接重新开始排队。 线程的优先级： setPriority方法设置，1-10，默认5，注意优先级并不代表一定先执行。 守护线程：setDaemon可以设置某个线程为守护线程，守护亡则线程亡。 二、线程的同步都知道多线程处理同一份资源的时候，往往会出现线程非安全的问题。原因就是一个线程对一个资源进行了修改还没来得及保存，另一个线程也读取了这分资源进行了修改，只是后就会出现不同步的现象。 synchrnized同步方法123456789101112131415161718192021222324252627282930313233343536/** * 现在我们来加上锁试试 * 结果时不会又线程不安全问题的 * 等同于 同步了，一定要等a用完了这个方法，b才能去碰它 * */public class Thread13 &#123; private static int num; public synchronized static void addI(String uname) throws InterruptedException &#123; if(uname.equals("a"))&#123; num=100; System.out.println("a set over"); Thread.sleep(2000); &#125;else&#123; num=200; System.out.println("b set over"); &#125; System.out.println(uname+" num="+num); &#125; public static void main(String[] args)&#123; new Thread(()-&gt;&#123; try &#123; addI("a"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); new Thread(()-&gt;&#123; try &#123; addI("b"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125;&#125; synchrnized同步块1234567891011121314151617181920212223242526272829303132333435363738/** * 同步代码块也是对象锁，当一个线程持有了一个对象的同步块锁，那么这个对象的所有上锁的方法都是同步的 * 不能被其他线程所访问，只有当这个线程结束，才会释放锁 * * 上面是锁this,我们也可以不锁this，而是锁另外一个对象，那么这个锁和整个类里面的其他锁就是异步的了 */public class Thread19 &#123; private String name; private String pwd; private void fun(String name ,String pwd) throws InterruptedException &#123; String anything=new String(); synchronized (anything)&#123; this.name=name; this.pwd=pwd; Thread.sleep(3000); System.out.println(Thread.currentThread().getName()+" name="+this.name+ " pwd="+this.pwd); &#125; &#125; public static void main(String[] args)&#123; Thread19 thread19=new Thread19(); new Thread(()-&gt;&#123; try &#123; thread19.fun("a","aaa"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); new Thread(()-&gt;&#123; try &#123; thread19.fun("b","bbb"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125;&#125; volatile关键字轻基的锁，它所得是资源，也就是线程每次用到这个资源的时候都会区公共区看看这个资源是否改变，都会取读取公共部分的这个资源。这样就可以实现对一个线程的控制。 值得注意的是： 这个锁只对原子性=型操作有效。 关于死锁简单来说死锁就是互相持有对方需要的锁。。。 A线程持有A锁，在A线程里面需要调用上了B锁的资源。 B线程持有B锁，在B线程里需要调用上了A锁的资源，这个时候就很容易发生死锁， 嵌套锁是很容易导致死锁。 三、线程之间的通信wait 和 notify1234567891011121314151617181920212223242526272829303132333435363738/** * 这一部分是线程通信的学习： * 主要掌握的技术点： * 1、使用wait/notify实现线程之间的通信 * 2、生产者/消费者模式的实现 * 3、方法join的使用、 * 4、TreadLocal类额使用 *//** * wait使线程停止，停止必需要持有对象的锁，对象级别的锁， * 而notify/notifyall，刚好相反，它可以是线程恢复，但是它也需要对象锁，而且这把锁应该和它需要唤起的线程的对象 * 锁一致，方可唤起。 */public class Thread1 &#123; public static void main(String[] args) throws InterruptedException &#123; String lock=new String(); new Thread(()-&gt;&#123; synchronized (lock)&#123; System.out.println("第一个开始了"); try &#123; lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("第一个结束了"); &#125; &#125;).start(); Thread.sleep(2000); new Thread(()-&gt;&#123; synchronized (lock)&#123; System.out.println("第二个开始了"); lock.notify(); System.out.println("第二个结束了"); &#125; &#125;).start(); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 用wait/notify实现线程之间的通信 * 但结果是，另个一线程notify之后，wait线程并没有马上开始，而是等notify线程执行之后才执行 * 这是因为两个线程持有同一个锁，notify调用之后，可以让wait线程从阻塞状态到就绪状态。 * 但notify线程还没有释放同步锁，wait线程就只能同步等待 * 综上wait：让一个线程进入等待队列，并且释放同步锁，知道被另一个持有相同锁的线程调用notify才进入就绪状态 * notify:然同步锁相同的线程从阻塞状态进入就绪状态，但不会释放自己的同步锁。 */class MyList&#123; private static List list=new ArrayList(); public void add()&#123; list.add("anything"); &#125; public int size()&#123; return list.size(); &#125;&#125;public class Thread2 &#123; public static void main(String[] args)&#123; String lock=new String(); MyList list=new MyList(); new Thread(()-&gt;&#123; synchronized (lock)&#123; if(list.size()!=5)&#123; System.out.println("wait begin"); try &#123; lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("wait end"); &#125; &#125; &#125;).start(); new Thread(()-&gt;&#123; synchronized (lock)&#123; for(int i =0;i&lt;10;i++)&#123; list.add(); if(i==5)&#123; System.out.println("发出通知"); lock.notify(); &#125; System.out.println("添加了"+(i+1)+"个元素"); &#125; &#125; &#125;).start(); &#125;&#125; 稍微总结：wait时线程进入阻塞、并且释放锁，当线程被notify时，并不能马上开始，需要等notufy线程执行完毕释放了锁才能拿到锁，开始执行。这两个方法都是需要对象锁的！！！ 同步代码块，就是锁的范围缩小，我们应该让公共的变量被赋值的代码进行加锁，应该在线程结束之际在对其进行赋值,用私有变量保存小操作，可是这样连私有 线程通道流12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152** * 在javaz中有各种各样的io流操作，关于线程的io有以下几种 * PipedInpuStream PipedOutputStream * out.connect(in); 来连接两个流实现两个线程之间的交流 * PipedReader PepedWriter * 字符流操作大同小异，就是读出的时候不用再将字符变成字节，读取的时候创建一个字符数组或者stringbuild */public class Thread6 &#123; private void writeMthod(PipedOutputStream out) throws IOException &#123; System.out.println("write:"); for(int i=0;i&lt;300;i++)&#123; String outDate=""+(i+1); out.write(outDate.getBytes()); System.out.print(outDate); &#125; System.out.println(); out.close(); &#125; private void readMthod(PipedInputStream in) throws IOException &#123; System.out.println("read:"); byte[] bytes=new byte[20]; int lengh=in.read(bytes); while(lengh!=-1)&#123; String inDate=new String(bytes,0,lengh); System.out.print(inDate); lengh=in.read(bytes); &#125; System.out.println(); in.close(); &#125; public static void main(String[] args) throws IOException, InterruptedException &#123; Thread6 thread6=new Thread6(); PipedOutputStream out=new PipedOutputStream(); PipedInputStream in=new PipedInputStream(); out.connect(in); new Thread(()-&gt;&#123; try &#123; thread6.readMthod(in); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;).start(); Thread.sleep(200); new Thread(()-&gt;&#123; try &#123; thread6.writeMthod(out); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125;&#125; join 开始体验join实现线程之间的通信了。 在一个线程中 调用另一个线程的join方法，那么本线程将会进入阻塞状态，直到join的线程结束了 才会继续执行 在阻塞中的线程被调用 interrupt方法进行打断，都会抛出异常 join也有像wait(long)一样的方法，jion(long），而且底层就是用wait(long)实现的，所有也会释放锁 join(long)和wai(long)t不一样的是，join设置的时间到了也还要那个线程结束了才能唤起。但wait时间到了没有被notify也会被唤起 而且join是线程的方法，wait必要线程同步锁锁的对象！ sleep，是不释放锁的，一个线程在sleep的时候是始终持有着锁，其他线程无法访问 ThreadLocal 和 InheritableThreadLocal1、体验ThreadLocal：它相当于每个线程都个公共部分的变量设置一个私有的箱子，装着私有的内容。 简单来讲就是公共变量对每个线程都有自己私有的值。 它是一种泛型容器–，放在定义公共变量的前面. 它的底层是一个map,这个map会存放在所有的线程，然后每次去存取的时候，都会先找到当前线程。 如果从未存过内容，调用get会返回null。 2、没有存放get也可以不是null,方法是定义一个新的类继承ThreadLocal 当然要去复写initialValue方法，它就是定义了默认没有set的时候get出来的值。 当然这也继承出来的类，也是符合每个线程对公共变量可以有自己私有的值。 3、这里体验：InheritableThreadLocal的使用 名字真的是贼长…. 作用：就是让子线程可以从父线程中取值。。。 我觉得这里要明白一个东西就是 子父线程，这里不是线程之间的继承，而是父线中开创了子线程。 而且子线程也可以对这个值进行修改，但是这个修改不会对父线程值造成影响。 通知这种继承也实现了线程之间的通信 写在最后 char a =0 ; 这样a什么都没有的，null都不是 getIndexOf(String1,String2) 可以判断第一个字符串是否包含另一个字符串。包含放回起始位置，不包含返回-1。 123456789101112131415public static void main(String[] args)&#123; String a="12312314"; int abs=0; int[] index =new int[128]; /** * 动态规划：计算当前能到达当前位置的最长字符串，要有个头 * 这个头就是i，头的选择是从本来的i和当前字符前一次出现的下一个位置。得到头 */ for(int i=0,j=0;j&lt;a.length();j++)&#123; i=Math.max(i,index[a.charAt(j)]); abs=Math.max(abs,j-i+1); index[a.charAt(j)]=j+1; //这里是记录下 下一个位置，从j以后没有j位置上这个字符 &#125; System.out.println(abs); &#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[about me]]></title>
    <url>%2F2019%2F04%2F12%2Fabout-me%2F</url>
    <content type="text"><![CDATA[今天是2019.4.13–我念大三，从今天起记录我的生活。 2019-6-07 多云 怎么就一个月没写日常了，开始到期末了，考试也多起来了，每天还是会坚持学习计算机啦，很累。 最近没有学习一些新的框架技术了，买了一些基础与Java方面的书籍，这几天一直在看，其实挺推荐Java并发编程之美，不会很难讲的很好懂，可能是我之前看了一辆本。反正是本不错的书。 最近的文章可能会减少，因为把读书的一些笔记代码放在了一个仓库，可能会日常更新的是那个仓库了，最近真的挺忙的。等考试考完我在来把一些知识点总结成文章把。 2019-5-07 晴 本来说话的六一去看演唱会，结果她那个周末安排上了考试，哭泣，然后把票卖了，哭泣。 2019-5-04 今天开始又开始搞MySQL了，再Linux下安装了MySQL，花了不小的功复，到现在无论是window下还是Linux下我，安装遇到问题最大的就是MySQL了。。。 2019-5-01 被前端代码困扰和crud的一天，劳动节快乐 2019-4-30 很大的雨 马上开始五一长假了，我并没有回家呆在了学校，今天没怎么学知识，做了份简历，希望好运把 2019-4-26 开始热了 今天把图书馆借的多线程和高并发两本书还了，然后又借了本 ==Java编程思想== 2019-4-25 暴雨转大太阳 逼着我画了一下的CAD 最近依旧学习劲蒙，高并发—算法—以及新技术的继续学习 2019-4-23 气温逐渐升高 负载均衡 2019-4-21 还凑合 为什么重写对象的equals()方法一定要重写hashcode()方法。 原因很简单： 基本条件：两个对象 equals成立 是 hashcode相等的 充分不必要条件。 就此如果改了 equals 方法，使得地址不一样的两个对象 相等了；但是根据地址计算的hashcode却不相等；这违背了上面的条件，后面还会导致 hashSet去重不得经了，hashMap的key不重复也不得经了。 2019-4-20 多云转雨 今天周末，女朋友说练车手背门夹了，然后她大姨给了她一些17前过期的创口贴，然后现在她的手指夹还是紫的。我要笑死了。 学习学习使我快乐。 2019-4-18 天气还不错今天满课啊，每天又要上课又要学计算机还是蛮累的喔加油加油 2019-4-16 多云Java多线程一书算是看完了，后面还会看并发编程艺术一书，继续补充Java高级知识，真的挺累的，每天还有很多自己专业的课，虽然没听都是看自己的书，但还是感觉计算机学习不去敲代码感受很难有深切的体会。现在挺迷茫的，是应该再继续多学习新知识，还是回过头来把Java的核心知识回顾学习，三大框架和web基础好久没碰都不太记得了，原因也是之前学就仅仅只是学会怎么用，要去搞懂这些子框架原理又是需要一大把时间，我现在缺的就是时间啊。 2019-4-15 阴今天继续学习了JVM，这书看得非常的难受，先看到着吧，这本书以后再翻。这个月也不准备在学很多新知识了，准备做一个阶段性的复习，回顾整理。 2019-4-14 多云我已经写了两篇文章啦，还是很开心的。我在过着我喜欢的日子，不再有过去两年那种迷茫。 2019-4-12 雨初次尝试搭建一个博客，作为一个没什么审美的boy，照着文档七七八八的把功能补齐了，先凑合着用吧。我的其实是想记录下自己的所学，每天都能记录下来一些东西。]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>分享</tag>
        <tag>置顶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM学习笔记（一）]]></title>
    <url>%2F2019%2F04%2F12%2FJVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[最近学习Java虚拟机，看的是深入理解Java虚拟机，整本书内容还还是非常的多的，而且有一些知识似乎还太适合我…..水平不够。然后准备做点读书笔记和一些自己的思考。 JVM学习笔记（一） 我主要准备学习的有一下三部分： JVM虚拟内存和GC Java类的J加载机制 代码的优化） 本文主要总结一下第一部分，内存模型和垃圾回收机制。Java内存模型 先来看看一张JVM内存模型图 1. 程序计数器程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 各个线程独有，每个线程都有一个。内存区域是唯一一个在Java 虚拟机规范中没有规定任何OutOfMemoryError 情况的区域。 2. java虚拟机栈与程序计数器一样，Java 虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。虚拟机栈存放的是局部变量表、一些方法体内的东西。在Java 虚拟机规范中，对这个区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError 异常；如果虚拟机栈可以动态扩展（当前大部分的Java 虚拟机都可动态扩展，只不过Java 虚拟机规范中也允许固定长度的虚拟机栈），当扩展时无法申请到足够的内存时会抛出OutOfMemoryError 异常。 3. 本地方法栈这个和java虚拟机栈差不多，只不过它存放的是本地的方法，也就是native的方法。 4. Java堆堆占了很大一块内存它的作用：存放着所有的事例话对象，这里也是垃圾回收的主要目标了。后面讲垃圾回收在来自己看看。 5. 方法区方法区其实是在类加载的时一些类的信息，静态变量，常量，以及一些编译后的代码等数据。 6. 运行时的常量池常量池是方法区的一部分，常量池存放着编期生成的各种字面变量。这里有意思的是一个字符串常量池，和intern()方法： intern方法，是将堆里面的字符串对象试着放入字符转常量池，何为尝试？是这的，字符串放入常量池时，会先看看常量池中时候有这个字符串，如果有，则直接返回，我还是堆里面的我；如果没有，就回在常量池中创建这个字符串，然后返回常量池中这个字符串的引用，那么现在就不再时堆里面的那个我了，我就是指向常量池的那个我。 String a =” ads” ，这样去构造一个字符串对象，它首先会去看看常量池中是否有这个字符串，如果I有，就直接返回常量池的字符串引用。如果没有它就会在常量池中创建这个字符串然后然后返回。也就是是说，这样构造字符串一定是指向常量池的。 String a=new String(“sas”)。这样创建的话就是在堆里面的事例对象了。 ==，成立的前提是要对象一样（常量除外） 12345678910111213141516171819202122232425 public static void main(String[] args)&#123; String a =new String("1")+new String("1"); a.intern(); String b="11"; String c=new String("1")+new String("1"); c.intern(); System.out.println(a==b); //true 都是常量池中的 “11” System.out.println(a==c); //false c.intern时，常量池中已经有了“11”。所有c还是堆里的对象 System.out.println(b==c); //flase a==b,a!=c.自然 b!=c &#125;public static void main(String[] args)&#123; String b="11"; String a =new String("1")+new String("1"); a.intern(); System.out.println(a==b); //false 一样，先b就让常量池中有了“11”，a就intern不进去了 &#125;public static void main(String[] args)&#123; String a =new String("ja")+new String("va"); a.intern(); String b="java"; System.out.println(a==b); //这个也是false,因为常量池中本来就有"java".....我也不知道问什么本来就有 &#125; 7. 直接内存 直接内存其实也叫堆外内存。学习NIO的时候有了解一点，NIO在创建buffer时，就有两种allocate选择，其中有一种就是直接内存，数据是直接与底层的磁盘打交道。。。。。 Java垃圾回收机制一、判断是否可以回收的两个算法1、引用计数法算法介绍：简单来说一个对象被引用我就给他加一，失去引用就减一，以这个数来判断时候可以回收 缺点：无法解决对象之间的相互引用问题，所有jvm们基本都不是这么干的 2、可达性分析算法介绍：GC Roots，着就像一个根，所有的对象只要能和它扯上关系的就可以不被回收，也就是GC Root可以到达这些对象，如果GC Root不可达了，也就说明可以回收了 这个算法是现在用来判断是否可以回收的算法 在简单的说说引用：引用分四种：强引用、软引用、弱引用、虚引用。。。强度依次降低 分级作用：可以让垃圾回收有了分情况处理的能力，内存比较悠闲可以先不回收那些低级引用，如果内存紧张那么也知道应该先回收哪些。 二、垃圾回收算法1、标记-清除算法介绍：先标记，然后差不多了 就统一回收了 缺点： 效率不高 容易产生很多内存碎片，及其不集中，这样使得如果有大内存对象就不好处理了 2、复制算法介绍：把堆分成两份，一次只操作一遍，当这边的内存满了就将不要清楚的对象复制到另一边，然后统一清楚。 特点： 解决了标记-清楚的内存碎片问题 可以有一半的内存不被使用，效率可想而知，浪费啊！！ 3、标记-整理算法介绍：在标记-清除上做了一些改变，前面标记差不多，只是到了最后不是直接清除，而是将存活的对象移动到一端，其他的要清除的就清除掉 4、分代回收算法介绍：分代回收其实是一种思想，它肯定是要配合着前面的算法时候用，就是将堆里面的对象分为新生代和老年代 新生代：其实是马上要死了的。。。。别看它新， 老年代：这才是老不死的家伙，经常需要然后就很少被清除 总结一下：就是现在的虚拟机基本上是配合着使用的，老年代用标记-清除，新生代用复制算法三、主要的垃圾回收器1、串行：垃圾回收器 (Serial Garbage Collector)(1)串行垃圾回收器在进行垃圾回收时，它会持有所有应用程序的线程，冻结所有应用程序线程，使用单个垃圾回收线程来进行垃圾回收工作。 串行垃圾回收器是为单线程环境而设计的，如果你的程序不需要多线程，启动串行垃圾回收。 (2)串行收集器是最古老，最稳定以及效率高的收集器，可能会产生较长的停顿，只使用一个线程去回收。新生代、老年代使用串行回收；新生代复制算法、老年代标记-压缩；垃圾收集的过程中会Stop The World（服务暂停）使用方法：-XX:+UseSerialGC 串联收集 Ps：在jdk client模式，不指定VM参数，默认是串行垃圾回收器 2、串行：ParNew收集器ParNew收集器其实就是Serial收集器的多线程版本。新生代并行，老年代串行；新生代复制算法、老年代标记-压缩使用方法：-XX:+UseParNewGC ParNew收集器 -XX:ParallelGCThreads 限制线程数量 3、并行：Parallel收集器Parallel Scavenge收集器类似ParNew收集器，Parallel收集器更关注系统的吞吐量。可以通过参数来打开自适应调节策略，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或最大的吞吐量；也可以通过参数控制GC的时间不大于多少毫秒或者比例；新生代复制算法、老年代标记-压缩使用方法：-XX:+UseParallelGC 使用Parallel收集器+ 老年代串行 4、并行：Parallel Old 收集器Parallel Old是Parallel Scavenge收集器的老年代版本，使用多线程和“标记－整理”算法。这个收集器是在JDK 1.6中才开始提供使用方法： -XX:+UseParallelOldGC 使用Parallel收集器+ 老年代并行 5、并发标记扫描CMS收集器CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用都集中在互联网站或B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。 java官方介绍：https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/cms.html从名字（包含“Mark Sweep”）上就可以看出CMS收集器是基于“标记-清除”算法实现的，它的运作过程相对于前面几种收集器来说要更复杂一些，整个过程分为4个步骤，包括：初始标记（CMS initial mark）并发标记（CMS concurrent mark）重新标记（CMS remark）并发清除（CMS concurrent sweep）其中初始标记、重新标记这两个步骤仍然需要“Stop The World”。初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC Roots Tracing的过程，而重新标记阶段则是为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。由于整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，所以总体上来说，CMS收集器的内存回收过程是与用户线程一起并发地执行。老年代收集器（新生代使用ParNew） 优点:并发收集、低停顿 缺点：产生大量空间碎片、并发阶段会降低吞吐量 6、G1收集器G1是目前技术发展的最前沿成果之一，HotSpot开发团队赋予它的使命是未来可以替换掉JDK1.5中发布的CMS收集器。与CMS收集器相比G1收集器有以下特点：(1). 空间整合，G1收集器采用标记整理算法，不会产生内存空间碎片。分配大对象时不会因为无法找到连续空间而提前触发下一次GC。(2). 可预测停顿，这是G1的另一大优势，降低停顿时间是G1和CMS的共同关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为N毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒，这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了。上面提到的垃圾收集器，收集的范围都是整个新生代或者老年代，而G1不再是这样。使用G1收集器时，Java堆的内存布局与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔阂了，它们都是一部分（可以不连续）Region的集合。G1的新生代收集跟ParNew类似，当新生代占用达到一定比例的时候，开始出发收集。和CMS类似，G1收集器收集老年代对象会有短暂停顿。收集步骤：1)、标记阶段，首先初始标记(Initial-Mark),这个阶段是停顿的(Stop the World Event)，并且会触发一次普通Mintor GC。对应GC log:GC pause (young) (inital-mark)2)、Root Region Scanning，程序运行过程中会回收survivor区(存活到老年代)，这一过程必须在young GC之前完成。3)、Concurrent Marking，在整个堆中进行并发标记(和应用程序并发执行)，此过程可能被young GC中断。在并发标记阶段，若发现区域对象中的所有对象都是垃圾，那个这个区域会被立即回收(图中打X)。同时，并发标记过程中，会计算每个区域的对象活性(区域中存活对象的比例)。4)、Remark, 再标记，会有短暂停顿(STW)。再标记阶段是用来收集 并发标记阶段 产生新的垃圾(并发阶段和应用程序一同运行)；G1中采用了比CMS更快的初始快照算法:snapshot-at-the-beginning (SATB)。5)、Copy/Clean up，多线程清除失活对象，会有STW。G1将回收区域的存活对象拷贝到新区域，清除Remember Sets，并发清空回收区域并把它返回到空闲区域链表中。6)、复制/清除过程后。回收区域的活性对象已经被集中回收到深蓝色和深绿色区域。 唯一和串行垃圾回收器不同的是，并行垃圾回收器是使用多线程来进行垃圾回收工作的。 这些垃圾回收器应该只要有个印象吧，记不住=———-]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>学习</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F04%2F12%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post 1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
